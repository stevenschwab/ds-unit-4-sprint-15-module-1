{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ldr0HZ193GKb"
      },
      "source": [
        "*Unit 4, Sprint 3, Module 1*\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsrwhKw4ohgW"
      },
      "source": [
        "# 1. Recurrent Neural Networks (RNNs) and Long Short Term Memory (LSTM) -- Prepare"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Et2y0gP7IM19"
      },
      "source": [
        "\n",
        "\n",
        "![](https://wiki.tum.de/download/attachments/22578349/GATES.gif?version=1&modificationDate=1486083227237&api=v2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BOMScPtIM1-"
      },
      "source": [
        "## Learning Objectives\n",
        "- <a href=\"#p1\">Part 1: </a>Describe How Neural Networks are used for modeling sequences\n",
        "- <a href=\"#p2\">Part 2: </a>Implement LSTM models for a text classification problem and a text generation problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IizNKWLomoA"
      },
      "source": [
        "-----\n",
        "## Overview\n",
        "\n",
        "### Let's start with sequences\n",
        "\n",
        "A sequence is a collection of numbers, taking into account their order; repetition is allowed.\n",
        "\n",
        "Python lists are a good elemental example - `[1, 2, 2, -1]` is a valid list and is different from `[1, 2, -1, 2]`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44QZgrPUe3-Y"
      },
      "source": [
        "## 1.1 Recursion (Learn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rW6xwTptbDjx"
      },
      "source": [
        "\n",
        "A recursive function is a function that can call itself!<br><br>\n",
        "For a recursive function to be defined, there must be a _base case_ that the function eventually reaches by repeatedly calling itself.<br><br>\n",
        "\n",
        "###1.1.1 The factorial function\n",
        "A simple example of recursion is the _factorial_ function, <br>\n",
        "denoted by the character $!$ following a non-negative integer<br><br>\n",
        "$n! \\equiv n\\cdot (n-1) \\cdot (n-2) \\cdot \\ldots \\cdot  1$ <br><br>\n",
        "and $0! \\equiv  1$,<br><br>\n",
        "where $\\equiv$ means \"is defined as\"<br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WVaPpQdkbB3p"
      },
      "outputs": [],
      "source": [
        "def factorial(n):\n",
        "  if(n==0 or n==1):\n",
        "    return 1 #base case\n",
        "  elif(n>1):\n",
        "    return n*factorial(n-1) # recursion formula"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ap93tVqvdGKF"
      },
      "source": [
        "5! = 5 x 4 x 3 x 2 x 1 =120"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HH3AUX27rsZo",
        "outputId": "21ea446e-eb59-422c-e5ed-c6e89d58717f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "factorial(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dX_WLYHrIM1_"
      },
      "source": [
        "###1.1.2 The Fibonacci Sequence\n",
        "\n",
        "Before we dive into the inner workings of an LSTM model, let's try to understand and appreciate **recursion** in sequences. <br>A **recursive sequence** is a sequence in which the next number can be computed from one or more of the previous numbers via a [**recurrence relation**](https://en.wikipedia.org/wiki/Recurrence_relation). Recursion occurs in both pure mathematics and in the physical world in which we find ourselves embedded. <br><br>\n",
        "The root word is **recur**, which means \"to occur repeatedly\". Given a few consecutive values, the rest of a recursive sequence can be generated by repeatedly applying its recursion relation!\n",
        "\n",
        "\n",
        "As usual, we attempt to understand a concept from at least 3 different perspectives:\n",
        "- Algebraic\n",
        "- Geometric\n",
        "- Coding an example\n",
        "\n",
        "A famous example of a recursive sequence in mathematics is the [Fibonacci numbers](https://en.wikipedia.org/wiki/Fibonacci_number). Fibonacci was an Italian mathematician, who wrote about these numbers in **The Book of Calculation**, in 1202 AD. Although the sequence is named after him, it was known long before his time in India.\n",
        "\n",
        "The Fibonacci numbers are an infinite sequence of integers, beginning with $[0, 1]$ in which the $ith$ number (for $i>1$) is the sum of the two previous numbers.\n",
        "\n",
        "Here is the algorithm for generating the numbers in the Fibonacci sequence:\n",
        "\n",
        "$$F_n = F_{n-1} + F_{n-2}$$\n",
        "\n",
        "You need a **base case** $F_0=0$ and $F_1=1$ to get the sequence started.\n",
        "\n",
        "Starting from the base case, the recursion relation generates the entire sequence:\n",
        "\n",
        "$F_0=0,~~  F_1=1 $<br><br>\n",
        "\n",
        "$F_2 = F_{1} + F_{0} ~=~ 1 + 0 ~=~ 1$<br><br>\n",
        "\n",
        "Then\n",
        "\n",
        "$F_3 = F_{2} + F_{1} ~=~ 1 + 1 ~=~ 2$<br><br>\n",
        "\n",
        "Then\n",
        "\n",
        "$F_4 = F_{3} + F_{2} ~=~ 2 + 2 ~=~ 3$<br><br>\n",
        "\n",
        "Then\n",
        "\n",
        "$F_5 = F_{4} + F_{3} ~=~ 3 + 2 ~=~ 5$<br><br>\n",
        "\n",
        "etc.\n",
        "\n",
        "Get the idea?\n",
        "\n",
        "Now you try: what are $F_{6}$ and $F_{7}$?\n",
        "\n",
        "$F_6 = F_{5} + F_{4} ~=~ 5 + 3 ~=~ 8$<br><br>\n",
        "\n",
        "$F_7 = F_{6} + F_{5} ~=~ 8 + 5 ~=~ 13$<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpoASUlBvhEK"
      },
      "source": [
        "### 1.1.3 The Fibonacci Sequence in Nature\n",
        "Before coding up the Fibonacci sequence, let's take a moment to appreciate<br>\n",
        "its beauty, and how important and ubiquitous it is in nature!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCO2jNOjuH03"
      },
      "source": [
        "#### **Contruction of the [\"Golden Spiral\"](https://en.wikipedia.org/wiki/Golden_spiral)**\n",
        "![](http://www.davidbeahm.com/wp-content/uploads/2011/11/fibonacci-1024x637.jpg)\n",
        "\n",
        "#### **Snail Shells**\n",
        "![](https://i.pinimg.com/originals/32/d7/47/32d747bea24f4756dc4c5ffe61b36efd.jpg)\n",
        "\n",
        "#### **The Mona Lisa**\n",
        "![](https://i.pinimg.com/originals/f2/cb/34/f2cb3452dd774bab87bbee2b8a77d4bb.png)\n",
        "\n",
        "#### **A Spiral Galaxy**\n",
        "![](https://f4.bcbits.com/img/a3628582449_10.jpg)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-HQ2GEp9uB7"
      },
      "source": [
        "#### **Take Away:**\n",
        "- There are often surprising connections between mathematics and physical phenomena\n",
        "- The world contains many examples of recursive sequences\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObIXp1Wh9uB7"
      },
      "source": [
        "### 1.1.4 Coding the Fibonacci Sequence using a recursive function\n",
        "*This is a standard problem that often comes up in interviews for software engineering jobs!*<br>\n",
        "\n",
        "Recall: A recursive function is a function that can call itself.<br>\n",
        "For a recursive function to be defined, there must be a _base case_ that the function eventually reaches by repeatedly calling itself.<br>\n",
        "\n",
        "For the Fibonacci sequence, the _base case_ is<br><br>\n",
        "$$F_0=0 ~\\text{and}~ F_1=1$$<br><br>\n",
        "Again, here is the algorithm for the Fibonacci numbers.  \n",
        "\n",
        "\n",
        "$$F_n = F_{n-1} + F_{n-2}$$<br>\n",
        "\n",
        "So we want a recursive function that, given an integer $n$ computes the $nth$ Fibonacci number by repeatedly calling itself.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9DS5sFTX9uB8"
      },
      "outputs": [],
      "source": [
        "def fibo(n):\n",
        "    \"\"\"\n",
        "    Calculate and return the next number in the Fibonacci sequence\n",
        "\n",
        "    Input\n",
        "    -----\n",
        "    n: int or float\n",
        "        The nth number in the sequence (think of it as an index for a list)\n",
        "\n",
        "    Return\n",
        "    ------\n",
        "    F_n: the next number in the sequence generated from the previous two numbers in the sequence\n",
        "    \"\"\"\n",
        "\n",
        "    if n <= 1: # this is the base case\n",
        "        F_n = n## YOUR CODE HERE\n",
        "    elif n > 1: # this is the recursive case, where the function calls itself!\n",
        "        F_n = fibo(n-1) + fibo(n-2) ## YOUR CODE HERE\n",
        "    return F_n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-J9V1xC9uB-",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-b31ecb0aaf3ace76",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "outputId": "9f227aaf-9445-4b11-84d4-8897fbea520c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 1, 2, 3, 5, 8, 13, 21, 34]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Using our recursive function, generate the first 10 values of the Fibonacci Sequence\n",
        "###BEGIN SOLUTION\n",
        "[fibo(n) for n in range(10)]\n",
        "###END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gomC-EGf9wK6",
        "outputId": "768320dd-c3f1-45b2-e1c9-19ff9ed2d48a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6765"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "fibo(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSGduuZpymbD"
      },
      "outputs": [],
      "source": [
        "5! = 5*4*3*2*1 =  5*4! --> n! = n*(n-1)!\n",
        "\n",
        "\n",
        "def factorial(n):\n",
        "  if n==1:\n",
        "    return 1 #base case\n",
        "  else:\n",
        "    return n*factorial(n-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPQASrwt9uB_"
      },
      "source": [
        "**Take Away:**\n",
        "\n",
        "Recursive algorithms have as input their previous output. <br>\n",
        "In other words, the output at time step $t - 1$, becomes the input for the following time step $t$.<br><br>\n",
        "This key idea of recursion underlies the construction of a Recurrent Neural Networks (RNNs)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-zlyhan9uCA"
      },
      "source": [
        "-----\n",
        "\n",
        "## 1.2 Introduction to Recursive Neural Networks (RNNs)\n",
        "\n",
        "\n",
        "Now that we've gained insight into the recursion process, we can build on <br>\n",
        "our intuition to help us understand how RNNs and LSTMs work.\n",
        "\n",
        "Recurrent Neural Networks (RNNs) have a recursive loop in their architecture. The RNN model was first formulated in the original [backpropagation paper](https://chsasank.com/classic_papers/learning-representations-back-propogating-errors.html#) by Rumelhart et al. in 1986, based on the standard Fully-Connected Feed-Forward (FCFF) model:\n",
        "\n",
        "\n",
        "![](https://upload.wikimedia.org/wikipedia/commons/b/b5/Recurrent_neural_network_unfold.svg)\n",
        "\n",
        "The hidden state $\\textbf{h}$ has the same dimensionality as the input vector $\\textbf{x}$ and is updated at each time step $t$, according to _two inputs_: $x_t$ **and** the previous hidden state $h_{t-1}$. Since for the first input $x_{0}$, the previous hidden state is undefined, it is often initialized to all zeros.  <br><br>\n",
        "\n",
        "The key to the RNN is the recursive use of the _hidden state_ to learn and carry forward information about all the _previous_ elements of the input sequence.\n",
        "\n",
        "In principle, this \"memory\" feature of the RNN is an exciting concept that holds the promise to go beyond \"bag-of-words\" models in NLP to be able to encode contextual meaning of sequences of words in documents. However, the practical limitations of RNNs has prevented them from fully delivering on this promise. <br><br>\n",
        "\n",
        "RNNs\n",
        "- don't have long-term memory capacity, so cannot learn from input sequences longer than a few dozen elements long\n",
        "- suffer from the [Vanishing Gradient Problem](https://en.wikipedia.org/wiki/Vanishing_gradient_problem).<br><br>\n",
        "\n",
        "To mitigate against these limitations, Hochreiter and Schmidhuber invented the [LSTM model](https://papers.nips.cc/paper/1215-lstm-can-solve-hard-long-time-lag-problems.pdf) in 1996.<br><br>\n",
        "The LSTM model abandons the FCFF architecture in favor of the following architecture:\n",
        "\n",
        "![Long short-term memory unit](https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Long_Short-Term_Memory.svg/1024px-Long_Short-Term_Memory.svg.png)\n",
        "\n",
        "Wow! There's a lot going on here, isn't there? <br>\n",
        "In the next section, we'll break down the LSTM model bit-by-bit so, we can understand a bird's eye view of what is happening."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M49uor5E9uCB"
      },
      "source": [
        "_____\n",
        "\n",
        "\n",
        "## 1.3 Overview of the LSTM (Long Short Term Memory)\n",
        "\n",
        "For this course we will regard the LSTM as a black box, which functions as souped-up, more powerful version of the RNN. You will be responsible for being able to implement and use the LSTM models. Understanding how LSTMs work under the hood is optional, depending on your curiosity and interest.\n",
        "\n",
        "### 1.3.1 The \"vanishing gradient\" problem.  \n",
        "\n",
        "RNNs and LSTMs, like other neural networks we've encountered, are trained using backpropagation with some form of gradient descent. For an \"unrolled\" RNN (or LSTM), backpropagation has to go back through the entire time sequence of states, which is why it's called BPTT (backpropagation through time). If a gradient \"vanishes\", i.e. becomes close to zero somewhere along the line, the parameter updates also \"vanish\", and network training slows down and grinds to a halt because the parameters are becoming vanishingly small. _This is the \"vanishing gradient problem\", which LSTMs were invented to solve_. LSTMs are superior to RNNs because they can remember longer sequences and do not suffer from vanishing gradients.\n",
        "\n",
        "[Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) by Chris Olah presents a beautifully clear and concise explanation of the model's architecture and the mathematics (mostly matrix multiplication) behind it. This article will serve as our main resource for understanding how LSTMs work.\n",
        "\n",
        "Below are the equations for each of the gates in the LSTM architecture that are explained in the article.\n",
        "\n",
        "Although, you will not be held responsible for the equations in any quiz, module assignment, or Sprint Challenge - it is still instructive to have a look at the machinery inside the black box.\n",
        "\n",
        "First thing to notice is that each gate equation (not the cell states) has the form of a perceptron.\n",
        "\n",
        "Remember the perceptron? It's the fundamental building block of neural networks - it's not going away!\n",
        "\n",
        "Once you understand that, it will hopefully become gradually clear that each gate is a perceptron with a different job to do.\n",
        "\n",
        "That's it.\n",
        "\n",
        "It's just 4 perceptrons, each with a different job to do.\n",
        "\n",
        "Fortunately, you already know about perceptrons (you built one from scratch in `Sprint 2 Module 1`).\n",
        "\n",
        "____\n",
        "\n",
        "### 1.3.2 LSTM Gates\n",
        "\n",
        "#### Forget Gate\n",
        "This neuron's job is to use the current input to learn what information the cell state should forget regarding long-term dependencies.\n",
        "\n",
        "The output from the forget gate $f_t$ is used to scale the old cell state\n",
        "\n",
        "- If $f_t$ is closer to $0.0$, then less information from the previous cell state is retained.\n",
        "- If $f_t$ is closer to $1.0$, then more information from the previous cell state is retained.\n",
        "\n",
        "$$f_t = \\sigma(W_f \\cdot [h_{t-1},x_t]~+~b_f)$$\n",
        "\n",
        "#### Input Gate\n",
        "This neuron's job is to use the current input to learn what new information to include in the cell state.\n",
        "\n",
        "\n",
        "$$i_t = \\sigma(W_i \\cdot [h_{t-1},x_t]~+~b_i)$$\n",
        "\n",
        "#### Candidate Cell State\n",
        "This neuron's job is to use the current input to create a candidate cell state.\n",
        "\n",
        "This new candidate cell state will be used to update the model's final cell state.\n",
        "\n",
        "$$\\tilde{C}_t = \\text{tanh}(W_C \\cdot [h_{t-1},x_t]~+~b_C)$$\n",
        "\n",
        "#### New Cell State\n",
        "This is where the candidate and old cell state are combined to create a new cell state.\n",
        "\n",
        "This is also where the output of the input gate $i_t$ is used to scaled the candidate cell state.\n",
        "- If $i_t$ is closer to $0.0$, then less information from the candidate cell state is retained\n",
        "- If $i_t$ is closer to $1.0$, then more information from the candidate cell state is retained.\n",
        "\n",
        "Finally, you form a linear combination of the cell state $C_{t-1}$ from the previous time step with the candidate cell state $\\tilde{C}_{t}$ from the current time step to form the model's new cell state $C_{t}$ of the model.\n",
        "\n",
        "The cell state $C_t$ will be passed into the next training step and used to update the cell  and hidden states for the next step.\n",
        "\n",
        "$$C_t = f_t*C_{t-1} + i_t*\\tilde{C}_t$$\n",
        "\n",
        "#### Output Gate\n",
        "This is where the actual output of the model is calculated.\n",
        "\n",
        "This neuron's job is to take the current input and make a prediction.\n",
        "\n",
        "$$o_t = \\sigma(W_o \\cdot [h_{t-1},x_t]~+~b_o)$$\n",
        "\n",
        "Next, the cell state is used to inform the final prediction.\n",
        "\n",
        "Recall that $o_t$ is the output of a sigmoid activation function, so its value is somewhere between 0 and 1.\n",
        "\n",
        "$o_t$ is used to scale $\\text{tanh}(C_t)$, which contains the current cell state. <br><br>\n",
        "The model's final output is\n",
        "$$h_t = o_t*\\text{tanh}(C_t)$$<br><br>\n",
        "\n",
        "Recall that the tanh activation maps numbers on the real line to numbers on the interval $[-1,1]$.<br>\n",
        "So the presence of the factor $\\text{tanh}(C_t)$ makes it possible to have positive **or  negative** values for the model's final output. <br>\n",
        "Sigmoids don't allow for the possibility of negative values, but tanh does.\n",
        "\n",
        "\n",
        "The article denotes the model's pre-scaled output as $o_t$ and the final output as $h_t$. <br>\n",
        "To be clear, $h_t$ is the model's final prediction, while  $o_t$ is an intermediate step. <br>\n",
        "We are familiar with the notation $y$ to denote a model's prediction instead of using $h$. <br>\n",
        "In the LSTM, they both mean the same thing - the model's final prediction.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgvXhCKV9uCB"
      },
      "source": [
        "_________\n",
        "\n",
        "##1.4 Applications of LSTMs\n",
        "\n",
        "So why are LSTMs cool?\n",
        "\n",
        "One compelling application is **language modeling** - language is inherently ordered data (letters/words go one after another, and the order *matters*). [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) is a famous blog post by Andrej Karpathy on this topic, worth reading.<br><br>\n",
        "\n",
        "A language model is simply a model that, given some text, predicts the most likely next word, or character.<br><br>\n",
        "Language models are essentially self-supervised -- the \"label\" or \"target\" for any text string is the next word (or character). <br>\n",
        "The data set already has the answers!\n",
        "\n",
        "Another interesting application of LSTMs is to text classification problems such as the sentiment classification problem we encountered in Unit 4, Sprint 1. Since LSTMs can learn contextual information about sequences of words, they can learn for example, that \"the service is not so great\" does not indicate a positive sentiment.\n",
        "\n",
        "For our purposes, we'll use TensorFlow and Keras to train LSTMs with text data.\n",
        "\n",
        "Resources:\n",
        "- https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py\n",
        "- https://keras.io/layers/recurrent/#lstm\n",
        "- http://adventuresinmachinelearning.com/keras-lstm-tutorial/\n",
        "\n",
        "\n",
        "Note: These days, [Transformer models](https://jalammar.github.io/illustrated-transformer/) surpass LSTMs for most Natural Language Processing tasks. Interestingly, people have recently adapted Transformers -- which were developed to solve text NLP problems --- to work with Computer Vision tasks, and their performance now rivals that of Convolutional Neural Networks (which we'll introduce in the next Module)! So if you're interested in learning about state of the art NLP models, your next step is Transformers. The [Free Hugging Face Transformers Course](https://huggingface.co/course/chapter1) is a great resource.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSytcRhoIM2A"
      },
      "source": [
        "# 2. Sentiment Classification with RNN/LSTM -- Follow Along"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWrQllf8WEd-"
      },
      "source": [
        "_____________\n",
        "\n",
        "RNNs and LSTMs are great for modeling any kind of data that comes in ordered sequences. <br>\n",
        "There are an astonishing variety of sequences in our world, such as\n",
        "* words in a document\n",
        "* musical notes or chords in a song\n",
        "* sounds in an audio recording\n",
        "* daily stock prices\n",
        "* DNA base pairs\n",
        "* medical sensor time series data, such as voltage measurements in an EKG\n",
        "* etc.!<br>\n",
        "\n",
        "Can you think of other examples of sequence data?<br>\n",
        "\n",
        "To illustrate the power of Neural Networks for modeling sequences,<br>\n",
        "we'll focus on text data, and apply LSTMs to a simple sentiment classification task.<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESoxKIrKkd_w"
      },
      "source": [
        "The [Internet Movie Database (IMDb)](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb/load_data) is a database of movie reviews in text format, along with the sentiment label(positive or negative), coresponding to each review.\n",
        "\n",
        "The movie review labels are binary:\n",
        "* $1 \\rightarrow$ the review expresses positive sentiment\n",
        "* $0 \\rightarrow$ the review expresses negative sentiment\n",
        "\n",
        "In this exercise, we will train a **sentiment classification** model that can predict from the text whether a movie review is \"thumbs-up\" or \"thumbs-down\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Ti23G0gRe3kr"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Bidirectional\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.datasets import imdb\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bt77ZoUo9uCD",
        "outputId": "4c3486d8-235d-4840-b62c-a491af6ca9c5",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "25000 train sequences\n",
            "25000 test sequences\n"
          ]
        }
      ],
      "source": [
        "# load in dataset\n",
        "\n",
        "# maximum number of words in vocab\n",
        "max_features = 20000\n",
        "\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68GZlbBc3B_u"
      },
      "source": [
        "#### What does the IMDb data look like?\n",
        "The data is a list of reviews<br>\n",
        "Each review has been transformed to a list of numerical word encodings.<br>\n",
        "Each review may have a different number of words.<br>\n",
        "The number of words in our vocabulary is 20000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OE0AUO-Lz5c6",
        "outputId": "04884de3-9272-4211-9406-d8c1b6205ef5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(25000,)\n",
            "<class 'list'>\n",
            "218\n",
            "145\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
              "       list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
              "       list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
              "       ...,\n",
              "       list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 2, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 14532, 325, 725, 134, 15271, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 11656, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 2, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 17793, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 14492, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 17793, 5, 27, 710, 117, 2, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 17793, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 17793, 7750, 5, 4241, 18, 4, 8497, 13164, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 11027, 4, 3586, 2]),\n",
              "       list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 2, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 2, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 11418, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
              "       list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 12815, 270, 14437, 5, 16923, 12255, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 16553, 21, 27, 9685, 6139, 5, 2, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 2, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 2, 10755, 544, 5, 383, 1271, 848, 1468, 12183, 497, 16876, 8, 1597, 8778, 19280, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "print(type(x_train))\n",
        "print(x_train.shape)\n",
        "print(type(x_train[0]))\n",
        "print(len(x_train[0]))\n",
        "print(len(x_train[101]))\n",
        "x_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfJW79LhngHr"
      },
      "source": [
        "Here are the first 80 word indexes for the (numerically encoded) first review"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lg1Ydf44DIVI",
        "outputId": "9bcc7a13-7a40-4e0c-af0f-344e41e18579"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 14,\n",
              " 22,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 973,\n",
              " 1622,\n",
              " 1385,\n",
              " 65,\n",
              " 458,\n",
              " 4468,\n",
              " 66,\n",
              " 3941,\n",
              " 4,\n",
              " 173,\n",
              " 36,\n",
              " 256,\n",
              " 5,\n",
              " 25]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "x_train[0][:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73hiyEIh0rat"
      },
      "source": [
        "### What's are the lengths of the longest and shortest reviews in the training set?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "AmL0E8RhSVtL"
      },
      "outputs": [],
      "source": [
        "review_lengths = [len(x_train[i]) for i in range(len(x_train))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "O2EZdLW5SfAP",
        "outputId": "f762cfc7-c626-49e2-a143-7bc9c44a7d17"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.hist(review_lengths);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8tSZcLO0YcF",
        "outputId": "aa31f0af-448b-4fee-9c76-25aab3350303"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "longest review is 2494 words\n",
            "shortest review is 11 words\n",
            "median review length 178.0 words\n"
          ]
        }
      ],
      "source": [
        "print(f'longest review is { np.max( review_lengths ) } words')\n",
        "print(f'shortest review is { np.min( review_lengths ) } words')\n",
        "print(f'median review length { np.median( review_lengths ) } words')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcVrMKe1k5UI"
      },
      "source": [
        "### Truncating and padding the reviews to the same length\n",
        "We will standardize the length of our movie reviews to `maxlen = 80` words<br>\n",
        "The `pad_sequences` method from `tensorflow.keras.preprocessing.sequence` <br>\n",
        "provides a convenient way to accomplish this task\n",
        "* Reviews longer than `maxlen` will be **truncated** to the first `maxlen` words\n",
        "* Reviews shorter than `maxlen` will be **padded** with zeros at the beginning to increase their length to `maxlen`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0awRJCnIM2G",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-fb23c1d7d1168a73",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "outputId": "199dffd7-49ac-47e0-925d-f50c43fa8853"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pad or truncate sequences to a length of 80\n",
            "x_train shape:  (25000, 80)\n",
            "x_test shape:  (25000, 80)\n"
          ]
        }
      ],
      "source": [
        "maxlen = 80\n",
        "print(f'Pad or truncate sequences to a length of {maxlen}')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen, padding='pre', truncating = 'post')\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen, padding='pre', truncating = 'post')\n",
        "print('x_train shape: ', x_train.shape)\n",
        "print('x_test shape: ', x_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z78PHr5yFOeB"
      },
      "source": [
        "#### each review is truncated to the first 80 words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrwFDoliEJMd",
        "outputId": "4eb0117b-d17f-41a2-ccb8-56bfb13d7877"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   1,   14,   22,   16,   43,  530,  973, 1622, 1385,   65,  458,\n",
              "       4468,   66, 3941,    4,  173,   36,  256,    5,   25,  100,   43,\n",
              "        838,  112,   50,  670,    2,    9,   35,  480,  284,    5,  150,\n",
              "          4,  172,  112,  167,    2,  336,  385,   39,    4,  172, 4536,\n",
              "       1111,   17,  546,   38,   13,  447,    4,  192,   50,   16,    6,\n",
              "        147, 2025,   19,   14,   22,    4, 1920, 4613,  469,    4,   22,\n",
              "         71,   87,   12,   16,   43,  530,   38,   76,   15,   13, 1247,\n",
              "          4,   22,   17], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "x_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WeUXgQF2uht"
      },
      "source": [
        "#### The \"labels\" (or \"targets\") are classes -- 0 for negative reviews and 1 for positive reviews."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1GFlKzck5zW",
        "outputId": "93b76ce6-858d-4c13-d3d1-205591d71e52"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "np.unique(y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZFdt-TB9uCF"
      },
      "source": [
        "### Build a LSTM language model with 1 hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "QD_NjHw-pcJS",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-9c285c5d84213905",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "outputId": "e2f78019-f8bd-4ea7-ec61-3412ef47727e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# build a 1 layer LSTM language model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "max_features = 80\n",
        "# specify learning rate and optimizer\n",
        "opt = Adam(learning_rate=1.e-7)\n",
        "\n",
        "# as usual, we begin to build our model by instantiating a Sequential class\n",
        "model = Sequential()\n",
        "\n",
        "# input layer\n",
        "# adding an Embedding layer\n",
        "model.add(Embedding(input_dim=max_features, output_dim=128))\n",
        "\n",
        "# hidden layer 1\n",
        "model.add(LSTM(128, return_sequences=False))\n",
        "\n",
        "# output layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJCNhjvB7LX4"
      },
      "source": [
        "Each numerical word index has dimension of 20,000 when one-hot-encoded.<br>\n",
        "The embedding layer has no bias, and produces a 128 dimensional embedding vector for each word. There are 20,000 inputs and 128 outputs, so the number of weights is 20,000 * 128 = 2,560,000 weights,<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dioHuVz-jObs"
      },
      "source": [
        "### Use a learning rate schedule [callback](https://) to find the best learning rate!\n",
        "Note that for this part, we don't need to pass the `test` data to the `fit` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63yPeX0VhXp-",
        "outputId": "af4d417a-5d90-4bd4-f151-bb37ec9f9e0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.4980 - loss: 0.6932 - learning_rate: 1.0000e-05\n",
            "Epoch 2/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5348 - loss: 0.6908 - learning_rate: 3.1623e-05\n",
            "Epoch 3/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.6368 - loss: 0.6434 - learning_rate: 1.0000e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.6425 - loss: 0.6351 - learning_rate: 3.1623e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6349 - loss: 0.6401 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5691 - loss: 0.6798 - learning_rate: 0.0032\n",
            "Epoch 7/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.5762 - loss: 0.6729 - learning_rate: 0.0100\n",
            "Epoch 8/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5829 - loss: 0.6718 - learning_rate: 0.0316\n",
            "Epoch 9/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.5057 - loss: nan - learning_rate: 0.1000\n",
            "Epoch 10/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5040 - loss: nan - learning_rate: 0.3162\n",
            "CPU times: user 1min 4s, sys: 3.76 s, total: 1min 8s\n",
            "Wall time: 1min 2s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# about 5 or 6 sec per epoch on Colab GPU\n",
        "# specify batch size\n",
        "batch_size = 32\n",
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
        "     lambda epoch: 1e-5 * 10**(epoch/2))\n",
        "results_one_layer = model.fit(x_train, y_train,\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=10, callbacks=[lr_schedule])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuU0hmobsfUX"
      },
      "source": [
        "Backing off by by a factor of 10 from where the loss surface is unstable, we choose 1.e-4 as the best learning rate."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_one_layer.history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5byRuP_Fkf1",
        "outputId": "261f50c0-1abf-4c97-8ba5-c27626df88f5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.5047199726104736,\n",
              "  0.5601599812507629,\n",
              "  0.6379200220108032,\n",
              "  0.6418799757957458,\n",
              "  0.6330000162124634,\n",
              "  0.5510799884796143,\n",
              "  0.5876799821853638,\n",
              "  0.5846800208091736,\n",
              "  0.5039200186729431,\n",
              "  0.5],\n",
              " 'loss': [0.693130373954773,\n",
              "  0.6815249919891357,\n",
              "  0.6382235884666443,\n",
              "  0.6337143182754517,\n",
              "  0.6393383741378784,\n",
              "  0.6850616931915283,\n",
              "  0.6654000878334045,\n",
              "  0.671859622001648,\n",
              "  nan,\n",
              "  nan],\n",
              " 'learning_rate': [9.999999747378752e-06,\n",
              "  3.162277789670043e-05,\n",
              "  9.999999747378752e-05,\n",
              "  0.0003162277571391314,\n",
              "  0.0010000000474974513,\n",
              "  0.003162277629598975,\n",
              "  0.009999999776482582,\n",
              "  0.03162277489900589,\n",
              "  0.10000000149011612,\n",
              "  0.3162277638912201]}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "yVpTOFgAiXBN",
        "outputId": "d66ae3ff-f5d1-4d59-8072-ad0fde8a7ed9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.semilogx(results_one_layer.history[\"learning_rate\"], results_one_layer.history[\"loss\"])\n",
        "plt.axis([1e-5, 1e-1, 0, 1])\n",
        "plt.xlabel('learning rate')\n",
        "plt.ylabel('loss')\n",
        "plt.grid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kREzYX8sL7G"
      },
      "source": [
        "Build the LSTM with the learning rate set to 1.e-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "FUGjJpuxjxNY",
        "outputId": "78aca3cf-80c4-4a81-8e5c-d13bb2712771"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_6 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# build a 1 layer LSTM language model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# specify learning rate and optimizer\n",
        "opt = Adam(learning_rate=1.e-4)\n",
        "\n",
        "###BEING SOLUTION\n",
        "# as usual, we begin to build our model by instantiating a Sequential class\n",
        "model = Sequential()\n",
        "\n",
        "# input layer\n",
        "# we are explicitly declaring the dimension of the input layer here by adding an Embedding object\n",
        "# this is for the one-hot encoding of the numerical indices\n",
        "model.add(Embedding(max_features, 128))\n",
        "\n",
        "# hidden layer 1\n",
        "model.add(LSTM(128, return_sequences=False))\n",
        "\n",
        "# output layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "model.summary()\n",
        "###END SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrY7mat_sZaF"
      },
      "source": [
        "Fit the LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQAKkBGd9uCF",
        "outputId": "f94d68f9-2dee-4fce-a98c-e1add0dcc4b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.5152 - loss: 0.6930 - val_accuracy: 0.5417 - val_loss: 0.6923\n",
            "Epoch 2/10\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5540 - loss: 0.6914 - val_accuracy: 0.6007 - val_loss: 0.6680\n",
            "Epoch 3/10\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6111 - loss: 0.6558 - val_accuracy: 0.6237 - val_loss: 0.6425\n",
            "Epoch 4/10\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6370 - loss: 0.6342 - val_accuracy: 0.6345 - val_loss: 0.6349\n",
            "Epoch 5/10\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6434 - loss: 0.6265 - val_accuracy: 0.6406 - val_loss: 0.6302\n",
            "Epoch 6/10\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6493 - loss: 0.6212 - val_accuracy: 0.6436 - val_loss: 0.6285\n",
            "Epoch 7/10\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6434 - loss: 0.6217 - val_accuracy: 0.6435 - val_loss: 0.6276\n",
            "Epoch 8/10\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.6508 - loss: 0.6213 - val_accuracy: 0.6438 - val_loss: 0.6267\n",
            "Epoch 9/10\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.6423 - loss: 0.6252 - val_accuracy: 0.6422 - val_loss: 0.6266\n",
            "Epoch 10/10\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6473 - loss: 0.6227 - val_accuracy: 0.6424 - val_loss: 0.6307\n",
            "CPU times: user 9.57 s, sys: 806 ms, total: 10.4 s\n",
            "Wall time: 16.1 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# number of epochs\n",
        "n_epochs = 10\n",
        "batch_size = 512\n",
        "\n",
        "results_one_layer = model.fit(x_train, y_train,\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=n_epochs,\n",
        "                      validation_data=(x_test,y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZQj7QXr9uCG"
      },
      "source": [
        "### Build a 1 hidden layer Bidirectional LSTM language model\n",
        "\n",
        "A Bidirectional LSTM, or biLSTM, is a sequence processing model that consists of two LSTMs: **one taking the input in a forward direction**, and **the other in a backwards direction**. BiLSTMs effectively increase the amount of information available to the network, improving the context available to the algorithm (e.g. knowing what words immediately follow and precede a word in a sentence).\n",
        "\n",
        "![](https://miro.medium.com/max/764/1*6QnPUSv_t9BY9Fv8_aLb-Q.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "cKyGb4TzIM2O",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-706b7be103484984",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "outputId": "7e56539c-37a6-4652-efd9-c0cd603a4ced"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_7 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# build a 1 layer Bidirectional LSTM language model\n",
        "\n",
        "###BEGIN SOLUTION\n",
        "# as usual, we begin to build our model by instantiating a Sequential class\n",
        "model = Sequential()\n",
        "\n",
        "# input layer 1\n",
        "# we are explicitly declaring the input layer here by adding an Embedding object\n",
        "model.add(Embedding(max_features, 128))\n",
        "\n",
        "# hidden layer 1\n",
        "model.add(Bidirectional(LSTM(128, return_sequences=False)))\n",
        "\n",
        "# output layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "###END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3E-lL5kB9uCH",
        "outputId": "251e3ea7-2ad6-4654-ac8d-8738f7fca499"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - accuracy: 0.5464 - loss: 0.6782 - val_accuracy: 0.6330 - val_loss: 0.6359\n",
            "Epoch 2/10\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 46ms/step - accuracy: 0.6426 - loss: 0.6269 - val_accuracy: 0.6433 - val_loss: 0.6297\n",
            "Epoch 3/10\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.6474 - loss: 0.6265 - val_accuracy: 0.6468 - val_loss: 0.6254\n",
            "Epoch 4/10\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.6495 - loss: 0.6192 - val_accuracy: 0.6390 - val_loss: 0.6277\n",
            "Epoch 5/10\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.6574 - loss: 0.6175 - val_accuracy: 0.6471 - val_loss: 0.6254\n",
            "Epoch 6/10\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.6569 - loss: 0.6121 - val_accuracy: 0.6464 - val_loss: 0.6231\n",
            "Epoch 7/10\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.6610 - loss: 0.6093 - val_accuracy: 0.6428 - val_loss: 0.6284\n",
            "Epoch 8/10\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.6617 - loss: 0.6069 - val_accuracy: 0.6482 - val_loss: 0.6216\n",
            "Epoch 9/10\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.6627 - loss: 0.6058 - val_accuracy: 0.6474 - val_loss: 0.6226\n",
            "Epoch 10/10\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.6572 - loss: 0.6107 - val_accuracy: 0.6473 - val_loss: 0.6231\n",
            "CPU times: user 13 s, sys: 1.08 s, total: 14.1 s\n",
            "Wall time: 27.5 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "results_biLSTM = model.fit(x_train, y_train,\n",
        "                      batch_size=512,\n",
        "                      epochs=n_epochs,\n",
        "                      validation_data=(x_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "RZx3Zs7tIM2Q",
        "outputId": "9fa0f1b8-580a-4967-ecaf-ae80e5ffc66d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot training & validation loss values\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epoch_list = np.arange(1,n_epochs+1)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.grid()\n",
        "plt.xticks(epoch_list)\n",
        "# results for 1-layer lstm model\n",
        "plt.plot(epoch_list, results_one_layer.history['loss'], \"--\", label=\"1 layer LSTM Train\")\n",
        "plt.plot(epoch_list, results_one_layer.history['val_loss'], \"--\", label = \"1 layer LSTM Test\")\n",
        "\n",
        "# results for bi-lstm model\n",
        "plt.plot(epoch_list, results_biLSTM.history['loss'], label=\"1 layer biLSTM Train \")\n",
        "plt.plot(epoch_list, results_biLSTM.history['val_loss'], label = \"1 layer biLSTM Test\")\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9Ps3CauIM2S"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "You will be expected to use an Keras LSTM for a classicification task on the *Sprint Challenge*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pETWPIe362y"
      },
      "source": [
        "--------\n",
        "# 3. LSTM Text generation with Keras (Learn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeG4BPnJ9uCI"
      },
      "source": [
        "Using sequential models to generate text data is an application of recursive deep learning models. A couple of applications are [**chat bots**](https://hackernoon.com/deep-learning-chatbot-everything-you-need-to-know-r11jm30bc) and language translators such as [**google translate**](https://ai.googleblog.com/2020/06/recent-advances-in-google-translate.html).\n",
        "\n",
        "In order to properly build a chat bot or translater you need to use multiple lstm models in an encoder & decoder framework known as a [**sequence 2 sequence model**](https://keras.io/examples/nlp/lstm_seq2seq/) .\n",
        "\n",
        "\n",
        "![](https://jeddy92.github.io/images/ts_intro/seq2seq_lang.png)\n",
        "\n",
        "Also, now a days, using a standard LSTM isn't enough. You also have to use a version of lstm seq2seq models known as [**transformers**](https://towardsdatascience.com/transformers-141e32e69591). Transformers give seq2seq models the capacity to pay attention to specific portions of the input sequence, the most relevent portion in order to make a prediction. Yes, that's right, humanity has figured out how to convert attention into an algorithm. Next stop, self-awareness!\n",
        "\n",
        "The above mentions of sequence 2 sequence models and transformers are for a larger contextual understanding of the landscape of language models and how LSTMs fit into this landscape. Although **we will cover the encoder/decoder framework in a future lesson, transformers are outside the scope of Unit 4**. However, once you learn about LSTMs and encoder/decoder frameworks, you will have all necessary information to then go on and learn about transformers on your own. At that point, the only really new bit you'll be learning is the [**attention mechanism**](https://towardsdatascience.com/intuitive-understanding-of-attention-mechanism-in-deep-learning-6c9482aecf4f).\n",
        "\n",
        "\n",
        "As a first pass at text generation, we'll stick to standard LSTM models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BK-GrUGvIM2T"
      },
      "source": [
        "-----\n",
        "# Text Generation using LSTMs\n",
        "\n",
        "What else can we do with LSTMs? Since we're analyzing the *sequence*, we can do more than classify - we can *generate* text. <br>\n",
        "For this exercise, we'll use BBC news articles from the [newspaper](https://github.com/codelucas/newspaper/)  database.\n",
        "\n",
        "This example is drawn from the Keras [documentation](https://keras.io/examples/lstm_text_generation/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q64qHEYIIM2U",
        "outputId": "0541a1ad-efa6-44f8-a76f-b4ac6e0f4686"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-30 19:43:42--  https://raw.githubusercontent.com/LambdaSchool/DS-Unit-4-Sprint-3-Deep-Learning/main/module1-rnn-and-lstm/data_cleaning_toolkit_class.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6661 (6.5K) [text/plain]\n",
            "Saving to: ‘data_cleaning_toolkit_class.py’\n",
            "\n",
            "\r          data_clea   0%[                    ]       0  --.-KB/s               \rdata_cleaning_toolk 100%[===================>]   6.50K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-09-30 19:43:42 (116 MB/s) - ‘data_cleaning_toolkit_class.py’ saved [6661/6661]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# import a custom text data preparation class\n",
        "!wget https://raw.githubusercontent.com/LambdaSchool/DS-Unit-4-Sprint-3-Deep-Learning/main/module1-rnn-and-lstm/data_cleaning_toolkit_class.py\n",
        "from data_cleaning_toolkit_class import data_cleaning_toolkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MxcXsdsSIM2W",
        "outputId": "57c218fd-37b4-4516-f0df-ad351c95089c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             article\n",
              "0  Contributing columnist\\n\\nThe House is on fire...\n",
              "1  When President Trump announced his decision to...\n",
              "2  Nature teases us today with some flirtatious s...\n",
              "3  \\n\\nSTOCK IMAGE: Medicare application form wit...\n",
              "4  The problem of sleeping in knows no cultural, ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8678ba3b-2d93-4b07-ad41-d99ae77d51b7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Contributing columnist\\n\\nThe House is on fire...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>When President Trump announced his decision to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Nature teases us today with some flirtatious s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\n\\nSTOCK IMAGE: Medicare application form wit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The problem of sleeping in knows no cultural, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8678ba3b-2d93-4b07-ad41-d99ae77d51b7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8678ba3b-2d93-4b07-ad41-d99ae77d51b7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8678ba3b-2d93-4b07-ad41-d99ae77d51b7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-44585a54-7a5b-4f59-8df2-88e518c0a6d2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-44585a54-7a5b-4f59-8df2-88e518c0a6d2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-44585a54-7a5b-4f59-8df2-88e518c0a6d2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 136,\n  \"fields\": [\n    {\n      \"column\": \"article\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 126,\n        \"samples\": [\n          \"Much of China\\u2019s chapters over the past seven decades can seem very remote and disconnected from today\\u2019s economic powerhouse \\u2014 black-and-white images of grinding poverty where there are now food delivery apps; the groundbreaking visit of President Richard M. Nixon in 1972 to Beijing, which is now home to many Western brands. But not everything has changed.\",\n          \"He shipped out in the spring of 1944 for Europe, making his way from Normandy in the wake of the D-Day invasion to the Netherlands and then, by winter, to the Ardennes region of Belgium. There, as a 19-year-old private first class during the Battle of the Bulge, the infantryman was credited with almost single-handedly holding back a German attack on the town of Malmedy.\\n\\nFor his actions \\u2014 heralded days later in a New York Times account reporting that he had \\u201chelped immobilize three German tanks, wiped out a house full of Nazis, rescued six of his trapped buddies and saved five wounded men\\u201d \\u2014 Mr. Currey, who attained the rank of sergeant before completing his service, received the Medal of Honor, the military\\u2019s highest decoration. He died Oct. 8 at his home in Selkirk, N.Y.\\n\\nAD\\n\\nAD\\n\\nHe was 94 and had congestive heart failure, said his daughter, Kathryn Domery.\\n\\nMr. Currey\\u2019s Medal of Honor \\u2014 which he received on July 27, 1945, after the Allied victory in Europe and just before the defeat of Japan \\u2014 was one of 472 awarded for service during World War II, according to the Congressional Medal of Honor Society.\\n\\nHis death leaves two living honorees from that conflict: Charles Coolidge, 98, who was recognized for his actions as an Army technical sergeant in France in the fall of 1944, and Hershel \\u201cWoody\\u201d Williams, 96, recognized for his bravery as a Marine Corps corporal at Iwo Jima in the Pacific.\\n\\nMr. Currey, who was 6 feet tall but only 130 pounds, found himself at the heart of the Battle of the Bulge, the last major German offensive of World War II and a bloody affair resulting in 80,000 American and 100,000 German casualties. The town of Malmedy became infamous as the site of a massacre by Waffen-SS troops of more than 80 U.S. soldiers who had been forced to surrender at the start of the battle.\\n\\nAD\\n\\nAD\\n\\nNotable deaths in 2019: Ric Ocasek, Valerie Harper, Ross Perot, Toni Morrison, and others we have lost this year share Share Email this link Share on Pinterest Share on LinkedIn View Photos View Photos Next Image Ginger Baker, the prodigiously talented and volcanically temperamental rock drummer who helped form Cream, rock-and-roll\\u2019s first supergroup, and inspired awe and imitation in a generation of drummers, died Oct. 6 at 80. Read the obituary (Mj Kim/AP)\\n\\nFour days after the massacre, at about 4 a.m. on Dec. 21, 1944, Mr. Currey was in a foxhole when \\u201ca German armored column spearheaded by captured American tanks rolled out of the heavy mist,\\u201d the Times reported, overpowering an American antitank unit and surrounding Mr. Currey and several other soldiers.\\n\\nTaking shelter in an abandoned paper factory, the American soldiers discovered a bazooka but no ammunition. Mr. Currey left the building and, while completely exposed to enemy fire, ran to a supply of ammunition across the street to load the bazooka. With another soldier, he shot at a German tank.\\n\\n\\u201cBy what he would later call a miracle, the rocket hit the exact spot where the turret joined the chassis and disabled the vehicle,\\u201d reads an account in the book \\u201cMedal of Honor: Portraits of Valor Beyond the Call of Duty.\\u201d\\n\\nAD\\n\\nAD\\n\\nMr. Currey then turned his attention to a German-held stone house, firing with an automatic rifle on three enemy soldiers. \\u201cI got all three with one good burst,\\u201d he told the Times, \\u201cthen, while the other fellows in the factory covered me, I stood up in plain sight and knocked down half a wall of that house with the bazooka.\\n\\n\\u201cWhen I stood up,\\u201d he continued, \\u201cI saw a number of our guys trapped in a small hole between me and the house. They had been held down there for hours and asked me to help them out.\\u201d\\n\\nIn a desperate effort to rescue them, he obtained grenades, which he used to attack the house and German tanks threatening the Americans. When the grenades ran out, he continued firing on the Germans with machine guns.\\n\\nAD\\n\\n\\u201cUnder his covering fire the 5 soldiers were able to retire to safety,\\u201d reads the citation for his Medal of Honor. \\u201cDeprived of tanks and with heavy infantry casualties, the enemy was forced to withdraw. Through his extensive knowledge of weapons and by his heroic and repeated braving of murderous enemy fire, Sgt. Currey was greatly responsible for inflicting heavy losses in men and material on the enemy, for rescuing 5 comrades, 2 of whom were wounded, and for stemming an attack which threatened to flank his battalion\\u2019s position.\\u201d\\n\\nAD\\n\\nReflecting on his actions, he told the Times-Union newspaper of Albany, N.Y., decades later, \\u201cIt was just one day of nine months of steady combat.\\u201d\\n\\nFrancis Sherman Currey was born on June 29, 1925, in Loch Sheldrake, N.Y., and grew up with his foster parents in nearby Hurleyville.\\n\\nAD\\n\\nAfter joining the Army, he completed Officer Candidate School training, but it was decided, according to \\u201cMedal of Honor,\\u201d that he was \\u201ctoo immature\\u201d for a commission, an irony not lost on those who chronicled his deeds at Malmedy.\\n\\n\\u201cWe were all teenagers, the oldest one was maybe twenty-one years old, and I was the one with all the training,\\u201d he said in the book \\u201c Voices of the Bulge \\u201d by Michael Collins and Martin King. \\u201cI knew what I was doing, since I had been in training the year before.\\u201d\\n\\nBesides the Medal of Honor, his military decorations included the Silver Star, the Bronze Star Medal and three awards of the Purple Heart.\\n\\nAD\\n\\nAfter the war, Mr. Currey worked as a benefits counselor at a veterans hospital in Albany, N.Y., and ran a landscaping business.\\n\\nAD\\n\\nSurvivors include his wife of 70 years, the former Wilma French, of Selkirk; three children, Michael Currey and Kathryn Domery, both of Selkirk, and Jonathan Currey of Dudley, Mass.; seven grandchildren; and 12 great-grandchildren.\\n\\nDecades after the war, Mr. Currey became the first Medal of Honor recipient to be represented as a G.I. Joe action figure. However, he preferred not to seek attention for his recognition. \\u201cI got it; that\\u2019s all,\\u201d he told the Times-Union of Albany in 2013. \\u201cI don\\u2019t make a big issue out of it.\\u201d\\n\\nRead more Washington Post obituaries\\n\\nAD\",\n          \"\\n\\nPaul Farrell, a West Virginia attorney driving a massive lawsuit against drug companies. (Maddie McGarvey/For The Washington Post)\\n\\nPaul Farrell, Jr. was looking through the West Virginia Code a few years ago when he came across a statute saying a county has the legal right to abate a \\u201cpublic nuisance.\\u201d Typically, that would mean things like trash heaps in someone\\u2019s front yard.\\n\\nBut Farrell decided it might also describe prescription opioids.\\n\\nFarrell is a small-city lawyer in a place often described as the epicenter of the opioid crisis. His hometown has been flooded by pills \\u2014 \\u201ca tsunami,\\u201d he says. A thousand people have died of drug overdoses here in less than two decades.\\n\\nSo Farrell, 47, made a federal case out of the catastrophe. He\\u2019s now one of three lead attorneys in the national prescription opioid litigation, the biggest and most complicated civil case in U.S. history.\\n\\nThe first courtroom showdown is set to begin next week in federal court in Cleveland. Farrell won\\u2019t argue the case before the jury. Instead, he\\u2019s one of the backstage masterminds of the litigation, which now includes more than 2,600 communities. The plaintiffs argue that the nation\\u2019s biggest drug companies \\u2014 manufacturers, distributors and retailers \\u2014 recklessly peddled opioid painkillers and fueled a wave of addiction.\\n\\nThe public nuisance strategy he helped craft has the advantage of requiring abatement \\u2014 meaning the drug companies could be required to pour billions of dollars into communities across the nation that have been devastated by the epidemic.\\n\\n\\u201cThey broke it. So they need to fix it,\\u201d Farrell said of the drug companies. \\u201cI want them to stop killing people. I want mothers to stop giving birth to babies addicted to opium. I want my friends and my friends\\u2019 children to stop overdosing. I want to stop going to funerals.\\u201d\\n\\n[Follow The Post\\u2019s investigation of the opioid epidemic]\\n\\nFarrell is built like a wrestler, and his head has a severe boot-camp buzz cut, which, combined with his blunt speech, adds extra punch to comments like \\u201cI am on the war front\\u201d and \\u201cI\\u2019m going to crucify the chain store dispensers.\\u201d\\n\\nFarrell represents hundreds of municipalities, having aggressively signed up clients, including Cabell County, of which Huntington is the county seat. He and the other plaintiffs\\u2019 attorneys are working on a contingency fee basis, meaning they don\\u2019t get paid anything if they lose in court.\\n\\nThat\\u2019s been financially hard, Farrell said, and he\\u2019s not sure exactly how he and his fellow litigators would ultimately be paid -- because there\\u2019s never been a case quite like this. But in discussing the case, he tends to talk about his hometown. For him, this big lawsuit is personal.\\n\\n\\u201cWhat you see is the shell of the former glory and beauty of the town I grew up with,\\u201d Farrell said.\\n\\nA city's resilience\\n\\n\\n\\nMarcum Terrace, a Huntington public housing complex that has been the site of many overdoses. (Maddie McGarvey/For The Washington Post)\\n\\nHuntington is intimately acquainted with tragedy. The mayor, Steve Williams, keeps a framed photograph on the wall of his office, directly behind his desk so that anyone speaking to him will see it. It\\u2019s the 1970 Marshall University football team.\\n\\nOn Nov. 14 of that year, a chartered DC-9 airplane carrying the team home from an away game crashed into a hillside nearly a mile short of the Huntington airport runway. The pilots had misjudged their altitude, possibly due to instrumentation malfunction. All 75 people aboard \\u2014 including players, coaches and many prominent citizens who were boosters of the local team \\u2014 perished.\\n\\nThat remains the deadliest aviation accident in U.S. sports history. It also remains very much on the minds of the citizens of Huntington. In interviews, public officials often cite the crash when speaking about the city\\u2019s resilience. They say they had to learn to hold up one another in hard times.\\n\\nOpioid pills became popular in the late 1990s, after the medical community embraced pain as the \\u201cfifth vital sign\\u201d and Purdue Pharma introduced its powerful, slow-release painkiller OxyContin, which the company marketed as less likely to be addictive or abused. People became addicted, and pills became street drugs. When the authorities cracked down, heroin came to town. Then came illicit fentanyl, which was cheaper, more powerful and even deadlier than heroin.\\n\\nFatal overdoses jumped dramatically starting early in this decade. At the peak year of the epidemic, in 2017, Cabell County \\u2014 population 96,000 \\u2014 experienced 203 fatal drug overdoses.\\n\\nLocal leaders are sensitive to Huntington\\u2019s image. They point to progress in the past two years: Deaths are down, overdoses are down. A \\u201charm reduction program\\u201d based out of the health department distributes clean needles for intravenous drug users, along with naloxone to combat overdoses. The community has opened a walk-in clinic for people actively using drugs and seeking help. A new program offers residential treatment for women with children or who are pregnant.\\n\\n\\u201cWe are no longer the epicenter of the epidemic. We are the city of solutions,\\u201d says Lyn O\\u2019Connell, who helps run a new division of addiction sciences at the Marshall University School of Medicine.\\n\\nFarrell and his allies in the big lawsuit envision the drug companies funneling money to places like Huntington over many decades to deal with addiction and recovery.\\n\\nThe Huntington police chief, Hank Dial, noted that violent crime has dropped 26 percent in the past year, and drug use is down. But there\\u2019s a grim reason for that: So many drug users are dead now.\\n\\n\\u201cI\\u2019m not hanging up a Mission Accomplished banner yet because we\\u2019re still at war here,\\u201d Dial said.\\n\\n'I choose to fight back'\\n\\n\\n\\nFarrell prepares to present the latest on the lawsuits to the country commission in Huntington. (Maddie McGarvey/For The Washington Post)\\n\\nPaul Farrell Sr. is a county circuit court judge here. He says of his son, \\u201cHe\\u2019s playing in the big leagues now.\\u201d Asked to describe his namesake, the judge says, \\u201cAggressive. Smart. Focused. And the last two years of his life, this\\u201d \\u2014 the opioids litigation \\u2014 \\u201chas been all-consuming.\\u201d\\n\\nThere are a lot of Farrells here in Huntington. There\\u2019s a Farrell Building downtown. Back in the 1990s and early 2000s the building was the headquarters of Farrell, Farrell & Farrell, a law firm run by Paul Sr., who had not yet been appointed to the bench, and his brothers Mike and Joe. Paul Jr., a graduate of Notre Dame and West Virginia University School of Law, decided to strike out on his own rather than be part of the family firm, because, he says, \\u201cA whole bunch of Farrells had to die before I could be in charge.\\u201d\\n\\nPaul Jr. is not without ambition. He even ran for president of the United States \\u2014 sort of. In 2016, he paid $2,500 to have his name on the ballot for the Democratic primary in West Virginia. He said he couldn\\u2019t support either Hillary Clinton or Bernie Sanders because of their position on coal.\\n\\n\\u201cYou cannot shut down our coal mines, brag about it on the campaign trail and then expect me to vote for you,\\u201d Farrell wrote in an op-ed explaining his quixotic candidacy. \\u201cWin or lose, I choose to fight back.\\u201d He got a respectable number of votes in coal country and boasts that he came close to the number that would have given him three delegates to the national convention.\\n\\nNow he\\u2019s taken on something even more challenging than a presidential race. Among the uncertainties in recent weeks has been who, exactly, will wind up in court if and when the trial begins. Judge Polster has urged the parties to reach a settlement. Purdue Pharma has reached a tentative settlement with the federal court plaintiffs as well as a group of state attorneys general. Johnson & Johnson recently settled with the two Ohio counties that are part of the first bellwether case. The pharmacy companies were excluded from this trial track. Left standing are major drug distributors, including McKesson, Cardinal Health and AmeriSource Bergen.\\n\\nA second bellwether trial is planned, with Huntington and Cabell County as the plaintiffs. That\\u2019s Farrell\\u2019s trial, in a sense, because it\\u2019ll be on his home turf \\u2014 in the federal courthouse, a short walk from the Farrell Building and from the county courthouse where Judge Farrell has his chambers.\\n\\n\\n\\nThe courthouse in Huntington, where Paul Farrell Jr.\\u2019s father, a judge, has his chambers. (Maddie McGarvey/For The Washington Post)\\n\\nFarrell vows to make that second trial more down-to-earth than the first one. The first one will feature a lot of academic experts, he said. But when the trial comes to Huntington, he wants to call to the stand a string of doctors, nurses, police officers, paramedics, firefighters and other first responders.\\n\\nIt might never happen, though. The companies could settle.\\n\\nThere have been other attempts to derail the Cleveland trial. The attorney general of Ohio, Dave Yost, petitioned a federal appeals court to halt the trial, arguing that the states, not the municipalities, should have jurisdiction over the lawsuits and any subsequent distribution of money.\\n\\nYost\\u2019s last-minute effort infuriated Farrell, who along with other attorneys has spent a couple of years amassing evidence and preparing for trial.\\n\\n\\u201cThey can\\u2019t call me off,\\u201d he said. \\u201cThis entire thing is no longer about the responsibility of the defendants, or even about the amount of money they\\u2019re going to pay. The fight right now is who gets to control the money.\\u201d\\n\\nOn Thursday the appeals court ruled against Yost, and the Cleveland trial is a go.\\n\\nThe trial is near\\n\\nJudge Farrell \\u2014 who still makes pancakes for his three sons every Sunday morning \\u2014 said that 90 percent of the criminal cases he sees are related to drugs.\\n\\n\\u201cDo you want your drugs, or the kids?\\u201d he recalls asking mothers who are in his courtroom. And sometimes, he said, the answer is \\u201cI want the drugs.\\u201d\\n\\nThe fire chief, Jan Rader, who gained renown in the documentary \\u201cHeroin(e),\\u201d was also in the judge\\u2019s office, along with Paul Jr. She described the compassion fatigue that has taken a toll on her first responders. They\\u2019ve all gotten good at using naloxone to revive people who have overdosed. But they become jaded when they see the same people overdosing repeatedly.\\n\\n\\u201cA firefighter is a hero. They\\u2019re trained to make a situation better. They have the tools to put out a fire. They have the tools and the knowledge to cut somebody out of a car,\\u201d Rader said. \\u201cThey do not have the tools and knowledge to save somebody long-term who is suffering from substance use disorder.\\u201d\\n\\nPaul Jr. told the story of a young woman who as a girl played sports with his kids. She\\u2019d been on and off the drugs. Her grandfather called Farrell and said she was acting erratically again. Farrell called her and asked if she was using and she admitted it. \\u201cWhen you\\u2019re chasing the dragon as high as you go, the fall is just as great,\\u201d he warned her.\\n\\nThe judge signed an order to have her committed, and she went to residential rehab, and the day she got out, a Sunday, she had dinner with her whole family.\\n\\n\\u201cThe next morning Grandpa found her dead in the bathroom with a needle in her arm,\\u201d Paul Jr. said.\\n\\nOn a recent night, he took a walk downtown. To Farrell\\u2019s eyes many of the people on the streets had signs of addiction. It\\u2019s nothing he could submit into evidence in a court of law, but it\\u2019s obvious from the way people wander aimlessly, or squat on the sidewalk, or pace anxiously.\\n\\n\\u201cThis isn\\u2019t right. Something\\u2019s wrong here,\\u201d Farrell said.\\n\\nAs he stood on a streetcorner, along came a skeletal man in ragged clothes. The lawyer decided to engage him.\\n\\n\\u201cWhere you from? What brings you to town?\\u201d he asked.\\n\\nThe thin man said he was from Detroit, here to see some friends. His voice was not much more than a croak. \\u201cGonna get my band back together,\\u201d the man said \\u2014 and that same man would still be wandering downtown aimlessly the next day, alone, no band in sight.\\n\\nWhen Farrell went back to his darkened office, long after his law firm colleagues had gone home, he made a vow: \\u201cI\\u2019m going to fix what you just saw.\\u201d\\n\\n\\n\\nA billboard in Huntington, where more than 1,000 people have died of opioid overdoses. (Maddie McGarvey/For The Washington Post)\\n\\nDalton Bennett contributed to this report.\\n\\nRead more\\n\\n76 billion pills: Federal data unmasks the opioid epidemic\\n\\nHow an epic legal battle brought a secret drug database to light\\n\\nAs authorities crack down, chronic pain patients say they need the opioids\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "# load text data (articles)\n",
        "df = pd.read_json('https://raw.githubusercontent.com/LambdaSchool/DS-Unit-4-Sprint-3-Deep-Learning/main/module1-rnn-and-lstm/wp_articles.json')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHOYH4CjWJRk"
      },
      "source": [
        "How many articles are in the database?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjXfqs1IPyoS",
        "outputId": "a511c8c3-e7cb-4c73-cb3c-ad1fbc7b6b5f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "136"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHz9fsXBXz4a"
      },
      "source": [
        "The [`data_cleaning_toolkit()`](https://github.com/LambdaSchool/DS-Unit-4-Sprint-3-Deep-Learning/blob/main/module1-rnn-and-lstm/data_cleaning_toolkit_class.py)<br>\n",
        "* Cleans the documents<br>\n",
        "* Chops them into text strings of length `max_len` (default = 20) characters<br>\n",
        "* Creates the X and y split with the appropriate shapes to use with an RNN or LSTM model<br><br>\n",
        "For this  problem: <br>\n",
        "X is the input data -- the corpus of news articles, arranged in 20 character sequences, for which we want to predict the next character. <br>\n",
        "The dimension of X is [n_sequences, sequence_length, n_vocab]<br>\n",
        "The rows correspond to 20 character text sequences<br><br>\n",
        "In order to have more training data, each sequence starts at a position shifted forward by an integer step, compared to the previous text string<br><br>\n",
        "y is the \"next\" character that we are trying to predict for each sequence. y is a one-hot-encoded, of dimension [n_sequences, n_vocab]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "BOvbQddF3Tj-",
        "outputId": "20ca740a-d6e8-47c5-ac4a-e0efd4a0106d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               article\n",
              "0    Contributing columnist\\n\\nThe House is on fire...\n",
              "1    When President Trump announced his decision to...\n",
              "2    Nature teases us today with some flirtatious s...\n",
              "3    \\n\\nSTOCK IMAGE: Medicare application form wit...\n",
              "4    The problem of sleeping in knows no cultural, ...\n",
              "..                                                 ...\n",
              "131  \\n\\nServer Zoe Walpole presents the “fillet of...\n",
              "132  Despite his frustration, the ever-calm McLauri...\n",
              "133  \\n\\nPresident Trump walks to board Marine One ...\n",
              "134  Published: May 24, 2018\\n\\nWP Company LLC (“Th...\n",
              "135  Here are some recent headlines from schools ar...\n",
              "\n",
              "[136 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9c1c06da-f2a8-4653-abb4-a2e765d98490\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Contributing columnist\\n\\nThe House is on fire...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>When President Trump announced his decision to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Nature teases us today with some flirtatious s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\n\\nSTOCK IMAGE: Medicare application form wit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The problem of sleeping in knows no cultural, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>\\n\\nServer Zoe Walpole presents the “fillet of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>Despite his frustration, the ever-calm McLauri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>\\n\\nPresident Trump walks to board Marine One ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>Published: May 24, 2018\\n\\nWP Company LLC (“Th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>Here are some recent headlines from schools ar...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>136 rows × 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c1c06da-f2a8-4653-abb4-a2e765d98490')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9c1c06da-f2a8-4653-abb4-a2e765d98490 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9c1c06da-f2a8-4653-abb4-a2e765d98490');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1f26043a-5a88-4c42-8347-7c9e7222920d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1f26043a-5a88-4c42-8347-7c9e7222920d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1f26043a-5a88-4c42-8347-7c9e7222920d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_4db30234-28a1-40d2-a3a4-b94746c3c1f7\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4db30234-28a1-40d2-a3a4-b94746c3c1f7 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 136,\n  \"fields\": [\n    {\n      \"column\": \"article\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 126,\n        \"samples\": [\n          \"Much of China\\u2019s chapters over the past seven decades can seem very remote and disconnected from today\\u2019s economic powerhouse \\u2014 black-and-white images of grinding poverty where there are now food delivery apps; the groundbreaking visit of President Richard M. Nixon in 1972 to Beijing, which is now home to many Western brands. But not everything has changed.\",\n          \"He shipped out in the spring of 1944 for Europe, making his way from Normandy in the wake of the D-Day invasion to the Netherlands and then, by winter, to the Ardennes region of Belgium. There, as a 19-year-old private first class during the Battle of the Bulge, the infantryman was credited with almost single-handedly holding back a German attack on the town of Malmedy.\\n\\nFor his actions \\u2014 heralded days later in a New York Times account reporting that he had \\u201chelped immobilize three German tanks, wiped out a house full of Nazis, rescued six of his trapped buddies and saved five wounded men\\u201d \\u2014 Mr. Currey, who attained the rank of sergeant before completing his service, received the Medal of Honor, the military\\u2019s highest decoration. He died Oct. 8 at his home in Selkirk, N.Y.\\n\\nAD\\n\\nAD\\n\\nHe was 94 and had congestive heart failure, said his daughter, Kathryn Domery.\\n\\nMr. Currey\\u2019s Medal of Honor \\u2014 which he received on July 27, 1945, after the Allied victory in Europe and just before the defeat of Japan \\u2014 was one of 472 awarded for service during World War II, according to the Congressional Medal of Honor Society.\\n\\nHis death leaves two living honorees from that conflict: Charles Coolidge, 98, who was recognized for his actions as an Army technical sergeant in France in the fall of 1944, and Hershel \\u201cWoody\\u201d Williams, 96, recognized for his bravery as a Marine Corps corporal at Iwo Jima in the Pacific.\\n\\nMr. Currey, who was 6 feet tall but only 130 pounds, found himself at the heart of the Battle of the Bulge, the last major German offensive of World War II and a bloody affair resulting in 80,000 American and 100,000 German casualties. The town of Malmedy became infamous as the site of a massacre by Waffen-SS troops of more than 80 U.S. soldiers who had been forced to surrender at the start of the battle.\\n\\nAD\\n\\nAD\\n\\nNotable deaths in 2019: Ric Ocasek, Valerie Harper, Ross Perot, Toni Morrison, and others we have lost this year share Share Email this link Share on Pinterest Share on LinkedIn View Photos View Photos Next Image Ginger Baker, the prodigiously talented and volcanically temperamental rock drummer who helped form Cream, rock-and-roll\\u2019s first supergroup, and inspired awe and imitation in a generation of drummers, died Oct. 6 at 80. Read the obituary (Mj Kim/AP)\\n\\nFour days after the massacre, at about 4 a.m. on Dec. 21, 1944, Mr. Currey was in a foxhole when \\u201ca German armored column spearheaded by captured American tanks rolled out of the heavy mist,\\u201d the Times reported, overpowering an American antitank unit and surrounding Mr. Currey and several other soldiers.\\n\\nTaking shelter in an abandoned paper factory, the American soldiers discovered a bazooka but no ammunition. Mr. Currey left the building and, while completely exposed to enemy fire, ran to a supply of ammunition across the street to load the bazooka. With another soldier, he shot at a German tank.\\n\\n\\u201cBy what he would later call a miracle, the rocket hit the exact spot where the turret joined the chassis and disabled the vehicle,\\u201d reads an account in the book \\u201cMedal of Honor: Portraits of Valor Beyond the Call of Duty.\\u201d\\n\\nAD\\n\\nAD\\n\\nMr. Currey then turned his attention to a German-held stone house, firing with an automatic rifle on three enemy soldiers. \\u201cI got all three with one good burst,\\u201d he told the Times, \\u201cthen, while the other fellows in the factory covered me, I stood up in plain sight and knocked down half a wall of that house with the bazooka.\\n\\n\\u201cWhen I stood up,\\u201d he continued, \\u201cI saw a number of our guys trapped in a small hole between me and the house. They had been held down there for hours and asked me to help them out.\\u201d\\n\\nIn a desperate effort to rescue them, he obtained grenades, which he used to attack the house and German tanks threatening the Americans. When the grenades ran out, he continued firing on the Germans with machine guns.\\n\\nAD\\n\\n\\u201cUnder his covering fire the 5 soldiers were able to retire to safety,\\u201d reads the citation for his Medal of Honor. \\u201cDeprived of tanks and with heavy infantry casualties, the enemy was forced to withdraw. Through his extensive knowledge of weapons and by his heroic and repeated braving of murderous enemy fire, Sgt. Currey was greatly responsible for inflicting heavy losses in men and material on the enemy, for rescuing 5 comrades, 2 of whom were wounded, and for stemming an attack which threatened to flank his battalion\\u2019s position.\\u201d\\n\\nAD\\n\\nReflecting on his actions, he told the Times-Union newspaper of Albany, N.Y., decades later, \\u201cIt was just one day of nine months of steady combat.\\u201d\\n\\nFrancis Sherman Currey was born on June 29, 1925, in Loch Sheldrake, N.Y., and grew up with his foster parents in nearby Hurleyville.\\n\\nAD\\n\\nAfter joining the Army, he completed Officer Candidate School training, but it was decided, according to \\u201cMedal of Honor,\\u201d that he was \\u201ctoo immature\\u201d for a commission, an irony not lost on those who chronicled his deeds at Malmedy.\\n\\n\\u201cWe were all teenagers, the oldest one was maybe twenty-one years old, and I was the one with all the training,\\u201d he said in the book \\u201c Voices of the Bulge \\u201d by Michael Collins and Martin King. \\u201cI knew what I was doing, since I had been in training the year before.\\u201d\\n\\nBesides the Medal of Honor, his military decorations included the Silver Star, the Bronze Star Medal and three awards of the Purple Heart.\\n\\nAD\\n\\nAfter the war, Mr. Currey worked as a benefits counselor at a veterans hospital in Albany, N.Y., and ran a landscaping business.\\n\\nAD\\n\\nSurvivors include his wife of 70 years, the former Wilma French, of Selkirk; three children, Michael Currey and Kathryn Domery, both of Selkirk, and Jonathan Currey of Dudley, Mass.; seven grandchildren; and 12 great-grandchildren.\\n\\nDecades after the war, Mr. Currey became the first Medal of Honor recipient to be represented as a G.I. Joe action figure. However, he preferred not to seek attention for his recognition. \\u201cI got it; that\\u2019s all,\\u201d he told the Times-Union of Albany in 2013. \\u201cI don\\u2019t make a big issue out of it.\\u201d\\n\\nRead more Washington Post obituaries\\n\\nAD\",\n          \"\\n\\nPaul Farrell, a West Virginia attorney driving a massive lawsuit against drug companies. (Maddie McGarvey/For The Washington Post)\\n\\nPaul Farrell, Jr. was looking through the West Virginia Code a few years ago when he came across a statute saying a county has the legal right to abate a \\u201cpublic nuisance.\\u201d Typically, that would mean things like trash heaps in someone\\u2019s front yard.\\n\\nBut Farrell decided it might also describe prescription opioids.\\n\\nFarrell is a small-city lawyer in a place often described as the epicenter of the opioid crisis. His hometown has been flooded by pills \\u2014 \\u201ca tsunami,\\u201d he says. A thousand people have died of drug overdoses here in less than two decades.\\n\\nSo Farrell, 47, made a federal case out of the catastrophe. He\\u2019s now one of three lead attorneys in the national prescription opioid litigation, the biggest and most complicated civil case in U.S. history.\\n\\nThe first courtroom showdown is set to begin next week in federal court in Cleveland. Farrell won\\u2019t argue the case before the jury. Instead, he\\u2019s one of the backstage masterminds of the litigation, which now includes more than 2,600 communities. The plaintiffs argue that the nation\\u2019s biggest drug companies \\u2014 manufacturers, distributors and retailers \\u2014 recklessly peddled opioid painkillers and fueled a wave of addiction.\\n\\nThe public nuisance strategy he helped craft has the advantage of requiring abatement \\u2014 meaning the drug companies could be required to pour billions of dollars into communities across the nation that have been devastated by the epidemic.\\n\\n\\u201cThey broke it. So they need to fix it,\\u201d Farrell said of the drug companies. \\u201cI want them to stop killing people. I want mothers to stop giving birth to babies addicted to opium. I want my friends and my friends\\u2019 children to stop overdosing. I want to stop going to funerals.\\u201d\\n\\n[Follow The Post\\u2019s investigation of the opioid epidemic]\\n\\nFarrell is built like a wrestler, and his head has a severe boot-camp buzz cut, which, combined with his blunt speech, adds extra punch to comments like \\u201cI am on the war front\\u201d and \\u201cI\\u2019m going to crucify the chain store dispensers.\\u201d\\n\\nFarrell represents hundreds of municipalities, having aggressively signed up clients, including Cabell County, of which Huntington is the county seat. He and the other plaintiffs\\u2019 attorneys are working on a contingency fee basis, meaning they don\\u2019t get paid anything if they lose in court.\\n\\nThat\\u2019s been financially hard, Farrell said, and he\\u2019s not sure exactly how he and his fellow litigators would ultimately be paid -- because there\\u2019s never been a case quite like this. But in discussing the case, he tends to talk about his hometown. For him, this big lawsuit is personal.\\n\\n\\u201cWhat you see is the shell of the former glory and beauty of the town I grew up with,\\u201d Farrell said.\\n\\nA city's resilience\\n\\n\\n\\nMarcum Terrace, a Huntington public housing complex that has been the site of many overdoses. (Maddie McGarvey/For The Washington Post)\\n\\nHuntington is intimately acquainted with tragedy. The mayor, Steve Williams, keeps a framed photograph on the wall of his office, directly behind his desk so that anyone speaking to him will see it. It\\u2019s the 1970 Marshall University football team.\\n\\nOn Nov. 14 of that year, a chartered DC-9 airplane carrying the team home from an away game crashed into a hillside nearly a mile short of the Huntington airport runway. The pilots had misjudged their altitude, possibly due to instrumentation malfunction. All 75 people aboard \\u2014 including players, coaches and many prominent citizens who were boosters of the local team \\u2014 perished.\\n\\nThat remains the deadliest aviation accident in U.S. sports history. It also remains very much on the minds of the citizens of Huntington. In interviews, public officials often cite the crash when speaking about the city\\u2019s resilience. They say they had to learn to hold up one another in hard times.\\n\\nOpioid pills became popular in the late 1990s, after the medical community embraced pain as the \\u201cfifth vital sign\\u201d and Purdue Pharma introduced its powerful, slow-release painkiller OxyContin, which the company marketed as less likely to be addictive or abused. People became addicted, and pills became street drugs. When the authorities cracked down, heroin came to town. Then came illicit fentanyl, which was cheaper, more powerful and even deadlier than heroin.\\n\\nFatal overdoses jumped dramatically starting early in this decade. At the peak year of the epidemic, in 2017, Cabell County \\u2014 population 96,000 \\u2014 experienced 203 fatal drug overdoses.\\n\\nLocal leaders are sensitive to Huntington\\u2019s image. They point to progress in the past two years: Deaths are down, overdoses are down. A \\u201charm reduction program\\u201d based out of the health department distributes clean needles for intravenous drug users, along with naloxone to combat overdoses. The community has opened a walk-in clinic for people actively using drugs and seeking help. A new program offers residential treatment for women with children or who are pregnant.\\n\\n\\u201cWe are no longer the epicenter of the epidemic. We are the city of solutions,\\u201d says Lyn O\\u2019Connell, who helps run a new division of addiction sciences at the Marshall University School of Medicine.\\n\\nFarrell and his allies in the big lawsuit envision the drug companies funneling money to places like Huntington over many decades to deal with addiction and recovery.\\n\\nThe Huntington police chief, Hank Dial, noted that violent crime has dropped 26 percent in the past year, and drug use is down. But there\\u2019s a grim reason for that: So many drug users are dead now.\\n\\n\\u201cI\\u2019m not hanging up a Mission Accomplished banner yet because we\\u2019re still at war here,\\u201d Dial said.\\n\\n'I choose to fight back'\\n\\n\\n\\nFarrell prepares to present the latest on the lawsuits to the country commission in Huntington. (Maddie McGarvey/For The Washington Post)\\n\\nPaul Farrell Sr. is a county circuit court judge here. He says of his son, \\u201cHe\\u2019s playing in the big leagues now.\\u201d Asked to describe his namesake, the judge says, \\u201cAggressive. Smart. Focused. And the last two years of his life, this\\u201d \\u2014 the opioids litigation \\u2014 \\u201chas been all-consuming.\\u201d\\n\\nThere are a lot of Farrells here in Huntington. There\\u2019s a Farrell Building downtown. Back in the 1990s and early 2000s the building was the headquarters of Farrell, Farrell & Farrell, a law firm run by Paul Sr., who had not yet been appointed to the bench, and his brothers Mike and Joe. Paul Jr., a graduate of Notre Dame and West Virginia University School of Law, decided to strike out on his own rather than be part of the family firm, because, he says, \\u201cA whole bunch of Farrells had to die before I could be in charge.\\u201d\\n\\nPaul Jr. is not without ambition. He even ran for president of the United States \\u2014 sort of. In 2016, he paid $2,500 to have his name on the ballot for the Democratic primary in West Virginia. He said he couldn\\u2019t support either Hillary Clinton or Bernie Sanders because of their position on coal.\\n\\n\\u201cYou cannot shut down our coal mines, brag about it on the campaign trail and then expect me to vote for you,\\u201d Farrell wrote in an op-ed explaining his quixotic candidacy. \\u201cWin or lose, I choose to fight back.\\u201d He got a respectable number of votes in coal country and boasts that he came close to the number that would have given him three delegates to the national convention.\\n\\nNow he\\u2019s taken on something even more challenging than a presidential race. Among the uncertainties in recent weeks has been who, exactly, will wind up in court if and when the trial begins. Judge Polster has urged the parties to reach a settlement. Purdue Pharma has reached a tentative settlement with the federal court plaintiffs as well as a group of state attorneys general. Johnson & Johnson recently settled with the two Ohio counties that are part of the first bellwether case. The pharmacy companies were excluded from this trial track. Left standing are major drug distributors, including McKesson, Cardinal Health and AmeriSource Bergen.\\n\\nA second bellwether trial is planned, with Huntington and Cabell County as the plaintiffs. That\\u2019s Farrell\\u2019s trial, in a sense, because it\\u2019ll be on his home turf \\u2014 in the federal courthouse, a short walk from the Farrell Building and from the county courthouse where Judge Farrell has his chambers.\\n\\n\\n\\nThe courthouse in Huntington, where Paul Farrell Jr.\\u2019s father, a judge, has his chambers. (Maddie McGarvey/For The Washington Post)\\n\\nFarrell vows to make that second trial more down-to-earth than the first one. The first one will feature a lot of academic experts, he said. But when the trial comes to Huntington, he wants to call to the stand a string of doctors, nurses, police officers, paramedics, firefighters and other first responders.\\n\\nIt might never happen, though. The companies could settle.\\n\\nThere have been other attempts to derail the Cleveland trial. The attorney general of Ohio, Dave Yost, petitioned a federal appeals court to halt the trial, arguing that the states, not the municipalities, should have jurisdiction over the lawsuits and any subsequent distribution of money.\\n\\nYost\\u2019s last-minute effort infuriated Farrell, who along with other attorneys has spent a couple of years amassing evidence and preparing for trial.\\n\\n\\u201cThey can\\u2019t call me off,\\u201d he said. \\u201cThis entire thing is no longer about the responsibility of the defendants, or even about the amount of money they\\u2019re going to pay. The fight right now is who gets to control the money.\\u201d\\n\\nOn Thursday the appeals court ruled against Yost, and the Cleveland trial is a go.\\n\\nThe trial is near\\n\\nJudge Farrell \\u2014 who still makes pancakes for his three sons every Sunday morning \\u2014 said that 90 percent of the criminal cases he sees are related to drugs.\\n\\n\\u201cDo you want your drugs, or the kids?\\u201d he recalls asking mothers who are in his courtroom. And sometimes, he said, the answer is \\u201cI want the drugs.\\u201d\\n\\nThe fire chief, Jan Rader, who gained renown in the documentary \\u201cHeroin(e),\\u201d was also in the judge\\u2019s office, along with Paul Jr. She described the compassion fatigue that has taken a toll on her first responders. They\\u2019ve all gotten good at using naloxone to revive people who have overdosed. But they become jaded when they see the same people overdosing repeatedly.\\n\\n\\u201cA firefighter is a hero. They\\u2019re trained to make a situation better. They have the tools to put out a fire. They have the tools and the knowledge to cut somebody out of a car,\\u201d Rader said. \\u201cThey do not have the tools and knowledge to save somebody long-term who is suffering from substance use disorder.\\u201d\\n\\nPaul Jr. told the story of a young woman who as a girl played sports with his kids. She\\u2019d been on and off the drugs. Her grandfather called Farrell and said she was acting erratically again. Farrell called her and asked if she was using and she admitted it. \\u201cWhen you\\u2019re chasing the dragon as high as you go, the fall is just as great,\\u201d he warned her.\\n\\nThe judge signed an order to have her committed, and she went to residential rehab, and the day she got out, a Sunday, she had dinner with her whole family.\\n\\n\\u201cThe next morning Grandpa found her dead in the bathroom with a needle in her arm,\\u201d Paul Jr. said.\\n\\nOn a recent night, he took a walk downtown. To Farrell\\u2019s eyes many of the people on the streets had signs of addiction. It\\u2019s nothing he could submit into evidence in a court of law, but it\\u2019s obvious from the way people wander aimlessly, or squat on the sidewalk, or pace anxiously.\\n\\n\\u201cThis isn\\u2019t right. Something\\u2019s wrong here,\\u201d Farrell said.\\n\\nAs he stood on a streetcorner, along came a skeletal man in ragged clothes. The lawyer decided to engage him.\\n\\n\\u201cWhere you from? What brings you to town?\\u201d he asked.\\n\\nThe thin man said he was from Detroit, here to see some friends. His voice was not much more than a croak. \\u201cGonna get my band back together,\\u201d the man said \\u2014 and that same man would still be wandering downtown aimlessly the next day, alone, no band in sight.\\n\\nWhen Farrell went back to his darkened office, long after his law firm colleagues had gone home, he made a vow: \\u201cI\\u2019m going to fix what you just saw.\\u201d\\n\\n\\n\\nA billboard in Huntington, where more than 1,000 people have died of opioid overdoses. (Maddie McGarvey/For The Washington Post)\\n\\nDalton Bennett contributed to this report.\\n\\nRead more\\n\\n76 billion pills: Federal data unmasks the opioid epidemic\\n\\nHow an epic legal battle brought a secret drug database to light\\n\\nAs authorities crack down, chronic pain patients say they need the opioids\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Szp3M3We36PX"
      },
      "outputs": [],
      "source": [
        "dctk = data_cleaning_toolkit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "yWosuMX-6RGG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1f3523d-7b6c-4635-fc73-a9f9a2fa5279"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<data_cleaning_toolkit_class.data_cleaning_toolkit at 0x7c12f31aa390>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "dctk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0Ku2t609uCK",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-292d1e2b08c74976",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "outputId": "6bd3bef3-ada8-4bed-f327-347baf6de0cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "136\n",
            "136\n",
            "Created 168985 sequences.\n"
          ]
        }
      ],
      "source": [
        "# instantiate data cleaning toolkit\n",
        "dctk = data_cleaning_toolkit()\n",
        "\n",
        "# use regex to clean documents, applying the clean_data method from dctk\n",
        "df['clean_data'] = df.article.apply(lambda text: dctk.clean_data(text))\n",
        "print(len(df['clean_data']))\n",
        "\n",
        "# extract cleaned articles to an array of strings\n",
        "data = df['clean_data'].values\n",
        "print(len(data))\n",
        "\n",
        "# number of chars in each sequence\n",
        "doc_len = 20\n",
        "\n",
        "# numerically encode the sequences, using the create_char_sequences method from dctk\n",
        "dctk.create_char_sequences(data, doc_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDzu_NIH6cRE",
        "outputId": "7fe27e46-42f5-494c-ae2e-53e3972f2359"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "dctk.next_char[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QPOa3xqk-LF"
      },
      "source": [
        "Here is the first article"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "wfbpmXNZOrS3",
        "outputId": "bd443aac-68b2-465b-f63d-04b14748bdf2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Contributing columnist\\n\\nThe House is on fire. And with each passing day, Donald Trump defiles the office of the president. If only past defrocked presidents could provide a roadmap for this firestorm.\\n\\nAndrew Johnson fought impeachment vigorously and survived removal, but never won reelection. Richard Nixon got in the way of justice, but eventually bowed to the rule of law, accepting his asterisk in the annals of history and resigning before certain removal. Bill Clinton expressed contrition, went on to complete his presidency with high approval ratings and has remained a popular former president.\\n\\nIf you care about democracy, the rule of law and nearly 250 years of constitutional governance, take heed. President Trump is no Clinton or Nixon, or even Johnson. He will not go quietly. It will be ugly. He will betray us and the rule of law in the process — defying subpoenas, withholding documents, blocking witnesses.\\n\\nThis presidency is fouled with disrespect for rules, boundaries and norms. Trump walked away from major agreements negotiated by his predecessors — the Iran nuclear deal, the Paris climate accord — and the United States’ word as bond is no more. Look at the ease with which he discards supporters — ask former attorney general Jeff Sessions or former secretary of state Rex Tillerson. Ask our allies, here today, gone tomorrow — NATO, the Kurds in Syria.\\n\\nFrom his earliest days as a candidate, Trump voiced appallingly arrogant views about the power of the presidency: “Mexico will pay for the wall!” ; “I alone can fix it”; “My primary consultant is myself.” His possessiveness over people and institutions is also not new: “my generals and my military,” “my African American.”\\n\\nOnly months into his presidency, Trump disparaged democratic allies, including Germany’s Angela Merkel (“ruining Germany”) and Britain’s Theresa May (“foolish”) — notably, both women — in favor of strong-arm leaders such as North Korea’s Kim Jong Un (who wrote him “beautiful letters”), Saudi Arabia’s Mohammed bin Salman (“very good ally”), Turkey’s Recep Tayyip Erdogan (“great friendship”) and the Philippines’ Rodrigo Duterte (“great relationship”). Trump heaps praise on Russia’s Vladimir Putin (“he’s a strong leader”). And, days after revealing his words pressuring Ukrainian President Volodymyr Zelensky to dig up dirt on his opponent, he invited China to do it, too.\\n\\nTrump’s campaign for the White House was rotten from the beginning. We glimpsed its depths when his lawyer Michael Cohen pleaded guilty to campaign finance felonies and identified Trump as “Individual 1” in a conspiracy to pay off an adult-film star and a former Playboy model to silence them during the height of the 2016 presidential campaign. We got even more evidence of Trump’s deception in the dense report prepared by special counsel Robert S. Mueller III on Russia’s interference in the 2016 election to benefit Trump and try to defeat Hillary Clinton. Mueller laid the groundwork for at least 10 acts of obstruction of justice.\\n\\nEven with all of that, it’s this still-unraveling Ukraine story that makes clear the bits and pieces that we could only imagine with Trump’s pleas to “Russia, if you’re listening . . . .” We have the same threats, lies, subterfuge and obstruction — only this time, we have the president’s unambiguous words to Zelensky: “I would like you to do us a favor though.” Ukraine represents the same lawlessness that propelled Trump over the finish line in 2016: this time in plain sight, with witnesses, including at least one whistleblower and lots of bit players. From the State Department to the Energy Department to the Justice Department and throughout the White House, Trump is using every bit of the machinery of government and personnel at his disposal to strongarm a small country under the heel of its threatening Russian neighbor — all to get manufactured dirt on a political opponent.\\n\\nIt’s illegal. The evidence is bearing fruit. The time will come. And justice will be served.\\n\\nThe president’s personal approval rating remains low, though stable, but there is growing support for impeachment — a Fox News poll this week found that 51 percent support removing Trump from office. Independents, as well as Democrats, mostly support the impeachment inquiry, while Republicans are mostly holding tight. These things may or may not change.\\n\\nEither way, we will be changed if we do not right this ship of democracy.\\n\\n“Impeachment is not about punishment. Impeachment is about cleansing the office. Impeachment is about restoring honor and integrity to the office.” We should heed these words, spoken by the 1999 version of Sen. Lindsey O. Graham (R-S.C.). The fire did not start with Ukraine. Nonetheless, Ukraine may give us the water to finally put it out.\\n\\nRead more from Donna F. Edwards's archive.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "(df['article'][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE86rmUicjM_"
      },
      "source": [
        "`data` is an array containing the cleaned articles.<br>\n",
        "Here is the cleaned version of the first article"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "mljIx-NSPX3E",
        "outputId": "acd93acb-235c-4035-d195-f84c1ae9a6ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'contributing columnistthe house is on fire and with each passing day donald trump defiles the office of the president if only past defrocked presidents could provide a roadmap for this firestormandrew johnson fought impeachment vigorously and survived removal but never won reelection richard nixon got in the way of justice but eventually bowed to the rule of law accepting his asterisk in the annals of history and resigning before certain removal bill clinton expressed contrition went on to complete his presidency with high approval ratings and has remained a popular former presidentif you care about democracy the rule of law and nearlyyears of constitutional governance take heed president trump is no clinton or nixon or even johnson he will not go quietly it will be ugly he will betray us and the rule of law in the processdefying subpoenas withholding documents blocking witnessesthis presidency is fouled with disrespect for rules boundaries and norms trump walked away from major agreements negotiated by his predecessorsthe iran nuclear deal the paris climate accordand the united states word as bond is no more look at the ease with which he discards supportersask former attorney general jeff sessions or former secretary of state rex tillerson ask our allies here today gone tomorrownato the kurds in syriafrom his earliest days as a candidate trump voiced appallingly arrogant views about the power of the presidency mexico will pay for the walli alone can fix it my primary consultant is myself his possessiveness over people and institutions is also not new my generals and my military my african americanonly months into his presidency trump disparaged democratic allies including germanys angela merkel ruining germany and britains theresa may foolishnotably both womenin favor of strongarm leaders such as north koreas kim jong un who wrote him beautiful letters saudi arabias mohammed bin salman very good ally turkeys recep tayyip erdogan great friendship and the philippines rodrigo duterte great relationship trump heaps praise on russias vladimir putin hes a strong leader and days after revealing his words pressuring ukrainian president volodymyr zelensky to dig up dirt on his opponent he invited china to do it tootrumps campaign for the white house was rotten from the beginning we glimpsed its depths when his lawyer michael cohen pleaded guilty to campaign finance felonies and identified trump as individualin a conspiracy to pay off an adultfilm star and a former playboy model to silence them during the height of thepresidential campaign we got even more evidence of trumps deception in the dense report prepared by special counsel robert s mueller iii on russias interference in theelection to benefit trump and try to defeat hillary clinton mueller laid the groundwork for at leastacts of obstruction of justiceeven with all of that its this stillunraveling ukraine story that makes clear the bits and pieces that we could only imagine with trumps pleas to russia if youre listeningwe have the same threats lies subterfuge and obstructiononly this time we have the presidents unambiguous words to zelensky i would like you to do us a favor though ukraine represents the same lawlessness that propelled trump over the finish line inthis time in plain sight with witnesses including at least one whistleblower and lots of bit players from the state department to the energy department to the justice department and throughout the white house trump is using every bit of the machinery of government and personnel at his disposal to strongarm a small country under the heel of its threatening russian neighborall to get manufactured dirt on a political opponentits illegal the evidence is bearing fruit the time will come and justice will be servedthe presidents personal approval rating remains low though stable but there is growing support for impeachmenta fox news poll this week found thatpercent support removing trump from office independents as well as democrats mostly support the impeachment inquiry while republicans are mostly holding tight these things may or may not changeeither way we will be changed if we do not right this ship of democracyimpeachment is not about punishment impeachment is about cleansing the office impeachment is about restoring honor and integrity to the office we should heed these words spoken by theversion of sen lindsey o graham rsc the fire did not start with ukraine nonetheless ukraine may give us the water to finally put it outread more from donna f edwardss archive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "data[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XW5XKqPzisak"
      },
      "source": [
        "Let's explore the `dctk` class we just instantiated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4la7twqqhxmH",
        "outputId": "1b316918-2f86-403c-e98a-84b5b06e11d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[11, 6, 1, 20, 10, 19, 14, 2, 20, 19, 1, 5, 4, 11, 6, 3, 2, 7, 1, 19],\n",
              " [19, 14, 2, 20, 19, 1, 5, 4, 11, 6, 3, 2, 7, 1, 19, 9, 20, 20, 22, 15],\n",
              " [1, 5, 4, 11, 6, 3, 2, 7, 1, 19, 9, 20, 20, 22, 15, 4, 22, 6, 2, 9],\n",
              " [3, 2, 7, 1, 19, 9, 20, 20, 22, 15, 4, 22, 6, 2, 9, 15, 4, 19, 9, 4],\n",
              " [9, 20, 20, 22, 15, 4, 22, 6, 2, 9, 15, 4, 19, 9, 4, 6, 1, 4, 16, 19],\n",
              " [4, 22, 6, 2, 9, 15, 4, 19, 9, 4, 6, 1, 4, 16, 19, 10, 15, 4, 0, 1],\n",
              " [15, 4, 19, 9, 4, 6, 1, 4, 16, 19, 10, 15, 4, 0, 1, 13, 4, 17, 19, 20],\n",
              " [6, 1, 4, 16, 19, 10, 15, 4, 0, 1, 13, 4, 17, 19, 20, 22, 4, 15, 0, 11],\n",
              " [10, 15, 4, 0, 1, 13, 4, 17, 19, 20, 22, 4, 15, 0, 11, 22, 4, 23, 0, 9],\n",
              " [13, 4, 17, 19, 20, 22, 4, 15, 0, 11, 22, 4, 23, 0, 9, 9, 19, 1, 5, 4],\n",
              " [22, 4, 15, 0, 11, 22, 4, 23, 0, 9, 9, 19, 1, 5, 4, 13, 0, 26, 4, 13],\n",
              " [22, 4, 23, 0, 9, 9, 19, 1, 5, 4, 13, 0, 26, 4, 13, 6, 1, 0, 3, 13],\n",
              " [9, 19, 1, 5, 4, 13, 0, 26, 4, 13, 6, 1, 0, 3, 13, 4, 20, 10, 2, 7],\n",
              " [13, 0, 26, 4, 13, 6, 1, 0, 3, 13, 4, 20, 10, 2, 7, 23, 4, 13, 15, 16],\n",
              " [6, 1, 0, 3, 13, 4, 20, 10, 2, 7, 23, 4, 13, 15, 16, 19, 3, 15, 9, 4],\n",
              " [4, 20, 10, 2, 7, 23, 4, 13, 15, 16, 19, 3, 15, 9, 4, 20, 22, 15, 4, 6],\n",
              " [23, 4, 13, 15, 16, 19, 3, 15, 9, 4, 20, 22, 15, 4, 6, 16, 16, 19, 11, 15],\n",
              " [19, 3, 15, 9, 4, 20, 22, 15, 4, 6, 16, 16, 19, 11, 15, 4, 6, 16, 4, 20],\n",
              " [20, 22, 15, 4, 6, 16, 16, 19, 11, 15, 4, 6, 16, 4, 20, 22, 15, 4, 23, 10],\n",
              " [16, 16, 19, 11, 15, 4, 6, 16, 4, 20, 22, 15, 4, 23, 10, 15, 9, 19, 13, 15],\n",
              " [4, 6, 16, 4, 20, 22, 15, 4, 23, 10, 15, 9, 19, 13, 15, 1, 20, 4, 19, 16],\n",
              " [22, 15, 4, 23, 10, 15, 9, 19, 13, 15, 1, 20, 4, 19, 16, 4, 6, 1, 3, 26],\n",
              " [15, 9, 19, 13, 15, 1, 20, 4, 19, 16, 4, 6, 1, 3, 26, 4, 23, 0, 9, 20],\n",
              " [1, 20, 4, 19, 16, 4, 6, 1, 3, 26, 4, 23, 0, 9, 20, 4, 13, 15, 16, 10],\n",
              " [4, 6, 1, 3, 26, 4, 23, 0, 9, 20, 4, 13, 15, 16, 10, 6, 11, 12, 15, 13],\n",
              " [4, 23, 0, 9, 20, 4, 13, 15, 16, 10, 6, 11, 12, 15, 13, 4, 23, 10, 15, 9],\n",
              " [4, 13, 15, 16, 10, 6, 11, 12, 15, 13, 4, 23, 10, 15, 9, 19, 13, 15, 1, 20],\n",
              " [6, 11, 12, 15, 13, 4, 23, 10, 15, 9, 19, 13, 15, 1, 20, 9, 4, 11, 6, 2],\n",
              " [4, 23, 10, 15, 9, 19, 13, 15, 1, 20, 9, 4, 11, 6, 2, 3, 13, 4, 23, 10],\n",
              " [19, 13, 15, 1, 20, 9, 4, 11, 6, 2, 3, 13, 4, 23, 10, 6, 8, 19, 13, 15],\n",
              " [9, 4, 11, 6, 2, 3, 13, 4, 23, 10, 6, 8, 19, 13, 15, 4, 0, 4, 10, 6],\n",
              " [3, 13, 4, 23, 10, 6, 8, 19, 13, 15, 4, 0, 4, 10, 6, 0, 13, 7, 0, 23],\n",
              " [6, 8, 19, 13, 15, 4, 0, 4, 10, 6, 0, 13, 7, 0, 23, 4, 16, 6, 10, 4],\n",
              " [4, 0, 4, 10, 6, 0, 13, 7, 0, 23, 4, 16, 6, 10, 4, 20, 22, 19, 9, 4],\n",
              " [0, 13, 7, 0, 23, 4, 16, 6, 10, 4, 20, 22, 19, 9, 4, 16, 19, 10, 15, 9],\n",
              " [4, 16, 6, 10, 4, 20, 22, 19, 9, 4, 16, 19, 10, 15, 9, 20, 6, 10, 7, 0],\n",
              " [20, 22, 19, 9, 4, 16, 19, 10, 15, 9, 20, 6, 10, 7, 0, 1, 13, 10, 15, 17],\n",
              " [16, 19, 10, 15, 9, 20, 6, 10, 7, 0, 1, 13, 10, 15, 17, 4, 24, 6, 22, 1],\n",
              " [20, 6, 10, 7, 0, 1, 13, 10, 15, 17, 4, 24, 6, 22, 1, 9, 6, 1, 4, 16],\n",
              " [1, 13, 10, 15, 17, 4, 24, 6, 22, 1, 9, 6, 1, 4, 16, 6, 2, 5, 22, 20],\n",
              " [4, 24, 6, 22, 1, 9, 6, 1, 4, 16, 6, 2, 5, 22, 20, 4, 19, 7, 23, 15],\n",
              " [9, 6, 1, 4, 16, 6, 2, 5, 22, 20, 4, 19, 7, 23, 15, 0, 11, 22, 7, 15],\n",
              " [6, 2, 5, 22, 20, 4, 19, 7, 23, 15, 0, 11, 22, 7, 15, 1, 20, 4, 8, 19],\n",
              " [4, 19, 7, 23, 15, 0, 11, 22, 7, 15, 1, 20, 4, 8, 19, 5, 6, 10, 6, 2],\n",
              " [0, 11, 22, 7, 15, 1, 20, 4, 8, 19, 5, 6, 10, 6, 2, 9, 3, 26, 4, 0],\n",
              " [1, 20, 4, 8, 19, 5, 6, 10, 6, 2, 9, 3, 26, 4, 0, 1, 13, 4, 9, 2],\n",
              " [5, 6, 10, 6, 2, 9, 3, 26, 4, 0, 1, 13, 4, 9, 2, 10, 8, 19, 8, 15],\n",
              " [9, 3, 26, 4, 0, 1, 13, 4, 9, 2, 10, 8, 19, 8, 15, 13, 4, 10, 15, 7],\n",
              " [1, 13, 4, 9, 2, 10, 8, 19, 8, 15, 13, 4, 10, 15, 7, 6, 8, 0, 3, 4],\n",
              " [10, 8, 19, 8, 15, 13, 4, 10, 15, 7, 6, 8, 0, 3, 4, 14, 2, 20, 4, 1],\n",
              " [13, 4, 10, 15, 7, 6, 8, 0, 3, 4, 14, 2, 20, 4, 1, 15, 8, 15, 10, 4],\n",
              " [6, 8, 0, 3, 4, 14, 2, 20, 4, 1, 15, 8, 15, 10, 4, 17, 6, 1, 4, 10],\n",
              " [14, 2, 20, 4, 1, 15, 8, 15, 10, 4, 17, 6, 1, 4, 10, 15, 15, 3, 15, 11],\n",
              " [15, 8, 15, 10, 4, 17, 6, 1, 4, 10, 15, 15, 3, 15, 11, 20, 19, 6, 1, 4],\n",
              " [17, 6, 1, 4, 10, 15, 15, 3, 15, 11, 20, 19, 6, 1, 4, 10, 19, 11, 22, 0],\n",
              " [15, 15, 3, 15, 11, 20, 19, 6, 1, 4, 10, 19, 11, 22, 0, 10, 13, 4, 1, 19],\n",
              " [20, 19, 6, 1, 4, 10, 19, 11, 22, 0, 10, 13, 4, 1, 19, 25, 6, 1, 4, 5],\n",
              " [10, 19, 11, 22, 0, 10, 13, 4, 1, 19, 25, 6, 1, 4, 5, 6, 20, 4, 19, 1],\n",
              " [10, 13, 4, 1, 19, 25, 6, 1, 4, 5, 6, 20, 4, 19, 1, 4, 20, 22, 15, 4],\n",
              " [25, 6, 1, 4, 5, 6, 20, 4, 19, 1, 4, 20, 22, 15, 4, 17, 0, 26, 4, 6],\n",
              " [6, 20, 4, 19, 1, 4, 20, 22, 15, 4, 17, 0, 26, 4, 6, 16, 4, 24, 2, 9],\n",
              " [4, 20, 22, 15, 4, 17, 0, 26, 4, 6, 16, 4, 24, 2, 9, 20, 19, 11, 15, 4],\n",
              " [17, 0, 26, 4, 6, 16, 4, 24, 2, 9, 20, 19, 11, 15, 4, 14, 2, 20, 4, 15],\n",
              " [16, 4, 24, 2, 9, 20, 19, 11, 15, 4, 14, 2, 20, 4, 15, 8, 15, 1, 20, 2],\n",
              " [20, 19, 11, 15, 4, 14, 2, 20, 4, 15, 8, 15, 1, 20, 2, 0, 3, 3, 26, 4],\n",
              " [14, 2, 20, 4, 15, 8, 15, 1, 20, 2, 0, 3, 3, 26, 4, 14, 6, 17, 15, 13],\n",
              " [8, 15, 1, 20, 2, 0, 3, 3, 26, 4, 14, 6, 17, 15, 13, 4, 20, 6, 4, 20],\n",
              " [0, 3, 3, 26, 4, 14, 6, 17, 15, 13, 4, 20, 6, 4, 20, 22, 15, 4, 10, 2],\n",
              " [14, 6, 17, 15, 13, 4, 20, 6, 4, 20, 22, 15, 4, 10, 2, 3, 15, 4, 6, 16],\n",
              " [4, 20, 6, 4, 20, 22, 15, 4, 10, 2, 3, 15, 4, 6, 16, 4, 3, 0, 17, 4],\n",
              " [22, 15, 4, 10, 2, 3, 15, 4, 6, 16, 4, 3, 0, 17, 4, 0, 11, 11, 15, 23],\n",
              " [3, 15, 4, 6, 16, 4, 3, 0, 17, 4, 0, 11, 11, 15, 23, 20, 19, 1, 5, 4],\n",
              " [4, 3, 0, 17, 4, 0, 11, 11, 15, 23, 20, 19, 1, 5, 4, 22, 19, 9, 4, 0],\n",
              " [0, 11, 11, 15, 23, 20, 19, 1, 5, 4, 22, 19, 9, 4, 0, 9, 20, 15, 10, 19],\n",
              " [20, 19, 1, 5, 4, 22, 19, 9, 4, 0, 9, 20, 15, 10, 19, 9, 12, 4, 19, 1],\n",
              " [22, 19, 9, 4, 0, 9, 20, 15, 10, 19, 9, 12, 4, 19, 1, 4, 20, 22, 15, 4],\n",
              " [9, 20, 15, 10, 19, 9, 12, 4, 19, 1, 4, 20, 22, 15, 4, 0, 1, 1, 0, 3],\n",
              " [9, 12, 4, 19, 1, 4, 20, 22, 15, 4, 0, 1, 1, 0, 3, 9, 4, 6, 16, 4],\n",
              " [4, 20, 22, 15, 4, 0, 1, 1, 0, 3, 9, 4, 6, 16, 4, 22, 19, 9, 20, 6],\n",
              " [0, 1, 1, 0, 3, 9, 4, 6, 16, 4, 22, 19, 9, 20, 6, 10, 26, 4, 0, 1],\n",
              " [9, 4, 6, 16, 4, 22, 19, 9, 20, 6, 10, 26, 4, 0, 1, 13, 4, 10, 15, 9],\n",
              " [22, 19, 9, 20, 6, 10, 26, 4, 0, 1, 13, 4, 10, 15, 9, 19, 5, 1, 19, 1],\n",
              " [10, 26, 4, 0, 1, 13, 4, 10, 15, 9, 19, 5, 1, 19, 1, 5, 4, 14, 15, 16],\n",
              " [13, 4, 10, 15, 9, 19, 5, 1, 19, 1, 5, 4, 14, 15, 16, 6, 10, 15, 4, 11],\n",
              " [19, 5, 1, 19, 1, 5, 4, 14, 15, 16, 6, 10, 15, 4, 11, 15, 10, 20, 0, 19],\n",
              " [5, 4, 14, 15, 16, 6, 10, 15, 4, 11, 15, 10, 20, 0, 19, 1, 4, 10, 15, 7],\n",
              " [6, 10, 15, 4, 11, 15, 10, 20, 0, 19, 1, 4, 10, 15, 7, 6, 8, 0, 3, 4],\n",
              " [15, 10, 20, 0, 19, 1, 4, 10, 15, 7, 6, 8, 0, 3, 4, 14, 19, 3, 3, 4],\n",
              " [1, 4, 10, 15, 7, 6, 8, 0, 3, 4, 14, 19, 3, 3, 4, 11, 3, 19, 1, 20],\n",
              " [6, 8, 0, 3, 4, 14, 19, 3, 3, 4, 11, 3, 19, 1, 20, 6, 1, 4, 15, 25],\n",
              " [14, 19, 3, 3, 4, 11, 3, 19, 1, 20, 6, 1, 4, 15, 25, 23, 10, 15, 9, 9],\n",
              " [11, 3, 19, 1, 20, 6, 1, 4, 15, 25, 23, 10, 15, 9, 9, 15, 13, 4, 11, 6],\n",
              " [6, 1, 4, 15, 25, 23, 10, 15, 9, 9, 15, 13, 4, 11, 6, 1, 20, 10, 19, 20],\n",
              " [23, 10, 15, 9, 9, 15, 13, 4, 11, 6, 1, 20, 10, 19, 20, 19, 6, 1, 4, 17],\n",
              " [15, 13, 4, 11, 6, 1, 20, 10, 19, 20, 19, 6, 1, 4, 17, 15, 1, 20, 4, 6],\n",
              " [1, 20, 10, 19, 20, 19, 6, 1, 4, 17, 15, 1, 20, 4, 6, 1, 4, 20, 6, 4],\n",
              " [19, 6, 1, 4, 17, 15, 1, 20, 4, 6, 1, 4, 20, 6, 4, 11, 6, 7, 23, 3],\n",
              " [15, 1, 20, 4, 6, 1, 4, 20, 6, 4, 11, 6, 7, 23, 3, 15, 20, 15, 4, 22],\n",
              " [1, 4, 20, 6, 4, 11, 6, 7, 23, 3, 15, 20, 15, 4, 22, 19, 9, 4, 23, 10],\n",
              " [11, 6, 7, 23, 3, 15, 20, 15, 4, 22, 19, 9, 4, 23, 10, 15, 9, 19, 13, 15],\n",
              " [15, 20, 15, 4, 22, 19, 9, 4, 23, 10, 15, 9, 19, 13, 15, 1, 11, 26, 4, 17],\n",
              " [19, 9, 4, 23, 10, 15, 9, 19, 13, 15, 1, 11, 26, 4, 17, 19, 20, 22, 4, 22],\n",
              " [15, 9, 19, 13, 15, 1, 11, 26, 4, 17, 19, 20, 22, 4, 22, 19, 5, 22, 4, 0],\n",
              " [1, 11, 26, 4, 17, 19, 20, 22, 4, 22, 19, 5, 22, 4, 0, 23, 23, 10, 6, 8],\n",
              " [19, 20, 22, 4, 22, 19, 5, 22, 4, 0, 23, 23, 10, 6, 8, 0, 3, 4, 10, 0],\n",
              " [19, 5, 22, 4, 0, 23, 23, 10, 6, 8, 0, 3, 4, 10, 0, 20, 19, 1, 5, 9],\n",
              " [23, 23, 10, 6, 8, 0, 3, 4, 10, 0, 20, 19, 1, 5, 9, 4, 0, 1, 13, 4],\n",
              " [0, 3, 4, 10, 0, 20, 19, 1, 5, 9, 4, 0, 1, 13, 4, 22, 0, 9, 4, 10],\n",
              " [20, 19, 1, 5, 9, 4, 0, 1, 13, 4, 22, 0, 9, 4, 10, 15, 7, 0, 19, 1],\n",
              " [4, 0, 1, 13, 4, 22, 0, 9, 4, 10, 15, 7, 0, 19, 1, 15, 13, 4, 0, 4],\n",
              " [22, 0, 9, 4, 10, 15, 7, 0, 19, 1, 15, 13, 4, 0, 4, 23, 6, 23, 2, 3],\n",
              " [15, 7, 0, 19, 1, 15, 13, 4, 0, 4, 23, 6, 23, 2, 3, 0, 10, 4, 16, 6],\n",
              " [15, 13, 4, 0, 4, 23, 6, 23, 2, 3, 0, 10, 4, 16, 6, 10, 7, 15, 10, 4],\n",
              " [23, 6, 23, 2, 3, 0, 10, 4, 16, 6, 10, 7, 15, 10, 4, 23, 10, 15, 9, 19],\n",
              " [0, 10, 4, 16, 6, 10, 7, 15, 10, 4, 23, 10, 15, 9, 19, 13, 15, 1, 20, 19],\n",
              " [10, 7, 15, 10, 4, 23, 10, 15, 9, 19, 13, 15, 1, 20, 19, 16, 4, 26, 6, 2],\n",
              " [23, 10, 15, 9, 19, 13, 15, 1, 20, 19, 16, 4, 26, 6, 2, 4, 11, 0, 10, 15],\n",
              " [13, 15, 1, 20, 19, 16, 4, 26, 6, 2, 4, 11, 0, 10, 15, 4, 0, 14, 6, 2],\n",
              " [16, 4, 26, 6, 2, 4, 11, 0, 10, 15, 4, 0, 14, 6, 2, 20, 4, 13, 15, 7],\n",
              " [4, 11, 0, 10, 15, 4, 0, 14, 6, 2, 20, 4, 13, 15, 7, 6, 11, 10, 0, 11],\n",
              " [4, 0, 14, 6, 2, 20, 4, 13, 15, 7, 6, 11, 10, 0, 11, 26, 4, 20, 22, 15],\n",
              " [20, 4, 13, 15, 7, 6, 11, 10, 0, 11, 26, 4, 20, 22, 15, 4, 10, 2, 3, 15],\n",
              " [6, 11, 10, 0, 11, 26, 4, 20, 22, 15, 4, 10, 2, 3, 15, 4, 6, 16, 4, 3],\n",
              " [26, 4, 20, 22, 15, 4, 10, 2, 3, 15, 4, 6, 16, 4, 3, 0, 17, 4, 0, 1],\n",
              " [4, 10, 2, 3, 15, 4, 6, 16, 4, 3, 0, 17, 4, 0, 1, 13, 4, 1, 15, 0],\n",
              " [4, 6, 16, 4, 3, 0, 17, 4, 0, 1, 13, 4, 1, 15, 0, 10, 3, 26, 26, 15],\n",
              " [0, 17, 4, 0, 1, 13, 4, 1, 15, 0, 10, 3, 26, 26, 15, 0, 10, 9, 4, 6],\n",
              " [13, 4, 1, 15, 0, 10, 3, 26, 26, 15, 0, 10, 9, 4, 6, 16, 4, 11, 6, 1],\n",
              " [10, 3, 26, 26, 15, 0, 10, 9, 4, 6, 16, 4, 11, 6, 1, 9, 20, 19, 20, 2],\n",
              " [0, 10, 9, 4, 6, 16, 4, 11, 6, 1, 9, 20, 19, 20, 2, 20, 19, 6, 1, 0],\n",
              " [16, 4, 11, 6, 1, 9, 20, 19, 20, 2, 20, 19, 6, 1, 0, 3, 4, 5, 6, 8],\n",
              " [9, 20, 19, 20, 2, 20, 19, 6, 1, 0, 3, 4, 5, 6, 8, 15, 10, 1, 0, 1],\n",
              " [20, 19, 6, 1, 0, 3, 4, 5, 6, 8, 15, 10, 1, 0, 1, 11, 15, 4, 20, 0],\n",
              " [3, 4, 5, 6, 8, 15, 10, 1, 0, 1, 11, 15, 4, 20, 0, 12, 15, 4, 22, 15],\n",
              " [15, 10, 1, 0, 1, 11, 15, 4, 20, 0, 12, 15, 4, 22, 15, 15, 13, 4, 23, 10],\n",
              " [11, 15, 4, 20, 0, 12, 15, 4, 22, 15, 15, 13, 4, 23, 10, 15, 9, 19, 13, 15],\n",
              " [12, 15, 4, 22, 15, 15, 13, 4, 23, 10, 15, 9, 19, 13, 15, 1, 20, 4, 20, 10],\n",
              " [15, 13, 4, 23, 10, 15, 9, 19, 13, 15, 1, 20, 4, 20, 10, 2, 7, 23, 4, 19],\n",
              " [15, 9, 19, 13, 15, 1, 20, 4, 20, 10, 2, 7, 23, 4, 19, 9, 4, 1, 6, 4],\n",
              " [1, 20, 4, 20, 10, 2, 7, 23, 4, 19, 9, 4, 1, 6, 4, 11, 3, 19, 1, 20],\n",
              " [2, 7, 23, 4, 19, 9, 4, 1, 6, 4, 11, 3, 19, 1, 20, 6, 1, 4, 6, 10],\n",
              " [9, 4, 1, 6, 4, 11, 3, 19, 1, 20, 6, 1, 4, 6, 10, 4, 1, 19, 25, 6],\n",
              " [11, 3, 19, 1, 20, 6, 1, 4, 6, 10, 4, 1, 19, 25, 6, 1, 4, 6, 10, 4],\n",
              " [6, 1, 4, 6, 10, 4, 1, 19, 25, 6, 1, 4, 6, 10, 4, 15, 8, 15, 1, 4],\n",
              " [4, 1, 19, 25, 6, 1, 4, 6, 10, 4, 15, 8, 15, 1, 4, 24, 6, 22, 1, 9],\n",
              " [1, 4, 6, 10, 4, 15, 8, 15, 1, 4, 24, 6, 22, 1, 9, 6, 1, 4, 22, 15],\n",
              " [15, 8, 15, 1, 4, 24, 6, 22, 1, 9, 6, 1, 4, 22, 15, 4, 17, 19, 3, 3],\n",
              " [24, 6, 22, 1, 9, 6, 1, 4, 22, 15, 4, 17, 19, 3, 3, 4, 1, 6, 20, 4],\n",
              " [6, 1, 4, 22, 15, 4, 17, 19, 3, 3, 4, 1, 6, 20, 4, 5, 6, 4, 21, 2],\n",
              " [4, 17, 19, 3, 3, 4, 1, 6, 20, 4, 5, 6, 4, 21, 2, 19, 15, 20, 3, 26],\n",
              " [4, 1, 6, 20, 4, 5, 6, 4, 21, 2, 19, 15, 20, 3, 26, 4, 19, 20, 4, 17],\n",
              " [5, 6, 4, 21, 2, 19, 15, 20, 3, 26, 4, 19, 20, 4, 17, 19, 3, 3, 4, 14],\n",
              " [19, 15, 20, 3, 26, 4, 19, 20, 4, 17, 19, 3, 3, 4, 14, 15, 4, 2, 5, 3],\n",
              " [4, 19, 20, 4, 17, 19, 3, 3, 4, 14, 15, 4, 2, 5, 3, 26, 4, 22, 15, 4],\n",
              " [19, 3, 3, 4, 14, 15, 4, 2, 5, 3, 26, 4, 22, 15, 4, 17, 19, 3, 3, 4],\n",
              " [15, 4, 2, 5, 3, 26, 4, 22, 15, 4, 17, 19, 3, 3, 4, 14, 15, 20, 10, 0],\n",
              " [26, 4, 22, 15, 4, 17, 19, 3, 3, 4, 14, 15, 20, 10, 0, 26, 4, 2, 9, 4],\n",
              " [17, 19, 3, 3, 4, 14, 15, 20, 10, 0, 26, 4, 2, 9, 4, 0, 1, 13, 4, 20],\n",
              " [14, 15, 20, 10, 0, 26, 4, 2, 9, 4, 0, 1, 13, 4, 20, 22, 15, 4, 10, 2],\n",
              " [26, 4, 2, 9, 4, 0, 1, 13, 4, 20, 22, 15, 4, 10, 2, 3, 15, 4, 6, 16],\n",
              " [0, 1, 13, 4, 20, 22, 15, 4, 10, 2, 3, 15, 4, 6, 16, 4, 3, 0, 17, 4],\n",
              " [22, 15, 4, 10, 2, 3, 15, 4, 6, 16, 4, 3, 0, 17, 4, 19, 1, 4, 20, 22],\n",
              " [3, 15, 4, 6, 16, 4, 3, 0, 17, 4, 19, 1, 4, 20, 22, 15, 4, 23, 10, 6],\n",
              " [4, 3, 0, 17, 4, 19, 1, 4, 20, 22, 15, 4, 23, 10, 6, 11, 15, 9, 9, 13],\n",
              " [19, 1, 4, 20, 22, 15, 4, 23, 10, 6, 11, 15, 9, 9, 13, 15, 16, 26, 19, 1],\n",
              " [15, 4, 23, 10, 6, 11, 15, 9, 9, 13, 15, 16, 26, 19, 1, 5, 4, 9, 2, 14],\n",
              " [11, 15, 9, 9, 13, 15, 16, 26, 19, 1, 5, 4, 9, 2, 14, 23, 6, 15, 1, 0],\n",
              " [15, 16, 26, 19, 1, 5, 4, 9, 2, 14, 23, 6, 15, 1, 0, 9, 4, 17, 19, 20],\n",
              " [5, 4, 9, 2, 14, 23, 6, 15, 1, 0, 9, 4, 17, 19, 20, 22, 22, 6, 3, 13],\n",
              " [23, 6, 15, 1, 0, 9, 4, 17, 19, 20, 22, 22, 6, 3, 13, 19, 1, 5, 4, 13],\n",
              " [9, 4, 17, 19, 20, 22, 22, 6, 3, 13, 19, 1, 5, 4, 13, 6, 11, 2, 7, 15],\n",
              " [22, 22, 6, 3, 13, 19, 1, 5, 4, 13, 6, 11, 2, 7, 15, 1, 20, 9, 4, 14],\n",
              " [19, 1, 5, 4, 13, 6, 11, 2, 7, 15, 1, 20, 9, 4, 14, 3, 6, 11, 12, 19],\n",
              " [6, 11, 2, 7, 15, 1, 20, 9, 4, 14, 3, 6, 11, 12, 19, 1, 5, 4, 17, 19],\n",
              " [1, 20, 9, 4, 14, 3, 6, 11, 12, 19, 1, 5, 4, 17, 19, 20, 1, 15, 9, 9],\n",
              " [3, 6, 11, 12, 19, 1, 5, 4, 17, 19, 20, 1, 15, 9, 9, 15, 9, 20, 22, 19],\n",
              " [1, 5, 4, 17, 19, 20, 1, 15, 9, 9, 15, 9, 20, 22, 19, 9, 4, 23, 10, 15],\n",
              " [20, 1, 15, 9, 9, 15, 9, 20, 22, 19, 9, 4, 23, 10, 15, 9, 19, 13, 15, 1],\n",
              " [15, 9, 20, 22, 19, 9, 4, 23, 10, 15, 9, 19, 13, 15, 1, 11, 26, 4, 19, 9],\n",
              " [9, 4, 23, 10, 15, 9, 19, 13, 15, 1, 11, 26, 4, 19, 9, 4, 16, 6, 2, 3],\n",
              " [9, 19, 13, 15, 1, 11, 26, 4, 19, 9, 4, 16, 6, 2, 3, 15, 13, 4, 17, 19],\n",
              " [11, 26, 4, 19, 9, 4, 16, 6, 2, 3, 15, 13, 4, 17, 19, 20, 22, 4, 13, 19],\n",
              " [4, 16, 6, 2, 3, 15, 13, 4, 17, 19, 20, 22, 4, 13, 19, 9, 10, 15, 9, 23],\n",
              " [15, 13, 4, 17, 19, 20, 22, 4, 13, 19, 9, 10, 15, 9, 23, 15, 11, 20, 4, 16],\n",
              " [20, 22, 4, 13, 19, 9, 10, 15, 9, 23, 15, 11, 20, 4, 16, 6, 10, 4, 10, 2],\n",
              " [9, 10, 15, 9, 23, 15, 11, 20, 4, 16, 6, 10, 4, 10, 2, 3, 15, 9, 4, 14],\n",
              " [15, 11, 20, 4, 16, 6, 10, 4, 10, 2, 3, 15, 9, 4, 14, 6, 2, 1, 13, 0],\n",
              " [6, 10, 4, 10, 2, 3, 15, 9, 4, 14, 6, 2, 1, 13, 0, 10, 19, 15, 9, 4],\n",
              " [3, 15, 9, 4, 14, 6, 2, 1, 13, 0, 10, 19, 15, 9, 4, 0, 1, 13, 4, 1],\n",
              " [6, 2, 1, 13, 0, 10, 19, 15, 9, 4, 0, 1, 13, 4, 1, 6, 10, 7, 9, 4],\n",
              " [10, 19, 15, 9, 4, 0, 1, 13, 4, 1, 6, 10, 7, 9, 4, 20, 10, 2, 7, 23],\n",
              " [0, 1, 13, 4, 1, 6, 10, 7, 9, 4, 20, 10, 2, 7, 23, 4, 17, 0, 3, 12],\n",
              " [6, 10, 7, 9, 4, 20, 10, 2, 7, 23, 4, 17, 0, 3, 12, 15, 13, 4, 0, 17],\n",
              " [20, 10, 2, 7, 23, 4, 17, 0, 3, 12, 15, 13, 4, 0, 17, 0, 26, 4, 16, 10],\n",
              " [4, 17, 0, 3, 12, 15, 13, 4, 0, 17, 0, 26, 4, 16, 10, 6, 7, 4, 7, 0],\n",
              " [15, 13, 4, 0, 17, 0, 26, 4, 16, 10, 6, 7, 4, 7, 0, 24, 6, 10, 4, 0],\n",
              " [0, 26, 4, 16, 10, 6, 7, 4, 7, 0, 24, 6, 10, 4, 0, 5, 10, 15, 15, 7],\n",
              " [6, 7, 4, 7, 0, 24, 6, 10, 4, 0, 5, 10, 15, 15, 7, 15, 1, 20, 9, 4],\n",
              " [24, 6, 10, 4, 0, 5, 10, 15, 15, 7, 15, 1, 20, 9, 4, 1, 15, 5, 6, 20],\n",
              " [5, 10, 15, 15, 7, 15, 1, 20, 9, 4, 1, 15, 5, 6, 20, 19, 0, 20, 15, 13],\n",
              " [15, 1, 20, 9, 4, 1, 15, 5, 6, 20, 19, 0, 20, 15, 13, 4, 14, 26, 4, 22],\n",
              " [1, 15, 5, 6, 20, 19, 0, 20, 15, 13, 4, 14, 26, 4, 22, 19, 9, 4, 23, 10],\n",
              " [19, 0, 20, 15, 13, 4, 14, 26, 4, 22, 19, 9, 4, 23, 10, 15, 13, 15, 11, 15],\n",
              " [4, 14, 26, 4, 22, 19, 9, 4, 23, 10, 15, 13, 15, 11, 15, 9, 9, 6, 10, 9],\n",
              " [19, 9, 4, 23, 10, 15, 13, 15, 11, 15, 9, 9, 6, 10, 9, 20, 22, 15, 4, 19],\n",
              " [15, 13, 15, 11, 15, 9, 9, 6, 10, 9, 20, 22, 15, 4, 19, 10, 0, 1, 4, 1],\n",
              " [9, 9, 6, 10, 9, 20, 22, 15, 4, 19, 10, 0, 1, 4, 1, 2, 11, 3, 15, 0],\n",
              " [20, 22, 15, 4, 19, 10, 0, 1, 4, 1, 2, 11, 3, 15, 0, 10, 4, 13, 15, 0],\n",
              " [10, 0, 1, 4, 1, 2, 11, 3, 15, 0, 10, 4, 13, 15, 0, 3, 4, 20, 22, 15],\n",
              " [2, 11, 3, 15, 0, 10, 4, 13, 15, 0, 3, 4, 20, 22, 15, 4, 23, 0, 10, 19],\n",
              " [10, 4, 13, 15, 0, 3, 4, 20, 22, 15, 4, 23, 0, 10, 19, 9, 4, 11, 3, 19],\n",
              " [3, 4, 20, 22, 15, 4, 23, 0, 10, 19, 9, 4, 11, 3, 19, 7, 0, 20, 15, 4],\n",
              " [4, 23, 0, 10, 19, 9, 4, 11, 3, 19, 7, 0, 20, 15, 4, 0, 11, 11, 6, 10],\n",
              " [9, 4, 11, 3, 19, 7, 0, 20, 15, 4, 0, 11, 11, 6, 10, 13, 0, 1, 13, 4],\n",
              " [7, 0, 20, 15, 4, 0, 11, 11, 6, 10, 13, 0, 1, 13, 4, 20, 22, 15, 4, 2],\n",
              " [0, 11, 11, 6, 10, 13, 0, 1, 13, 4, 20, 22, 15, 4, 2, 1, 19, 20, 15, 13],\n",
              " [13, 0, 1, 13, 4, 20, 22, 15, 4, 2, 1, 19, 20, 15, 13, 4, 9, 20, 0, 20],\n",
              " [20, 22, 15, 4, 2, 1, 19, 20, 15, 13, 4, 9, 20, 0, 20, 15, 9, 4, 17, 6],\n",
              " [1, 19, 20, 15, 13, 4, 9, 20, 0, 20, 15, 9, 4, 17, 6, 10, 13, 4, 0, 9],\n",
              " [4, 9, 20, 0, 20, 15, 9, 4, 17, 6, 10, 13, 4, 0, 9, 4, 14, 6, 1, 13],\n",
              " [15, 9, 4, 17, 6, 10, 13, 4, 0, 9, 4, 14, 6, 1, 13, 4, 19, 9, 4, 1],\n",
              " [10, 13, 4, 0, 9, 4, 14, 6, 1, 13, 4, 19, 9, 4, 1, 6, 4, 7, 6, 10],\n",
              " [4, 14, 6, 1, 13, 4, 19, 9, 4, 1, 6, 4, 7, 6, 10, 15, 4, 3, 6, 6],\n",
              " [4, 19, 9, 4, 1, 6, 4, 7, 6, 10, 15, 4, 3, 6, 6, 12, 4, 0, 20, 4],\n",
              " [6, 4, 7, 6, 10, 15, 4, 3, 6, 6, 12, 4, 0, 20, 4, 20, 22, 15, 4, 15],\n",
              " [15, 4, 3, 6, 6, 12, 4, 0, 20, 4, 20, 22, 15, 4, 15, 0, 9, 15, 4, 17],\n",
              " [12, 4, 0, 20, 4, 20, 22, 15, 4, 15, 0, 9, 15, 4, 17, 19, 20, 22, 4, 17],\n",
              " [20, 22, 15, 4, 15, 0, 9, 15, 4, 17, 19, 20, 22, 4, 17, 22, 19, 11, 22, 4],\n",
              " [0, 9, 15, 4, 17, 19, 20, 22, 4, 17, 22, 19, 11, 22, 4, 22, 15, 4, 13, 19],\n",
              " [19, 20, 22, 4, 17, 22, 19, 11, 22, 4, 22, 15, 4, 13, 19, 9, 11, 0, 10, 13],\n",
              " [22, 19, 11, 22, 4, 22, 15, 4, 13, 19, 9, 11, 0, 10, 13, 9, 4, 9, 2, 23],\n",
              " [22, 15, 4, 13, 19, 9, 11, 0, 10, 13, 9, 4, 9, 2, 23, 23, 6, 10, 20, 15],\n",
              " [9, 11, 0, 10, 13, 9, 4, 9, 2, 23, 23, 6, 10, 20, 15, 10, 9, 0, 9, 12],\n",
              " [9, 4, 9, 2, 23, 23, 6, 10, 20, 15, 10, 9, 0, 9, 12, 4, 16, 6, 10, 7],\n",
              " [23, 6, 10, 20, 15, 10, 9, 0, 9, 12, 4, 16, 6, 10, 7, 15, 10, 4, 0, 20],\n",
              " [10, 9, 0, 9, 12, 4, 16, 6, 10, 7, 15, 10, 4, 0, 20, 20, 6, 10, 1, 15],\n",
              " [4, 16, 6, 10, 7, 15, 10, 4, 0, 20, 20, 6, 10, 1, 15, 26, 4, 5, 15, 1],\n",
              " [15, 10, 4, 0, 20, 20, 6, 10, 1, 15, 26, 4, 5, 15, 1, 15, 10, 0, 3, 4],\n",
              " [20, 6, 10, 1, 15, 26, 4, 5, 15, 1, 15, 10, 0, 3, 4, 24, 15, 16, 16, 4],\n",
              " [26, 4, 5, 15, 1, 15, 10, 0, 3, 4, 24, 15, 16, 16, 4, 9, 15, 9, 9, 19],\n",
              " [15, 10, 0, 3, 4, 24, 15, 16, 16, 4, 9, 15, 9, 9, 19, 6, 1, 9, 4, 6],\n",
              " [24, 15, 16, 16, 4, 9, 15, 9, 9, 19, 6, 1, 9, 4, 6, 10, 4, 16, 6, 10],\n",
              " [9, 15, 9, 9, 19, 6, 1, 9, 4, 6, 10, 4, 16, 6, 10, 7, 15, 10, 4, 9],\n",
              " [6, 1, 9, 4, 6, 10, 4, 16, 6, 10, 7, 15, 10, 4, 9, 15, 11, 10, 15, 20],\n",
              " [10, 4, 16, 6, 10, 7, 15, 10, 4, 9, 15, 11, 10, 15, 20, 0, 10, 26, 4, 6],\n",
              " [7, 15, 10, 4, 9, 15, 11, 10, 15, 20, 0, 10, 26, 4, 6, 16, 4, 9, 20, 0],\n",
              " [15, 11, 10, 15, 20, 0, 10, 26, 4, 6, 16, 4, 9, 20, 0, 20, 15, 4, 10, 15],\n",
              " [0, 10, 26, 4, 6, 16, 4, 9, 20, 0, 20, 15, 4, 10, 15, 25, 4, 20, 19, 3],\n",
              " [16, 4, 9, 20, 0, 20, 15, 4, 10, 15, 25, 4, 20, 19, 3, 3, 15, 10, 9, 6],\n",
              " [20, 15, 4, 10, 15, 25, 4, 20, 19, 3, 3, 15, 10, 9, 6, 1, 4, 0, 9, 12],\n",
              " [25, 4, 20, 19, 3, 3, 15, 10, 9, 6, 1, 4, 0, 9, 12, 4, 6, 2, 10, 4],\n",
              " [3, 15, 10, 9, 6, 1, 4, 0, 9, 12, 4, 6, 2, 10, 4, 0, 3, 3, 19, 15],\n",
              " [1, 4, 0, 9, 12, 4, 6, 2, 10, 4, 0, 3, 3, 19, 15, 9, 4, 22, 15, 10],\n",
              " [4, 6, 2, 10, 4, 0, 3, 3, 19, 15, 9, 4, 22, 15, 10, 15, 4, 20, 6, 13],\n",
              " [0, 3, 3, 19, 15, 9, 4, 22, 15, 10, 15, 4, 20, 6, 13, 0, 26, 4, 5, 6],\n",
              " [9, 4, 22, 15, 10, 15, 4, 20, 6, 13, 0, 26, 4, 5, 6, 1, 15, 4, 20, 6],\n",
              " [15, 4, 20, 6, 13, 0, 26, 4, 5, 6, 1, 15, 4, 20, 6, 7, 6, 10, 10, 6],\n",
              " [0, 26, 4, 5, 6, 1, 15, 4, 20, 6, 7, 6, 10, 10, 6, 17, 1, 0, 20, 6],\n",
              " [1, 15, 4, 20, 6, 7, 6, 10, 10, 6, 17, 1, 0, 20, 6, 4, 20, 22, 15, 4],\n",
              " [7, 6, 10, 10, 6, 17, 1, 0, 20, 6, 4, 20, 22, 15, 4, 12, 2, 10, 13, 9],\n",
              " [17, 1, 0, 20, 6, 4, 20, 22, 15, 4, 12, 2, 10, 13, 9, 4, 19, 1, 4, 9],\n",
              " [4, 20, 22, 15, 4, 12, 2, 10, 13, 9, 4, 19, 1, 4, 9, 26, 10, 19, 0, 16],\n",
              " [12, 2, 10, 13, 9, 4, 19, 1, 4, 9, 26, 10, 19, 0, 16, 10, 6, 7, 4, 22],\n",
              " [4, 19, 1, 4, 9, 26, 10, 19, 0, 16, 10, 6, 7, 4, 22, 19, 9, 4, 15, 0],\n",
              " [26, 10, 19, 0, 16, 10, 6, 7, 4, 22, 19, 9, 4, 15, 0, 10, 3, 19, 15, 9],\n",
              " [10, 6, 7, 4, 22, 19, 9, 4, 15, 0, 10, 3, 19, 15, 9, 20, 4, 13, 0, 26],\n",
              " [19, 9, 4, 15, 0, 10, 3, 19, 15, 9, 20, 4, 13, 0, 26, 9, 4, 0, 9, 4],\n",
              " [10, 3, 19, 15, 9, 20, 4, 13, 0, 26, 9, 4, 0, 9, 4, 0, 4, 11, 0, 1],\n",
              " [20, 4, 13, 0, 26, 9, 4, 0, 9, 4, 0, 4, 11, 0, 1, 13, 19, 13, 0, 20],\n",
              " [9, 4, 0, 9, 4, 0, 4, 11, 0, 1, 13, 19, 13, 0, 20, 15, 4, 20, 10, 2],\n",
              " [0, 4, 11, 0, 1, 13, 19, 13, 0, 20, 15, 4, 20, 10, 2, 7, 23, 4, 8, 6],\n",
              " [13, 19, 13, 0, 20, 15, 4, 20, 10, 2, 7, 23, 4, 8, 6, 19, 11, 15, 13, 4],\n",
              " [15, 4, 20, 10, 2, 7, 23, 4, 8, 6, 19, 11, 15, 13, 4, 0, 23, 23, 0, 3],\n",
              " [7, 23, 4, 8, 6, 19, 11, 15, 13, 4, 0, 23, 23, 0, 3, 3, 19, 1, 5, 3],\n",
              " [19, 11, 15, 13, 4, 0, 23, 23, 0, 3, 3, 19, 1, 5, 3, 26, 4, 0, 10, 10],\n",
              " [0, 23, 23, 0, 3, 3, 19, 1, 5, 3, 26, 4, 0, 10, 10, 6, 5, 0, 1, 20],\n",
              " [3, 19, 1, 5, 3, 26, 4, 0, 10, 10, 6, 5, 0, 1, 20, 4, 8, 19, 15, 17],\n",
              " [26, 4, 0, 10, 10, 6, 5, 0, 1, 20, 4, 8, 19, 15, 17, 9, 4, 0, 14, 6],\n",
              " [6, 5, 0, 1, 20, 4, 8, 19, 15, 17, 9, 4, 0, 14, 6, 2, 20, 4, 20, 22],\n",
              " [4, 8, 19, 15, 17, 9, 4, 0, 14, 6, 2, 20, 4, 20, 22, 15, 4, 23, 6, 17],\n",
              " [9, 4, 0, 14, 6, 2, 20, 4, 20, 22, 15, 4, 23, 6, 17, 15, 10, 4, 6, 16],\n",
              " [2, 20, 4, 20, 22, 15, 4, 23, 6, 17, 15, 10, 4, 6, 16, 4, 20, 22, 15, 4],\n",
              " [15, 4, 23, 6, 17, 15, 10, 4, 6, 16, 4, 20, 22, 15, 4, 23, 10, 15, 9, 19],\n",
              " [15, 10, 4, 6, 16, 4, 20, 22, 15, 4, 23, 10, 15, 9, 19, 13, 15, 1, 11, 26],\n",
              " [4, 20, 22, 15, 4, 23, 10, 15, 9, 19, 13, 15, 1, 11, 26, 4, 7, 15, 25, 19],\n",
              " [23, 10, 15, 9, 19, 13, 15, 1, 11, 26, 4, 7, 15, 25, 19, 11, 6, 4, 17, 19],\n",
              " [13, 15, 1, 11, 26, 4, 7, 15, 25, 19, 11, 6, 4, 17, 19, 3, 3, 4, 23, 0],\n",
              " [4, 7, 15, 25, 19, 11, 6, 4, 17, 19, 3, 3, 4, 23, 0, 26, 4, 16, 6, 10],\n",
              " [11, 6, 4, 17, 19, 3, 3, 4, 23, 0, 26, 4, 16, 6, 10, 4, 20, 22, 15, 4],\n",
              " [3, 3, 4, 23, 0, 26, 4, 16, 6, 10, 4, 20, 22, 15, 4, 17, 0, 3, 3, 19],\n",
              " [26, 4, 16, 6, 10, 4, 20, 22, 15, 4, 17, 0, 3, 3, 19, 4, 0, 3, 6, 1],\n",
              " [4, 20, 22, 15, 4, 17, 0, 3, 3, 19, 4, 0, 3, 6, 1, 15, 4, 11, 0, 1],\n",
              " [17, 0, 3, 3, 19, 4, 0, 3, 6, 1, 15, 4, 11, 0, 1, 4, 16, 19, 25, 4],\n",
              " [4, 0, 3, 6, 1, 15, 4, 11, 0, 1, 4, 16, 19, 25, 4, 19, 20, 4, 7, 26],\n",
              " [15, 4, 11, 0, 1, 4, 16, 19, 25, 4, 19, 20, 4, 7, 26, 4, 23, 10, 19, 7],\n",
              " [4, 16, 19, 25, 4, 19, 20, 4, 7, 26, 4, 23, 10, 19, 7, 0, 10, 26, 4, 11],\n",
              " [19, 20, 4, 7, 26, 4, 23, 10, 19, 7, 0, 10, 26, 4, 11, 6, 1, 9, 2, 3],\n",
              " [4, 23, 10, 19, 7, 0, 10, 26, 4, 11, 6, 1, 9, 2, 3, 20, 0, 1, 20, 4],\n",
              " [0, 10, 26, 4, 11, 6, 1, 9, 2, 3, 20, 0, 1, 20, 4, 19, 9, 4, 7, 26],\n",
              " [6, 1, 9, 2, 3, 20, 0, 1, 20, 4, 19, 9, 4, 7, 26, 9, 15, 3, 16, 4],\n",
              " [20, 0, 1, 20, 4, 19, 9, 4, 7, 26, 9, 15, 3, 16, 4, 22, 19, 9, 4, 23],\n",
              " [19, 9, 4, 7, 26, 9, 15, 3, 16, 4, 22, 19, 9, 4, 23, 6, 9, 9, 15, 9],\n",
              " [9, 15, 3, 16, 4, 22, 19, 9, 4, 23, 6, 9, 9, 15, 9, 9, 19, 8, 15, 1],\n",
              " [22, 19, 9, 4, 23, 6, 9, 9, 15, 9, 9, 19, 8, 15, 1, 15, 9, 9, 4, 6],\n",
              " [6, 9, 9, 15, 9, 9, 19, 8, 15, 1, 15, 9, 9, 4, 6, 8, 15, 10, 4, 23],\n",
              " [9, 19, 8, 15, 1, 15, 9, 9, 4, 6, 8, 15, 10, 4, 23, 15, 6, 23, 3, 15],\n",
              " [15, 9, 9, 4, 6, 8, 15, 10, 4, 23, 15, 6, 23, 3, 15, 4, 0, 1, 13, 4],\n",
              " [8, 15, 10, 4, 23, 15, 6, 23, 3, 15, 4, 0, 1, 13, 4, 19, 1, 9, 20, 19],\n",
              " [15, 6, 23, 3, 15, 4, 0, 1, 13, 4, 19, 1, 9, 20, 19, 20, 2, 20, 19, 6],\n",
              " [4, 0, 1, 13, 4, 19, 1, 9, 20, 19, 20, 2, 20, 19, 6, 1, 9, 4, 19, 9],\n",
              " [19, 1, 9, 20, 19, 20, 2, 20, 19, 6, 1, 9, 4, 19, 9, 4, 0, 3, 9, 6],\n",
              " [20, 2, 20, 19, 6, 1, 9, 4, 19, 9, 4, 0, 3, 9, 6, 4, 1, 6, 20, 4],\n",
              " [1, 9, 4, 19, 9, 4, 0, 3, 9, 6, 4, 1, 6, 20, 4, 1, 15, 17, 4, 7],\n",
              " [4, 0, 3, 9, 6, 4, 1, 6, 20, 4, 1, 15, 17, 4, 7, 26, 4, 5, 15, 1],\n",
              " [4, 1, 6, 20, 4, 1, 15, 17, 4, 7, 26, 4, 5, 15, 1, 15, 10, 0, 3, 9],\n",
              " [1, 15, 17, 4, 7, 26, 4, 5, 15, 1, 15, 10, 0, 3, 9, 4, 0, 1, 13, 4],\n",
              " [26, 4, 5, 15, 1, 15, 10, 0, 3, 9, 4, 0, 1, 13, 4, 7, 26, 4, 7, 19],\n",
              " [15, 10, 0, 3, 9, 4, 0, 1, 13, 4, 7, 26, 4, 7, 19, 3, 19, 20, 0, 10],\n",
              " [4, 0, 1, 13, 4, 7, 26, 4, 7, 19, 3, 19, 20, 0, 10, 26, 4, 7, 26, 4],\n",
              " [7, 26, 4, 7, 19, 3, 19, 20, 0, 10, 26, 4, 7, 26, 4, 0, 16, 10, 19, 11],\n",
              " [3, 19, 20, 0, 10, 26, 4, 7, 26, 4, 0, 16, 10, 19, 11, 0, 1, 4, 0, 7],\n",
              " [26, 4, 7, 26, 4, 0, 16, 10, 19, 11, 0, 1, 4, 0, 7, 15, 10, 19, 11, 0],\n",
              " [0, 16, 10, 19, 11, 0, 1, 4, 0, 7, 15, 10, 19, 11, 0, 1, 6, 1, 3, 26],\n",
              " [0, 1, 4, 0, 7, 15, 10, 19, 11, 0, 1, 6, 1, 3, 26, 4, 7, 6, 1, 20],\n",
              " [15, 10, 19, 11, 0, 1, 6, 1, 3, 26, 4, 7, 6, 1, 20, 22, 9, 4, 19, 1],\n",
              " [1, 6, 1, 3, 26, 4, 7, 6, 1, 20, 22, 9, 4, 19, 1, 20, 6, 4, 22, 19],\n",
              " [4, 7, 6, 1, 20, 22, 9, 4, 19, 1, 20, 6, 4, 22, 19, 9, 4, 23, 10, 15],\n",
              " [22, 9, 4, 19, 1, 20, 6, 4, 22, 19, 9, 4, 23, 10, 15, 9, 19, 13, 15, 1],\n",
              " [20, 6, 4, 22, 19, 9, 4, 23, 10, 15, 9, 19, 13, 15, 1, 11, 26, 4, 20, 10],\n",
              " [9, 4, 23, 10, 15, 9, 19, 13, 15, 1, 11, 26, 4, 20, 10, 2, 7, 23, 4, 13],\n",
              " [9, 19, 13, 15, 1, 11, 26, 4, 20, 10, 2, 7, 23, 4, 13, 19, 9, 23, 0, 10],\n",
              " [11, 26, 4, 20, 10, 2, 7, 23, 4, 13, 19, 9, 23, 0, 10, 0, 5, 15, 13, 4],\n",
              " [2, 7, 23, 4, 13, 19, 9, 23, 0, 10, 0, 5, 15, 13, 4, 13, 15, 7, 6, 11],\n",
              " [19, 9, 23, 0, 10, 0, 5, 15, 13, 4, 13, 15, 7, 6, 11, 10, 0, 20, 19, 11],\n",
              " [0, 5, 15, 13, 4, 13, 15, 7, 6, 11, 10, 0, 20, 19, 11, 4, 0, 3, 3, 19],\n",
              " [13, 15, 7, 6, 11, 10, 0, 20, 19, 11, 4, 0, 3, 3, 19, 15, 9, 4, 19, 1],\n",
              " [10, 0, 20, 19, 11, 4, 0, 3, 3, 19, 15, 9, 4, 19, 1, 11, 3, 2, 13, 19],\n",
              " [4, 0, 3, 3, 19, 15, 9, 4, 19, 1, 11, 3, 2, 13, 19, 1, 5, 4, 5, 15],\n",
              " [15, 9, 4, 19, 1, 11, 3, 2, 13, 19, 1, 5, 4, 5, 15, 10, 7, 0, 1, 26],\n",
              " [11, 3, 2, 13, 19, 1, 5, 4, 5, 15, 10, 7, 0, 1, 26, 9, 4, 0, 1, 5],\n",
              " [1, 5, 4, 5, 15, 10, 7, 0, 1, 26, 9, 4, 0, 1, 5, 15, 3, 0, 4, 7],\n",
              " [10, 7, 0, 1, 26, 9, 4, 0, 1, 5, 15, 3, 0, 4, 7, 15, 10, 12, 15, 3],\n",
              " [9, 4, 0, 1, 5, 15, 3, 0, 4, 7, 15, 10, 12, 15, 3, 4, 10, 2, 19, 1],\n",
              " [15, 3, 0, 4, 7, 15, 10, 12, 15, 3, 4, 10, 2, 19, 1, 19, 1, 5, 4, 5],\n",
              " [15, 10, 12, 15, 3, 4, 10, 2, 19, 1, 19, 1, 5, 4, 5, 15, 10, 7, 0, 1],\n",
              " [4, 10, 2, 19, 1, 19, 1, 5, 4, 5, 15, 10, 7, 0, 1, 26, 4, 0, 1, 13],\n",
              " [19, 1, 5, 4, 5, 15, 10, 7, 0, 1, 26, 4, 0, 1, 13, 4, 14, 10, 19, 20],\n",
              " [15, 10, 7, 0, 1, 26, 4, 0, 1, 13, 4, 14, 10, 19, 20, 0, 19, 1, 9, 4],\n",
              " [26, 4, 0, 1, 13, 4, 14, 10, 19, 20, 0, 19, 1, 9, 4, 20, 22, 15, 10, 15],\n",
              " [4, 14, 10, 19, 20, 0, 19, 1, 9, 4, 20, 22, 15, 10, 15, 9, 0, 4, 7, 0],\n",
              " [0, 19, 1, 9, 4, 20, 22, 15, 10, 15, 9, 0, 4, 7, 0, 26, 4, 16, 6, 6],\n",
              " [20, 22, 15, 10, 15, 9, 0, 4, 7, 0, 26, 4, 16, 6, 6, 3, 19, 9, 22, 1],\n",
              " [9, 0, 4, 7, 0, 26, 4, 16, 6, 6, 3, 19, 9, 22, 1, 6, 20, 0, 14, 3],\n",
              " [26, 4, 16, 6, 6, 3, 19, 9, 22, 1, 6, 20, 0, 14, 3, 26, 4, 14, 6, 20],\n",
              " [3, 19, 9, 22, 1, 6, 20, 0, 14, 3, 26, 4, 14, 6, 20, 22, 4, 17, 6, 7],\n",
              " [6, 20, 0, 14, 3, 26, 4, 14, 6, 20, 22, 4, 17, 6, 7, 15, 1, 19, 1, 4],\n",
              " [26, 4, 14, 6, 20, 22, 4, 17, 6, 7, 15, 1, 19, 1, 4, 16, 0, 8, 6, 10],\n",
              " [22, 4, 17, 6, 7, 15, 1, 19, 1, 4, 16, 0, 8, 6, 10, 4, 6, 16, 4, 9],\n",
              " [15, 1, 19, 1, 4, 16, 0, 8, 6, 10, 4, 6, 16, 4, 9, 20, 10, 6, 1, 5],\n",
              " [16, 0, 8, 6, 10, 4, 6, 16, 4, 9, 20, 10, 6, 1, 5, 0, 10, 7, 4, 3],\n",
              " [4, 6, 16, 4, 9, 20, 10, 6, 1, 5, 0, 10, 7, 4, 3, 15, 0, 13, 15, 10],\n",
              " [20, 10, 6, 1, 5, 0, 10, 7, 4, 3, 15, 0, 13, 15, 10, 9, 4, 9, 2, 11],\n",
              " [0, 10, 7, 4, 3, 15, 0, 13, 15, 10, 9, 4, 9, 2, 11, 22, 4, 0, 9, 4],\n",
              " [15, 0, 13, 15, 10, 9, 4, 9, 2, 11, 22, 4, 0, 9, 4, 1, 6, 10, 20, 22],\n",
              " [9, 4, 9, 2, 11, 22, 4, 0, 9, 4, 1, 6, 10, 20, 22, 4, 12, 6, 10, 15],\n",
              " [22, 4, 0, 9, 4, 1, 6, 10, 20, 22, 4, 12, 6, 10, 15, 0, 9, 4, 12, 19],\n",
              " [1, 6, 10, 20, 22, 4, 12, 6, 10, 15, 0, 9, 4, 12, 19, 7, 4, 24, 6, 1],\n",
              " [4, 12, 6, 10, 15, 0, 9, 4, 12, 19, 7, 4, 24, 6, 1, 5, 4, 2, 1, 4],\n",
              " [0, 9, 4, 12, 19, 7, 4, 24, 6, 1, 5, 4, 2, 1, 4, 17, 22, 6, 4, 17],\n",
              " [7, 4, 24, 6, 1, 5, 4, 2, 1, 4, 17, 22, 6, 4, 17, 10, 6, 20, 15, 4],\n",
              " [5, 4, 2, 1, 4, 17, 22, 6, 4, 17, 10, 6, 20, 15, 4, 22, 19, 7, 4, 14],\n",
              " [17, 22, 6, 4, 17, 10, 6, 20, 15, 4, 22, 19, 7, 4, 14, 15, 0, 2, 20, 19],\n",
              " [10, 6, 20, 15, 4, 22, 19, 7, 4, 14, 15, 0, 2, 20, 19, 16, 2, 3, 4, 3],\n",
              " [22, 19, 7, 4, 14, 15, 0, 2, 20, 19, 16, 2, 3, 4, 3, 15, 20, 20, 15, 10],\n",
              " [15, 0, 2, 20, 19, 16, 2, 3, 4, 3, 15, 20, 20, 15, 10, 9, 4, 9, 0, 2],\n",
              " [16, 2, 3, 4, 3, 15, 20, 20, 15, 10, 9, 4, 9, 0, 2, 13, 19, 4, 0, 10],\n",
              " [15, 20, 20, 15, 10, 9, 4, 9, 0, 2, 13, 19, 4, 0, 10, 0, 14, 19, 0, 9],\n",
              " [9, 4, 9, 0, 2, 13, 19, 4, 0, 10, 0, 14, 19, 0, 9, 4, 7, 6, 22, 0],\n",
              " [13, 19, 4, 0, 10, 0, 14, 19, 0, 9, 4, 7, 6, 22, 0, 7, 7, 15, 13, 4],\n",
              " [0, 14, 19, 0, 9, 4, 7, 6, 22, 0, 7, 7, 15, 13, 4, 14, 19, 1, 4, 9],\n",
              " [4, 7, 6, 22, 0, 7, 7, 15, 13, 4, 14, 19, 1, 4, 9, 0, 3, 7, 0, 1],\n",
              " [7, 7, 15, 13, 4, 14, 19, 1, 4, 9, 0, 3, 7, 0, 1, 4, 8, 15, 10, 26],\n",
              " [14, 19, 1, 4, 9, 0, 3, 7, 0, 1, 4, 8, 15, 10, 26, 4, 5, 6, 6, 13],\n",
              " [0, 3, 7, 0, 1, 4, 8, 15, 10, 26, 4, 5, 6, 6, 13, 4, 0, 3, 3, 26],\n",
              " [4, 8, 15, 10, 26, 4, 5, 6, 6, 13, 4, 0, 3, 3, 26, 4, 20, 2, 10, 12],\n",
              " [4, 5, 6, 6, 13, 4, 0, 3, 3, 26, 4, 20, 2, 10, 12, 15, 26, 9, 4, 10],\n",
              " [4, 0, 3, 3, 26, 4, 20, 2, 10, 12, 15, 26, 9, 4, 10, 15, 11, 15, 23, 4],\n",
              " [4, 20, 2, 10, 12, 15, 26, 9, 4, 10, 15, 11, 15, 23, 4, 20, 0, 26, 26, 19],\n",
              " [15, 26, 9, 4, 10, 15, 11, 15, 23, 4, 20, 0, 26, 26, 19, 23, 4, 15, 10, 13],\n",
              " [15, 11, 15, 23, 4, 20, 0, 26, 26, 19, 23, 4, 15, 10, 13, 6, 5, 0, 1, 4],\n",
              " [20, 0, 26, 26, 19, 23, 4, 15, 10, 13, 6, 5, 0, 1, 4, 5, 10, 15, 0, 20],\n",
              " [23, 4, 15, 10, 13, 6, 5, 0, 1, 4, 5, 10, 15, 0, 20, 4, 16, 10, 19, 15],\n",
              " [6, 5, 0, 1, 4, 5, 10, 15, 0, 20, 4, 16, 10, 19, 15, 1, 13, 9, 22, 19],\n",
              " [5, 10, 15, 0, 20, 4, 16, 10, 19, 15, 1, 13, 9, 22, 19, 23, 4, 0, 1, 13],\n",
              " [4, 16, 10, 19, 15, 1, 13, 9, 22, 19, 23, 4, 0, 1, 13, 4, 20, 22, 15, 4],\n",
              " [1, 13, 9, 22, 19, 23, 4, 0, 1, 13, 4, 20, 22, 15, 4, 23, 22, 19, 3, 19],\n",
              " [23, 4, 0, 1, 13, 4, 20, 22, 15, 4, 23, 22, 19, 3, 19, 23, 23, 19, 1, 15],\n",
              " [4, 20, 22, 15, 4, 23, 22, 19, 3, 19, 23, 23, 19, 1, 15, 9, 4, 10, 6, 13],\n",
              " [23, 22, 19, 3, 19, 23, 23, 19, 1, 15, 9, 4, 10, 6, 13, 10, 19, 5, 6, 4],\n",
              " [23, 23, 19, 1, 15, 9, 4, 10, 6, 13, 10, 19, 5, 6, 4, 13, 2, 20, 15, 10],\n",
              " [9, 4, 10, 6, 13, 10, 19, 5, 6, 4, 13, 2, 20, 15, 10, 20, 15, 4, 5, 10],\n",
              " [10, 19, 5, 6, 4, 13, 2, 20, 15, 10, 20, 15, 4, 5, 10, 15, 0, 20, 4, 10],\n",
              " [13, 2, 20, 15, 10, 20, 15, 4, 5, 10, 15, 0, 20, 4, 10, 15, 3, 0, 20, 19],\n",
              " [20, 15, 4, 5, 10, 15, 0, 20, 4, 10, 15, 3, 0, 20, 19, 6, 1, 9, 22, 19],\n",
              " [15, 0, 20, 4, 10, 15, 3, 0, 20, 19, 6, 1, 9, 22, 19, 23, 4, 20, 10, 2],\n",
              " [15, 3, 0, 20, 19, 6, 1, 9, 22, 19, 23, 4, 20, 10, 2, 7, 23, 4, 22, 15],\n",
              " [6, 1, 9, 22, 19, 23, 4, 20, 10, 2, 7, 23, 4, 22, 15, 0, 23, 9, 4, 23],\n",
              " [23, 4, 20, 10, 2, 7, 23, 4, 22, 15, 0, 23, 9, 4, 23, 10, 0, 19, 9, 15],\n",
              " [7, 23, 4, 22, 15, 0, 23, 9, 4, 23, 10, 0, 19, 9, 15, 4, 6, 1, 4, 10],\n",
              " [0, 23, 9, 4, 23, 10, 0, 19, 9, 15, 4, 6, 1, 4, 10, 2, 9, 9, 19, 0],\n",
              " [10, 0, 19, 9, 15, 4, 6, 1, 4, 10, 2, 9, 9, 19, 0, 9, 4, 8, 3, 0],\n",
              " [4, 6, 1, 4, 10, 2, 9, 9, 19, 0, 9, 4, 8, 3, 0, 13, 19, 7, 19, 10],\n",
              " [2, 9, 9, 19, 0, 9, 4, 8, 3, 0, 13, 19, 7, 19, 10, 4, 23, 2, 20, 19],\n",
              " [9, 4, 8, 3, 0, 13, 19, 7, 19, 10, 4, 23, 2, 20, 19, 1, 4, 22, 15, 9],\n",
              " [13, 19, 7, 19, 10, 4, 23, 2, 20, 19, 1, 4, 22, 15, 9, 4, 0, 4, 9, 20],\n",
              " [4, 23, 2, 20, 19, 1, 4, 22, 15, 9, 4, 0, 4, 9, 20, 10, 6, 1, 5, 4],\n",
              " [1, 4, 22, 15, 9, 4, 0, 4, 9, 20, 10, 6, 1, 5, 4, 3, 15, 0, 13, 15],\n",
              " [4, 0, 4, 9, 20, 10, 6, 1, 5, 4, 3, 15, 0, 13, 15, 10, 4, 0, 1, 13],\n",
              " [10, 6, 1, 5, 4, 3, 15, 0, 13, 15, 10, 4, 0, 1, 13, 4, 13, 0, 26, 9],\n",
              " [3, 15, 0, 13, 15, 10, 4, 0, 1, 13, 4, 13, 0, 26, 9, 4, 0, 16, 20, 15],\n",
              " [10, 4, 0, 1, 13, 4, 13, 0, 26, 9, 4, 0, 16, 20, 15, 10, 4, 10, 15, 8],\n",
              " [4, 13, 0, 26, 9, 4, 0, 16, 20, 15, 10, 4, 10, 15, 8, 15, 0, 3, 19, 1],\n",
              " [4, 0, 16, 20, 15, 10, 4, 10, 15, 8, 15, 0, 3, 19, 1, 5, 4, 22, 19, 9],\n",
              " [10, 4, 10, 15, 8, 15, 0, 3, 19, 1, 5, 4, 22, 19, 9, 4, 17, 6, 10, 13],\n",
              " [15, 0, 3, 19, 1, 5, 4, 22, 19, 9, 4, 17, 6, 10, 13, 9, 4, 23, 10, 15],\n",
              " [5, 4, 22, 19, 9, 4, 17, 6, 10, 13, 9, 4, 23, 10, 15, 9, 9, 2, 10, 19],\n",
              " [4, 17, 6, 10, 13, 9, 4, 23, 10, 15, 9, 9, 2, 10, 19, 1, 5, 4, 2, 12],\n",
              " [9, 4, 23, 10, 15, 9, 9, 2, 10, 19, 1, 5, 4, 2, 12, 10, 0, 19, 1, 19],\n",
              " [9, 9, 2, 10, 19, 1, 5, 4, 2, 12, 10, 0, 19, 1, 19, 0, 1, 4, 23, 10],\n",
              " [1, 5, 4, 2, 12, 10, 0, 19, 1, 19, 0, 1, 4, 23, 10, 15, 9, 19, 13, 15],\n",
              " [10, 0, 19, 1, 19, 0, 1, 4, 23, 10, 15, 9, 19, 13, 15, 1, 20, 4, 8, 6],\n",
              " [0, 1, 4, 23, 10, 15, 9, 19, 13, 15, 1, 20, 4, 8, 6, 3, 6, 13, 26, 7],\n",
              " [15, 9, 19, 13, 15, 1, 20, 4, 8, 6, 3, 6, 13, 26, 7, 26, 10, 4, 18, 15],\n",
              " [1, 20, 4, 8, 6, 3, 6, 13, 26, 7, 26, 10, 4, 18, 15, 3, 15, 1, 9, 12],\n",
              " [3, 6, 13, 26, 7, 26, 10, 4, 18, 15, 3, 15, 1, 9, 12, 26, 4, 20, 6, 4],\n",
              " [26, 10, 4, 18, 15, 3, 15, 1, 9, 12, 26, 4, 20, 6, 4, 13, 19, 5, 4, 2],\n",
              " [3, 15, 1, 9, 12, 26, 4, 20, 6, 4, 13, 19, 5, 4, 2, 23, 4, 13, 19, 10],\n",
              " [26, 4, 20, 6, 4, 13, 19, 5, 4, 2, 23, 4, 13, 19, 10, 20, 4, 6, 1, 4],\n",
              " [13, 19, 5, 4, 2, 23, 4, 13, 19, 10, 20, 4, 6, 1, 4, 22, 19, 9, 4, 6],\n",
              " [23, 4, 13, 19, 10, 20, 4, 6, 1, 4, 22, 19, 9, 4, 6, 23, 23, 6, 1, 15],\n",
              " [20, 4, 6, 1, 4, 22, 19, 9, 4, 6, 23, 23, 6, 1, 15, 1, 20, 4, 22, 15],\n",
              " [22, 19, 9, 4, 6, 23, 23, 6, 1, 15, 1, 20, 4, 22, 15, 4, 19, 1, 8, 19],\n",
              " [23, 23, 6, 1, 15, 1, 20, 4, 22, 15, 4, 19, 1, 8, 19, 20, 15, 13, 4, 11],\n",
              " [1, 20, 4, 22, 15, 4, 19, 1, 8, 19, 20, 15, 13, 4, 11, 22, 19, 1, 0, 4],\n",
              " [4, 19, 1, 8, 19, 20, 15, 13, 4, 11, 22, 19, 1, 0, 4, 20, 6, 4, 13, 6],\n",
              " [20, 15, 13, 4, 11, 22, 19, 1, 0, 4, 20, 6, 4, 13, 6, 4, 19, 20, 4, 20],\n",
              " [22, 19, 1, 0, 4, 20, 6, 4, 13, 6, 4, 19, 20, 4, 20, 6, 6, 20, 10, 2],\n",
              " [20, 6, 4, 13, 6, 4, 19, 20, 4, 20, 6, 6, 20, 10, 2, 7, 23, 9, 4, 11],\n",
              " [4, 19, 20, 4, 20, 6, 6, 20, 10, 2, 7, 23, 9, 4, 11, 0, 7, 23, 0, 19],\n",
              " [6, 6, 20, 10, 2, 7, 23, 9, 4, 11, 0, 7, 23, 0, 19, 5, 1, 4, 16, 6],\n",
              " [7, 23, 9, 4, 11, 0, 7, 23, 0, 19, 5, 1, 4, 16, 6, 10, 4, 20, 22, 15],\n",
              " [0, 7, 23, 0, 19, 5, 1, 4, 16, 6, 10, 4, 20, 22, 15, 4, 17, 22, 19, 20],\n",
              " [5, 1, 4, 16, 6, 10, 4, 20, 22, 15, 4, 17, 22, 19, 20, 15, 4, 22, 6, 2],\n",
              " [10, 4, 20, 22, 15, 4, 17, 22, 19, 20, 15, 4, 22, 6, 2, 9, 15, 4, 17, 0],\n",
              " [4, 17, 22, 19, 20, 15, 4, 22, 6, 2, 9, 15, 4, 17, 0, 9, 4, 10, 6, 20],\n",
              " [15, 4, 22, 6, 2, 9, 15, 4, 17, 0, 9, 4, 10, 6, 20, 20, 15, 1, 4, 16],\n",
              " [9, 15, 4, 17, 0, 9, 4, 10, 6, 20, 20, 15, 1, 4, 16, 10, 6, 7, 4, 20],\n",
              " [9, 4, 10, 6, 20, 20, 15, 1, 4, 16, 10, 6, 7, 4, 20, 22, 15, 4, 14, 15],\n",
              " [20, 15, 1, 4, 16, 10, 6, 7, 4, 20, 22, 15, 4, 14, 15, 5, 19, 1, 1, 19],\n",
              " [10, 6, 7, 4, 20, 22, 15, 4, 14, 15, 5, 19, 1, 1, 19, 1, 5, 4, 17, 15],\n",
              " [22, 15, 4, 14, 15, 5, 19, 1, 1, 19, 1, 5, 4, 17, 15, 4, 5, 3, 19, 7],\n",
              " [5, 19, 1, 1, 19, 1, 5, 4, 17, 15, 4, 5, 3, 19, 7, 23, 9, 15, 13, 4],\n",
              " [1, 5, 4, 17, 15, 4, 5, 3, 19, 7, 23, 9, 15, 13, 4, 19, 20, 9, 4, 13],\n",
              " [4, 5, 3, 19, 7, 23, 9, 15, 13, 4, 19, 20, 9, 4, 13, 15, 23, 20, 22, 9],\n",
              " [23, 9, 15, 13, 4, 19, 20, 9, 4, 13, 15, 23, 20, 22, 9, 4, 17, 22, 15, 1],\n",
              " [19, 20, 9, 4, 13, 15, 23, 20, 22, 9, 4, 17, 22, 15, 1, 4, 22, 19, 9, 4],\n",
              " [15, 23, 20, 22, 9, 4, 17, 22, 15, 1, 4, 22, 19, 9, 4, 3, 0, 17, 26, 15],\n",
              " [4, 17, 22, 15, 1, 4, 22, 19, 9, 4, 3, 0, 17, 26, 15, 10, 4, 7, 19, 11],\n",
              " [4, 22, 19, 9, 4, 3, 0, 17, 26, 15, 10, 4, 7, 19, 11, 22, 0, 15, 3, 4],\n",
              " [3, 0, 17, 26, 15, 10, 4, 7, 19, 11, 22, 0, 15, 3, 4, 11, 6, 22, 15, 1],\n",
              " [10, 4, 7, 19, 11, 22, 0, 15, 3, 4, 11, 6, 22, 15, 1, 4, 23, 3, 15, 0],\n",
              " [22, 0, 15, 3, 4, 11, 6, 22, 15, 1, 4, 23, 3, 15, 0, 13, 15, 13, 4, 5],\n",
              " [11, 6, 22, 15, 1, 4, 23, 3, 15, 0, 13, 15, 13, 4, 5, 2, 19, 3, 20, 26],\n",
              " [4, 23, 3, 15, 0, 13, 15, 13, 4, 5, 2, 19, 3, 20, 26, 4, 20, 6, 4, 11],\n",
              " [13, 15, 13, 4, 5, 2, 19, 3, 20, 26, 4, 20, 6, 4, 11, 0, 7, 23, 0, 19],\n",
              " [2, 19, 3, 20, 26, 4, 20, 6, 4, 11, 0, 7, 23, 0, 19, 5, 1, 4, 16, 19],\n",
              " [4, 20, 6, 4, 11, 0, 7, 23, 0, 19, 5, 1, 4, 16, 19, 1, 0, 1, 11, 15],\n",
              " [0, 7, 23, 0, 19, 5, 1, 4, 16, 19, 1, 0, 1, 11, 15, 4, 16, 15, 3, 6],\n",
              " [5, 1, 4, 16, 19, 1, 0, 1, 11, 15, 4, 16, 15, 3, 6, 1, 19, 15, 9, 4],\n",
              " [1, 0, 1, 11, 15, 4, 16, 15, 3, 6, 1, 19, 15, 9, 4, 0, 1, 13, 4, 19],\n",
              " [4, 16, 15, 3, 6, 1, 19, 15, 9, 4, 0, 1, 13, 4, 19, 13, 15, 1, 20, 19],\n",
              " [1, 19, 15, 9, 4, 0, 1, 13, 4, 19, 13, 15, 1, 20, 19, 16, 19, 15, 13, 4],\n",
              " [0, 1, 13, 4, 19, 13, 15, 1, 20, 19, 16, 19, 15, 13, 4, 20, 10, 2, 7, 23],\n",
              " [13, 15, 1, 20, 19, 16, 19, 15, 13, 4, 20, 10, 2, 7, 23, 4, 0, 9, 4, 19],\n",
              " [16, 19, 15, 13, 4, 20, 10, 2, 7, 23, 4, 0, 9, 4, 19, 1, 13, 19, 8, 19],\n",
              " [20, 10, 2, 7, 23, 4, 0, 9, 4, 19, 1, 13, 19, 8, 19, 13, 2, 0, 3, 19],\n",
              " [4, 0, 9, 4, 19, 1, 13, 19, 8, 19, 13, 2, 0, 3, 19, 1, 4, 0, 4, 11],\n",
              " [1, 13, 19, 8, 19, 13, 2, 0, 3, 19, 1, 4, 0, 4, 11, 6, 1, 9, 23, 19],\n",
              " [13, 2, 0, 3, 19, 1, 4, 0, 4, 11, 6, 1, 9, 23, 19, 10, 0, 11, 26, 4],\n",
              " [1, 4, 0, 4, 11, 6, 1, 9, 23, 19, 10, 0, 11, 26, 4, 20, 6, 4, 23, 0],\n",
              " [6, 1, 9, 23, 19, 10, 0, 11, 26, 4, 20, 6, 4, 23, 0, 26, 4, 6, 16, 16],\n",
              " [10, 0, 11, 26, 4, 20, 6, 4, 23, 0, 26, 4, 6, 16, 16, 4, 0, 1, 4, 0],\n",
              " [20, 6, 4, 23, 0, 26, 4, 6, 16, 16, 4, 0, 1, 4, 0, 13, 2, 3, 20, 16],\n",
              " [26, 4, 6, 16, 16, 4, 0, 1, 4, 0, 13, 2, 3, 20, 16, 19, 3, 7, 4, 9],\n",
              " [4, 0, 1, 4, 0, 13, 2, 3, 20, 16, 19, 3, 7, 4, 9, 20, 0, 10, 4, 0],\n",
              " [13, 2, 3, 20, 16, 19, 3, 7, 4, 9, 20, 0, 10, 4, 0, 1, 13, 4, 0, 4],\n",
              " [19, 3, 7, 4, 9, 20, 0, 10, 4, 0, 1, 13, 4, 0, 4, 16, 6, 10, 7, 15],\n",
              " [20, 0, 10, 4, 0, 1, 13, 4, 0, 4, 16, 6, 10, 7, 15, 10, 4, 23, 3, 0],\n",
              " [1, 13, 4, 0, 4, 16, 6, 10, 7, 15, 10, 4, 23, 3, 0, 26, 14, 6, 26, 4],\n",
              " [16, 6, 10, 7, 15, 10, 4, 23, 3, 0, 26, 14, 6, 26, 4, 7, 6, 13, 15, 3],\n",
              " [10, 4, 23, 3, 0, 26, 14, 6, 26, 4, 7, 6, 13, 15, 3, 4, 20, 6, 4, 9],\n",
              " [26, 14, 6, 26, 4, 7, 6, 13, 15, 3, 4, 20, 6, 4, 9, 19, 3, 15, 1, 11],\n",
              " [7, 6, 13, 15, 3, 4, 20, 6, 4, 9, 19, 3, 15, 1, 11, 15, 4, 20, 22, 15],\n",
              " [4, 20, 6, 4, 9, 19, 3, 15, 1, 11, 15, 4, 20, 22, 15, 7, 4, 13, 2, 10],\n",
              " [19, 3, 15, 1, 11, 15, 4, 20, 22, 15, 7, 4, 13, 2, 10, 19, 1, 5, 4, 20],\n",
              " [15, 4, 20, 22, 15, 7, 4, 13, 2, 10, 19, 1, 5, 4, 20, 22, 15, 4, 22, 15],\n",
              " [7, 4, 13, 2, 10, 19, 1, 5, 4, 20, 22, 15, 4, 22, 15, 19, 5, 22, 20, 4],\n",
              " [19, 1, 5, 4, 20, 22, 15, 4, 22, 15, 19, 5, 22, 20, 4, 6, 16, 4, 20, 22],\n",
              " [22, 15, 4, 22, 15, 19, 5, 22, 20, 4, 6, 16, 4, 20, 22, 15, 23, 10, 15, 9],\n",
              " [19, 5, 22, 20, 4, 6, 16, 4, 20, 22, 15, 23, 10, 15, 9, 19, 13, 15, 1, 20],\n",
              " [6, 16, 4, 20, 22, 15, 23, 10, 15, 9, 19, 13, 15, 1, 20, 19, 0, 3, 4, 11],\n",
              " [15, 23, 10, 15, 9, 19, 13, 15, 1, 20, 19, 0, 3, 4, 11, 0, 7, 23, 0, 19],\n",
              " [19, 13, 15, 1, 20, 19, 0, 3, 4, 11, 0, 7, 23, 0, 19, 5, 1, 4, 17, 15],\n",
              " [19, 0, 3, 4, 11, 0, 7, 23, 0, 19, 5, 1, 4, 17, 15, 4, 5, 6, 20, 4],\n",
              " [0, 7, 23, 0, 19, 5, 1, 4, 17, 15, 4, 5, 6, 20, 4, 15, 8, 15, 1, 4],\n",
              " [5, 1, 4, 17, 15, 4, 5, 6, 20, 4, 15, 8, 15, 1, 4, 7, 6, 10, 15, 4],\n",
              " [4, 5, 6, 20, 4, 15, 8, 15, 1, 4, 7, 6, 10, 15, 4, 15, 8, 19, 13, 15],\n",
              " [15, 8, 15, 1, 4, 7, 6, 10, 15, 4, 15, 8, 19, 13, 15, 1, 11, 15, 4, 6],\n",
              " [7, 6, 10, 15, 4, 15, 8, 19, 13, 15, 1, 11, 15, 4, 6, 16, 4, 20, 10, 2],\n",
              " [15, 8, 19, 13, 15, 1, 11, 15, 4, 6, 16, 4, 20, 10, 2, 7, 23, 9, 4, 13],\n",
              " [1, 11, 15, 4, 6, 16, 4, 20, 10, 2, 7, 23, 9, 4, 13, 15, 11, 15, 23, 20],\n",
              " [16, 4, 20, 10, 2, 7, 23, 9, 4, 13, 15, 11, 15, 23, 20, 19, 6, 1, 4, 19],\n",
              " [7, 23, 9, 4, 13, 15, 11, 15, 23, 20, 19, 6, 1, 4, 19, 1, 4, 20, 22, 15],\n",
              " [15, 11, 15, 23, 20, 19, 6, 1, 4, 19, 1, 4, 20, 22, 15, 4, 13, 15, 1, 9],\n",
              " [19, 6, 1, 4, 19, 1, 4, 20, 22, 15, 4, 13, 15, 1, 9, 15, 4, 10, 15, 23],\n",
              " [1, 4, 20, 22, 15, 4, 13, 15, 1, 9, 15, 4, 10, 15, 23, 6, 10, 20, 4, 23],\n",
              " [4, 13, 15, 1, 9, 15, 4, 10, 15, 23, 6, 10, 20, 4, 23, 10, 15, 23, 0, 10],\n",
              " [15, 4, 10, 15, 23, 6, 10, 20, 4, 23, 10, 15, 23, 0, 10, 15, 13, 4, 14, 26],\n",
              " [6, 10, 20, 4, 23, 10, 15, 23, 0, 10, 15, 13, 4, 14, 26, 4, 9, 23, 15, 11],\n",
              " [10, 15, 23, 0, 10, 15, 13, 4, 14, 26, 4, 9, 23, 15, 11, 19, 0, 3, 4, 11],\n",
              " [15, 13, 4, 14, 26, 4, 9, 23, 15, 11, 19, 0, 3, 4, 11, 6, 2, 1, 9, 15],\n",
              " [4, 9, 23, 15, 11, 19, 0, 3, 4, 11, 6, 2, 1, 9, 15, 3, 4, 10, 6, 14],\n",
              " [19, 0, 3, 4, 11, 6, 2, 1, 9, 15, 3, 4, 10, 6, 14, 15, 10, 20, 4, 9],\n",
              " [6, 2, 1, 9, 15, 3, 4, 10, 6, 14, 15, 10, 20, 4, 9, 4, 7, 2, 15, 3],\n",
              " [3, 4, 10, 6, 14, 15, 10, 20, 4, 9, 4, 7, 2, 15, 3, 3, 15, 10, 4, 19],\n",
              " [15, 10, 20, 4, 9, 4, 7, 2, 15, 3, 3, 15, 10, 4, 19, 19, 19, 4, 6, 1],\n",
              " [4, 7, 2, 15, 3, 3, 15, 10, 4, 19, 19, 19, 4, 6, 1, 4, 10, 2, 9, 9],\n",
              " [3, 15, 10, 4, 19, 19, 19, 4, 6, 1, 4, 10, 2, 9, 9, 19, 0, 9, 4, 19],\n",
              " [19, 19, 4, 6, 1, 4, 10, 2, 9, 9, 19, 0, 9, 4, 19, 1, 20, 15, 10, 16],\n",
              " [4, 10, 2, 9, 9, 19, 0, 9, 4, 19, 1, 20, 15, 10, 16, 15, 10, 15, 1, 11],\n",
              " [19, 0, 9, 4, 19, 1, 20, 15, 10, 16, 15, 10, 15, 1, 11, 15, 4, 19, 1, 4],\n",
              " [1, 20, 15, 10, 16, 15, 10, 15, 1, 11, 15, 4, 19, 1, 4, 20, 22, 15, 15, 3],\n",
              " [15, 10, 15, 1, 11, 15, 4, 19, 1, 4, 20, 22, 15, 15, 3, 15, 11, 20, 19, 6],\n",
              " [15, 4, 19, 1, 4, 20, 22, 15, 15, 3, 15, 11, 20, 19, 6, 1, 4, 20, 6, 4],\n",
              " [20, 22, 15, 15, 3, 15, 11, 20, 19, 6, 1, 4, 20, 6, 4, 14, 15, 1, 15, 16],\n",
              " [15, 11, 20, 19, 6, 1, 4, 20, 6, 4, 14, 15, 1, 15, 16, 19, 20, 4, 20, 10],\n",
              " [1, 4, 20, 6, 4, 14, 15, 1, 15, 16, 19, 20, 4, 20, 10, 2, 7, 23, 4, 0],\n",
              " [14, 15, 1, 15, 16, 19, 20, 4, 20, 10, 2, 7, 23, 4, 0, 1, 13, 4, 20, 10],\n",
              " [19, 20, 4, 20, 10, 2, 7, 23, 4, 0, 1, 13, 4, 20, 10, 26, 4, 20, 6, 4],\n",
              " [2, 7, 23, 4, 0, 1, 13, 4, 20, 10, 26, 4, 20, 6, 4, 13, 15, 16, 15, 0],\n",
              " [1, 13, 4, 20, 10, 26, 4, 20, 6, 4, 13, 15, 16, 15, 0, 20, 4, 22, 19, 3],\n",
              " [26, 4, 20, 6, 4, 13, 15, 16, 15, 0, 20, 4, 22, 19, 3, 3, 0, 10, 26, 4],\n",
              " [13, 15, 16, 15, 0, 20, 4, 22, 19, 3, 3, 0, 10, 26, 4, 11, 3, 19, 1, 20],\n",
              " [20, 4, 22, 19, 3, 3, 0, 10, 26, 4, 11, 3, 19, 1, 20, 6, 1, 4, 7, 2],\n",
              " [3, 0, 10, 26, 4, 11, 3, 19, 1, 20, 6, 1, 4, 7, 2, 15, 3, 3, 15, 10],\n",
              " [11, 3, 19, 1, 20, 6, 1, 4, 7, 2, 15, 3, 3, 15, 10, 4, 3, 0, 19, 13],\n",
              " [6, 1, 4, 7, 2, 15, 3, 3, 15, 10, 4, 3, 0, 19, 13, 4, 20, 22, 15, 4],\n",
              " [15, 3, 3, 15, 10, 4, 3, 0, 19, 13, 4, 20, 22, 15, 4, 5, 10, 6, 2, 1],\n",
              " [4, 3, 0, 19, 13, 4, 20, 22, 15, 4, 5, 10, 6, 2, 1, 13, 17, 6, 10, 12],\n",
              " [4, 20, 22, 15, 4, 5, 10, 6, 2, 1, 13, 17, 6, 10, 12, 4, 16, 6, 10, 4],\n",
              " [5, 10, 6, 2, 1, 13, 17, 6, 10, 12, 4, 16, 6, 10, 4, 0, 20, 4, 3, 15],\n",
              " [13, 17, 6, 10, 12, 4, 16, 6, 10, 4, 0, 20, 4, 3, 15, 0, 9, 20, 0, 11],\n",
              " [4, 16, 6, 10, 4, 0, 20, 4, 3, 15, 0, 9, 20, 0, 11, 20, 9, 4, 6, 16],\n",
              " [0, 20, 4, 3, 15, 0, 9, 20, 0, 11, 20, 9, 4, 6, 16, 4, 6, 14, 9, 20],\n",
              " [0, 9, 20, 0, 11, 20, 9, 4, 6, 16, 4, 6, 14, 9, 20, 10, 2, 11, 20, 19],\n",
              " [20, 9, 4, 6, 16, 4, 6, 14, 9, 20, 10, 2, 11, 20, 19, 6, 1, 4, 6, 16],\n",
              " [4, 6, 14, 9, 20, 10, 2, 11, 20, 19, 6, 1, 4, 6, 16, 4, 24, 2, 9, 20],\n",
              " [10, 2, 11, 20, 19, 6, 1, 4, 6, 16, 4, 24, 2, 9, 20, 19, 11, 15, 15, 8],\n",
              " [6, 1, 4, 6, 16, 4, 24, 2, 9, 20, 19, 11, 15, 15, 8, 15, 1, 4, 17, 19],\n",
              " [4, 24, 2, 9, 20, 19, 11, 15, 15, 8, 15, 1, 4, 17, 19, 20, 22, 4, 0, 3],\n",
              " [19, 11, 15, 15, 8, 15, 1, 4, 17, 19, 20, 22, 4, 0, 3, 3, 4, 6, 16, 4],\n",
              " [15, 1, 4, 17, 19, 20, 22, 4, 0, 3, 3, 4, 6, 16, 4, 20, 22, 0, 20, 4],\n",
              " [20, 22, 4, 0, 3, 3, 4, 6, 16, 4, 20, 22, 0, 20, 4, 19, 20, 9, 4, 20],\n",
              " [3, 4, 6, 16, 4, 20, 22, 0, 20, 4, 19, 20, 9, 4, 20, 22, 19, 9, 4, 9],\n",
              " [20, 22, 0, 20, 4, 19, 20, 9, 4, 20, 22, 19, 9, 4, 9, 20, 19, 3, 3, 2],\n",
              " [19, 20, 9, 4, 20, 22, 19, 9, 4, 9, 20, 19, 3, 3, 2, 1, 10, 0, 8, 15],\n",
              " [22, 19, 9, 4, 9, 20, 19, 3, 3, 2, 1, 10, 0, 8, 15, 3, 19, 1, 5, 4],\n",
              " [20, 19, 3, 3, 2, 1, 10, 0, 8, 15, 3, 19, 1, 5, 4, 2, 12, 10, 0, 19],\n",
              " [1, 10, 0, 8, 15, 3, 19, 1, 5, 4, 2, 12, 10, 0, 19, 1, 15, 4, 9, 20],\n",
              " [3, 19, 1, 5, 4, 2, 12, 10, 0, 19, 1, 15, 4, 9, 20, 6, 10, 26, 4, 20],\n",
              " [2, 12, 10, 0, 19, 1, 15, 4, 9, 20, 6, 10, 26, 4, 20, 22, 0, 20, 4, 7],\n",
              " [1, 15, 4, 9, 20, 6, 10, 26, 4, 20, 22, 0, 20, 4, 7, 0, 12, 15, 9, 4],\n",
              " [6, 10, 26, 4, 20, 22, 0, 20, 4, 7, 0, 12, 15, 9, 4, 11, 3, 15, 0, 10],\n",
              " [22, 0, 20, 4, 7, 0, 12, 15, 9, 4, 11, 3, 15, 0, 10, 4, 20, 22, 15, 4],\n",
              " [0, 12, 15, 9, 4, 11, 3, 15, 0, 10, 4, 20, 22, 15, 4, 14, 19, 20, 9, 4],\n",
              " [11, 3, 15, 0, 10, 4, 20, 22, 15, 4, 14, 19, 20, 9, 4, 0, 1, 13, 4, 23],\n",
              " [4, 20, 22, 15, 4, 14, 19, 20, 9, 4, 0, 1, 13, 4, 23, 19, 15, 11, 15, 9],\n",
              " [14, 19, 20, 9, 4, 0, 1, 13, 4, 23, 19, 15, 11, 15, 9, 4, 20, 22, 0, 20],\n",
              " [0, 1, 13, 4, 23, 19, 15, 11, 15, 9, 4, 20, 22, 0, 20, 4, 17, 15, 4, 11],\n",
              " [19, 15, 11, 15, 9, 4, 20, 22, 0, 20, 4, 17, 15, 4, 11, 6, 2, 3, 13, 4],\n",
              " [4, 20, 22, 0, 20, 4, 17, 15, 4, 11, 6, 2, 3, 13, 4, 6, 1, 3, 26, 4],\n",
              " [4, 17, 15, 4, 11, 6, 2, 3, 13, 4, 6, 1, 3, 26, 4, 19, 7, 0, 5, 19],\n",
              " [6, 2, 3, 13, 4, 6, 1, 3, 26, 4, 19, 7, 0, 5, 19, 1, 15, 4, 17, 19],\n",
              " [6, 1, 3, 26, 4, 19, 7, 0, 5, 19, 1, 15, 4, 17, 19, 20, 22, 4, 20, 10],\n",
              " [19, 7, 0, 5, 19, 1, 15, 4, 17, 19, 20, 22, 4, 20, 10, 2, 7, 23, 9, 4],\n",
              " [1, 15, 4, 17, 19, 20, 22, 4, 20, 10, 2, 7, 23, 9, 4, 23, 3, 15, 0, 9],\n",
              " [20, 22, 4, 20, 10, 2, 7, 23, 9, 4, 23, 3, 15, 0, 9, 4, 20, 6, 4, 10],\n",
              " [2, 7, 23, 9, 4, 23, 3, 15, 0, 9, 4, 20, 6, 4, 10, 2, 9, 9, 19, 0],\n",
              " [23, 3, 15, 0, 9, 4, 20, 6, 4, 10, 2, 9, 9, 19, 0, 4, 19, 16, 4, 26],\n",
              " [4, 20, 6, 4, 10, 2, 9, 9, 19, 0, 4, 19, 16, 4, 26, 6, 2, 10, 15, 4],\n",
              " [2, 9, 9, 19, 0, 4, 19, 16, 4, 26, 6, 2, 10, 15, 4, 3, 19, 9, 20, 15],\n",
              " [4, 19, 16, 4, 26, 6, 2, 10, 15, 4, 3, 19, 9, 20, 15, 1, 19, 1, 5, 17],\n",
              " [6, 2, 10, 15, 4, 3, 19, 9, 20, 15, 1, 19, 1, 5, 17, 15, 4, 22, 0, 8],\n",
              " [3, 19, 9, 20, 15, 1, 19, 1, 5, 17, 15, 4, 22, 0, 8, 15, 4, 20, 22, 15],\n",
              " [1, 19, 1, 5, 17, 15, 4, 22, 0, 8, 15, 4, 20, 22, 15, 4, 9, 0, 7, 15],\n",
              " [15, 4, 22, 0, 8, 15, 4, 20, 22, 15, 4, 9, 0, 7, 15, 4, 20, 22, 10, 15],\n",
              " [15, 4, 20, 22, 15, 4, 9, 0, 7, 15, 4, 20, 22, 10, 15, 0, 20, 9, 4, 3],\n",
              " [4, 9, 0, 7, 15, 4, 20, 22, 10, 15, 0, 20, 9, 4, 3, 19, 15, 9, 4, 9],\n",
              " [4, 20, 22, 10, 15, 0, 20, 9, 4, 3, 19, 15, 9, 4, 9, 2, 14, 20, 15, 10],\n",
              " [0, 20, 9, 4, 3, 19, 15, 9, 4, 9, 2, 14, 20, 15, 10, 16, 2, 5, 15, 4],\n",
              " [19, 15, 9, 4, 9, 2, 14, 20, 15, 10, 16, 2, 5, 15, 4, 0, 1, 13, 4, 6],\n",
              " [2, 14, 20, 15, 10, 16, 2, 5, 15, 4, 0, 1, 13, 4, 6, 14, 9, 20, 10, 2],\n",
              " [16, 2, 5, 15, 4, 0, 1, 13, 4, 6, 14, 9, 20, 10, 2, 11, 20, 19, 6, 1],\n",
              " [0, 1, 13, 4, 6, 14, 9, 20, 10, 2, 11, 20, 19, 6, 1, 6, 1, 3, 26, 4],\n",
              " [14, 9, 20, 10, 2, 11, 20, 19, 6, 1, 6, 1, 3, 26, 4, 20, 22, 19, 9, 4],\n",
              " [11, 20, 19, 6, 1, 6, 1, 3, 26, 4, 20, 22, 19, 9, 4, 20, 19, 7, 15, 4],\n",
              " [6, 1, 3, 26, 4, 20, 22, 19, 9, 4, 20, 19, 7, 15, 4, 17, 15, 4, 22, 0],\n",
              " [20, 22, 19, 9, 4, 20, 19, 7, 15, 4, 17, 15, 4, 22, 0, 8, 15, 4, 20, 22],\n",
              " [20, 19, 7, 15, 4, 17, 15, 4, 22, 0, 8, 15, 4, 20, 22, 15, 4, 23, 10, 15],\n",
              " [17, 15, 4, 22, 0, 8, 15, 4, 20, 22, 15, 4, 23, 10, 15, 9, 19, 13, 15, 1],\n",
              " [8, 15, 4, 20, 22, 15, 4, 23, 10, 15, 9, 19, 13, 15, 1, 20, 9, 4, 2, 1],\n",
              " [15, 4, 23, 10, 15, 9, 19, 13, 15, 1, 20, 9, 4, 2, 1, 0, 7, 14, 19, 5],\n",
              " [9, 19, 13, 15, 1, 20, 9, 4, 2, 1, 0, 7, 14, 19, 5, 2, 6, 2, 9, 4],\n",
              " [20, 9, 4, 2, 1, 0, 7, 14, 19, 5, 2, 6, 2, 9, 4, 17, 6, 10, 13, 9],\n",
              " [0, 7, 14, 19, 5, 2, 6, 2, 9, 4, 17, 6, 10, 13, 9, 4, 20, 6, 4, 18],\n",
              " [2, 6, 2, 9, 4, 17, 6, 10, 13, 9, 4, 20, 6, 4, 18, 15, 3, 15, 1, 9],\n",
              " [17, 6, 10, 13, 9, 4, 20, 6, 4, 18, 15, 3, 15, 1, 9, 12, 26, 4, 19, 4],\n",
              " [4, 20, 6, 4, 18, 15, 3, 15, 1, 9, 12, 26, 4, 19, 4, 17, 6, 2, 3, 13],\n",
              " [15, 3, 15, 1, 9, 12, 26, 4, 19, 4, 17, 6, 2, 3, 13, 4, 3, 19, 12, 15],\n",
              " [12, 26, 4, 19, 4, 17, 6, 2, 3, 13, 4, 3, 19, 12, 15, 4, 26, 6, 2, 4],\n",
              " [17, 6, 2, 3, 13, 4, 3, 19, 12, 15, 4, 26, 6, 2, 4, 20, 6, 4, 13, 6],\n",
              " [4, 3, 19, 12, 15, 4, 26, 6, 2, 4, 20, 6, 4, 13, 6, 4, 2, 9, 4, 0],\n",
              " [4, 26, 6, 2, 4, 20, 6, 4, 13, 6, 4, 2, 9, 4, 0, 4, 16, 0, 8, 6],\n",
              " [20, 6, 4, 13, 6, 4, 2, 9, 4, 0, 4, 16, 0, 8, 6, 10, 4, 20, 22, 6],\n",
              " [4, 2, 9, 4, 0, 4, 16, 0, 8, 6, 10, 4, 20, 22, 6, 2, 5, 22, 4, 2],\n",
              " [4, 16, 0, 8, 6, 10, 4, 20, 22, 6, 2, 5, 22, 4, 2, 12, 10, 0, 19, 1],\n",
              " [10, 4, 20, 22, 6, 2, 5, 22, 4, 2, 12, 10, 0, 19, 1, 15, 4, 10, 15, 23],\n",
              " [2, 5, 22, 4, 2, 12, 10, 0, 19, 1, 15, 4, 10, 15, 23, 10, 15, 9, 15, 1],\n",
              " [12, 10, 0, 19, 1, 15, 4, 10, 15, 23, 10, 15, 9, 15, 1, 20, 9, 4, 20, 22],\n",
              " [15, 4, 10, 15, 23, 10, 15, 9, 15, 1, 20, 9, 4, 20, 22, 15, 4, 9, 0, 7],\n",
              " [10, 15, 9, 15, 1, 20, 9, 4, 20, 22, 15, 4, 9, 0, 7, 15, 4, 3, 0, 17],\n",
              " [20, 9, 4, 20, 22, 15, 4, 9, 0, 7, 15, 4, 3, 0, 17, 3, 15, 9, 9, 1],\n",
              " [15, 4, 9, 0, 7, 15, 4, 3, 0, 17, 3, 15, 9, 9, 1, 15, 9, 9, 4, 20],\n",
              " [15, 4, 3, 0, 17, 3, 15, 9, 9, 1, 15, 9, 9, 4, 20, 22, 0, 20, 4, 23],\n",
              " [3, 15, 9, 9, 1, 15, 9, 9, 4, 20, 22, 0, 20, 4, 23, 10, 6, 23, 15, 3],\n",
              " [15, 9, 9, 4, 20, 22, 0, 20, 4, 23, 10, 6, 23, 15, 3, 3, 15, 13, 4, 20],\n",
              " [22, 0, 20, 4, 23, 10, 6, 23, 15, 3, 3, 15, 13, 4, 20, 10, 2, 7, 23, 4],\n",
              " [10, 6, 23, 15, 3, 3, 15, 13, 4, 20, 10, 2, 7, 23, 4, 6, 8, 15, 10, 4],\n",
              " [3, 15, 13, 4, 20, 10, 2, 7, 23, 4, 6, 8, 15, 10, 4, 20, 22, 15, 4, 16],\n",
              " [10, 2, 7, 23, 4, 6, 8, 15, 10, 4, 20, 22, 15, 4, 16, 19, 1, 19, 9, 22],\n",
              " [6, 8, 15, 10, 4, 20, 22, 15, 4, 16, 19, 1, 19, 9, 22, 4, 3, 19, 1, 15],\n",
              " [20, 22, 15, 4, 16, 19, 1, 19, 9, 22, 4, 3, 19, 1, 15, 4, 19, 1, 20, 22],\n",
              " [19, 1, 19, 9, 22, 4, 3, 19, 1, 15, 4, 19, 1, 20, 22, 19, 9, 4, 20, 19],\n",
              " [4, 3, 19, 1, 15, 4, 19, 1, 20, 22, 19, 9, 4, 20, 19, 7, 15, 4, 19, 1],\n",
              " [4, 19, 1, 20, 22, 19, 9, 4, 20, 19, 7, 15, 4, 19, 1, 4, 23, 3, 0, 19],\n",
              " [19, 9, 4, 20, 19, 7, 15, 4, 19, 1, 4, 23, 3, 0, 19, 1, 4, 9, 19, 5],\n",
              " [7, 15, 4, 19, 1, 4, 23, 3, 0, 19, 1, 4, 9, 19, 5, 22, 20, 4, 17, 19],\n",
              " [4, 23, 3, 0, 19, 1, 4, 9, 19, 5, 22, 20, 4, 17, 19, 20, 22, 4, 17, 19],\n",
              " [1, 4, 9, 19, 5, 22, 20, 4, 17, 19, 20, 22, 4, 17, 19, 20, 1, 15, 9, 9],\n",
              " [22, 20, 4, 17, 19, 20, 22, 4, 17, 19, 20, 1, 15, 9, 9, 15, 9, 4, 19, 1],\n",
              " [20, 22, 4, 17, 19, 20, 1, 15, 9, 9, 15, 9, 4, 19, 1, 11, 3, 2, 13, 19],\n",
              " [20, 1, 15, 9, 9, 15, 9, 4, 19, 1, 11, 3, 2, 13, 19, 1, 5, 4, 0, 20],\n",
              " [15, 9, 4, 19, 1, 11, 3, 2, 13, 19, 1, 5, 4, 0, 20, 4, 3, 15, 0, 9],\n",
              " [11, 3, 2, 13, 19, 1, 5, 4, 0, 20, 4, 3, 15, 0, 9, 20, 4, 6, 1, 15],\n",
              " [1, 5, 4, 0, 20, 4, 3, 15, 0, 9, 20, 4, 6, 1, 15, 4, 17, 22, 19, 9],\n",
              " [4, 3, 15, 0, 9, 20, 4, 6, 1, 15, 4, 17, 22, 19, 9, 20, 3, 15, 14, 3],\n",
              " [20, 4, 6, 1, 15, 4, 17, 22, 19, 9, 20, 3, 15, 14, 3, 6, 17, 15, 10, 4],\n",
              " [4, 17, 22, 19, 9, 20, 3, 15, 14, 3, 6, 17, 15, 10, 4, 0, 1, 13, 4, 3],\n",
              " [20, 3, 15, 14, 3, 6, 17, 15, 10, 4, 0, 1, 13, 4, 3, 6, 20, 9, 4, 6],\n",
              " [6, 17, 15, 10, 4, 0, 1, 13, 4, 3, 6, 20, 9, 4, 6, 16, 4, 14, 19, 20],\n",
              " [0, 1, 13, 4, 3, 6, 20, 9, 4, 6, 16, 4, 14, 19, 20, 4, 23, 3, 0, 26],\n",
              " [6, 20, 9, 4, 6, 16, 4, 14, 19, 20, 4, 23, 3, 0, 26, 15, 10, 9, 4, 16],\n",
              " [16, 4, 14, 19, 20, 4, 23, 3, 0, 26, 15, 10, 9, 4, 16, 10, 6, 7, 4, 20],\n",
              " [4, 23, 3, 0, 26, 15, 10, 9, 4, 16, 10, 6, 7, 4, 20, 22, 15, 4, 9, 20],\n",
              " [15, 10, 9, 4, 16, 10, 6, 7, 4, 20, 22, 15, 4, 9, 20, 0, 20, 15, 4, 13],\n",
              " [10, 6, 7, 4, 20, 22, 15, 4, 9, 20, 0, 20, 15, 4, 13, 15, 23, 0, 10, 20],\n",
              " [22, 15, 4, 9, 20, 0, 20, 15, 4, 13, 15, 23, 0, 10, 20, 7, 15, 1, 20, 4],\n",
              " [0, 20, 15, 4, 13, 15, 23, 0, 10, 20, 7, 15, 1, 20, 4, 20, 6, 4, 20, 22],\n",
              " [15, 23, 0, 10, 20, 7, 15, 1, 20, 4, 20, 6, 4, 20, 22, 15, 4, 15, 1, 15],\n",
              " [7, 15, 1, 20, 4, 20, 6, 4, 20, 22, 15, 4, 15, 1, 15, 10, 5, 26, 4, 13],\n",
              " [20, 6, 4, 20, 22, 15, 4, 15, 1, 15, 10, 5, 26, 4, 13, 15, 23, 0, 10, 20],\n",
              " [15, 4, 15, 1, 15, 10, 5, 26, 4, 13, 15, 23, 0, 10, 20, 7, 15, 1, 20, 4],\n",
              " [10, 5, 26, 4, 13, 15, 23, 0, 10, 20, 7, 15, 1, 20, 4, 20, 6, 4, 20, 22],\n",
              " [15, 23, 0, 10, 20, 7, 15, 1, 20, 4, 20, 6, 4, 20, 22, 15, 4, 24, 2, 9],\n",
              " [7, 15, 1, 20, 4, 20, 6, 4, 20, 22, 15, 4, 24, 2, 9, 20, 19, 11, 15, 4],\n",
              " [20, 6, 4, 20, 22, 15, 4, 24, 2, 9, 20, 19, 11, 15, 4, 13, 15, 23, 0, 10],\n",
              " [15, 4, 24, 2, 9, 20, 19, 11, 15, 4, 13, 15, 23, 0, 10, 20, 7, 15, 1, 20],\n",
              " [20, 19, 11, 15, 4, 13, 15, 23, 0, 10, 20, 7, 15, 1, 20, 4, 0, 1, 13, 4],\n",
              " [13, 15, 23, 0, 10, 20, 7, 15, 1, 20, 4, 0, 1, 13, 4, 20, 22, 10, 6, 2],\n",
              " [20, 7, 15, 1, 20, 4, 0, 1, 13, 4, 20, 22, 10, 6, 2, 5, 22, 6, 2, 20],\n",
              " [4, 0, 1, 13, 4, 20, 22, 10, 6, 2, 5, 22, 6, 2, 20, 4, 20, 22, 15, 4],\n",
              " [20, 22, 10, 6, 2, 5, 22, 6, 2, 20, 4, 20, 22, 15, 4, 17, 22, 19, 20, 15],\n",
              " [5, 22, 6, 2, 20, 4, 20, 22, 15, 4, 17, 22, 19, 20, 15, 4, 22, 6, 2, 9],\n",
              " [4, 20, 22, 15, 4, 17, 22, 19, 20, 15, 4, 22, 6, 2, 9, 15, 4, 20, 10, 2],\n",
              " [17, 22, 19, 20, 15, 4, 22, 6, 2, 9, 15, 4, 20, 10, 2, 7, 23, 4, 19, 9],\n",
              " [4, 22, 6, 2, 9, 15, 4, 20, 10, 2, 7, 23, 4, 19, 9, 4, 2, 9, 19, 1],\n",
              " [15, 4, 20, 10, 2, 7, 23, 4, 19, 9, 4, 2, 9, 19, 1, 5, 4, 15, 8, 15],\n",
              " [7, 23, 4, 19, 9, 4, 2, 9, 19, 1, 5, 4, 15, 8, 15, 10, 26, 4, 14, 19],\n",
              " [4, 2, 9, 19, 1, 5, 4, 15, 8, 15, 10, 26, 4, 14, 19, 20, 4, 6, 16, 4],\n",
              " [5, 4, 15, 8, 15, 10, 26, 4, 14, 19, 20, 4, 6, 16, 4, 20, 22, 15, 4, 7],\n",
              " [10, 26, 4, 14, 19, 20, 4, 6, 16, 4, 20, 22, 15, 4, 7, 0, 11, 22, 19, 1],\n",
              " [20, 4, 6, 16, 4, 20, 22, 15, 4, 7, 0, 11, 22, 19, 1, 15, 10, 26, 4, 6],\n",
              " [20, 22, 15, 4, 7, 0, 11, 22, 19, 1, 15, 10, 26, 4, 6, 16, 4, 5, 6, 8],\n",
              " [0, 11, 22, 19, 1, 15, 10, 26, 4, 6, 16, 4, 5, 6, 8, 15, 10, 1, 7, 15],\n",
              " [15, 10, 26, 4, 6, 16, 4, 5, 6, 8, 15, 10, 1, 7, 15, 1, 20, 4, 0, 1],\n",
              " [16, 4, 5, 6, 8, 15, 10, 1, 7, 15, 1, 20, 4, 0, 1, 13, 4, 23, 15, 10],\n",
              " [15, 10, 1, 7, 15, 1, 20, 4, 0, 1, 13, 4, 23, 15, 10, 9, 6, 1, 1, 15],\n",
              " [1, 20, 4, 0, 1, 13, 4, 23, 15, 10, 9, 6, 1, 1, 15, 3, 4, 0, 20, 4],\n",
              " [13, 4, 23, 15, 10, 9, 6, 1, 1, 15, 3, 4, 0, 20, 4, 22, 19, 9, 4, 13],\n",
              " [9, 6, 1, 1, 15, 3, 4, 0, 20, 4, 22, 19, 9, 4, 13, 19, 9, 23, 6, 9],\n",
              " [3, 4, 0, 20, 4, 22, 19, 9, 4, 13, 19, 9, 23, 6, 9, 0, 3, 4, 20, 6],\n",
              " [22, 19, 9, 4, 13, 19, 9, 23, 6, 9, 0, 3, 4, 20, 6, 4, 9, 20, 10, 6],\n",
              " [19, 9, 23, 6, 9, 0, 3, 4, 20, 6, 4, 9, 20, 10, 6, 1, 5, 0, 10, 7],\n",
              " [0, 3, 4, 20, 6, 4, 9, 20, 10, 6, 1, 5, 0, 10, 7, 4, 0, 4, 9, 7],\n",
              " [4, 9, 20, 10, 6, 1, 5, 0, 10, 7, 4, 0, 4, 9, 7, 0, 3, 3, 4, 11],\n",
              " [1, 5, 0, 10, 7, 4, 0, 4, 9, 7, 0, 3, 3, 4, 11, 6, 2, 1, 20, 10],\n",
              " [4, 0, 4, 9, 7, 0, 3, 3, 4, 11, 6, 2, 1, 20, 10, 26, 4, 2, 1, 13],\n",
              " [0, 3, 3, 4, 11, 6, 2, 1, 20, 10, 26, 4, 2, 1, 13, 15, 10, 4, 20, 22],\n",
              " [6, 2, 1, 20, 10, 26, 4, 2, 1, 13, 15, 10, 4, 20, 22, 15, 4, 22, 15, 15],\n",
              " [26, 4, 2, 1, 13, 15, 10, 4, 20, 22, 15, 4, 22, 15, 15, 3, 4, 6, 16, 4],\n",
              " [15, 10, 4, 20, 22, 15, 4, 22, 15, 15, 3, 4, 6, 16, 4, 19, 20, 9, 4, 20],\n",
              " [15, 4, 22, 15, 15, 3, 4, 6, 16, 4, 19, 20, 9, 4, 20, 22, 10, 15, 0, 20],\n",
              " [3, 4, 6, 16, 4, 19, 20, 9, 4, 20, 22, 10, 15, 0, 20, 15, 1, 19, 1, 5],\n",
              " [19, 20, 9, 4, 20, 22, 10, 15, 0, 20, 15, 1, 19, 1, 5, 4, 10, 2, 9, 9],\n",
              " [22, 10, 15, 0, 20, 15, 1, 19, 1, 5, 4, 10, 2, 9, 9, 19, 0, 1, 4, 1],\n",
              " [15, 1, 19, 1, 5, 4, 10, 2, 9, 9, 19, 0, 1, 4, 1, 15, 19, 5, 22, 14],\n",
              " [4, 10, 2, 9, 9, 19, 0, 1, 4, 1, 15, 19, 5, 22, 14, 6, 10, 0, 3, 3],\n",
              " [19, 0, 1, 4, 1, 15, 19, 5, 22, 14, 6, 10, 0, 3, 3, 4, 20, 6, 4, 5],\n",
              " [15, 19, 5, 22, 14, 6, 10, 0, 3, 3, 4, 20, 6, 4, 5, 15, 20, 4, 7, 0],\n",
              " [6, 10, 0, 3, 3, 4, 20, 6, 4, 5, 15, 20, 4, 7, 0, 1, 2, 16, 0, 11],\n",
              " [4, 20, 6, 4, 5, 15, 20, 4, 7, 0, 1, 2, 16, 0, 11, 20, 2, 10, 15, 13],\n",
              " [15, 20, 4, 7, 0, 1, 2, 16, 0, 11, 20, 2, 10, 15, 13, 4, 13, 19, 10, 20],\n",
              " [1, 2, 16, 0, 11, 20, 2, 10, 15, 13, 4, 13, 19, 10, 20, 4, 6, 1, 4, 0],\n",
              " [20, 2, 10, 15, 13, 4, 13, 19, 10, 20, 4, 6, 1, 4, 0, 4, 23, 6, 3, 19],\n",
              " [4, 13, 19, 10, 20, 4, 6, 1, 4, 0, 4, 23, 6, 3, 19, 20, 19, 11, 0, 3],\n",
              " [4, 6, 1, 4, 0, 4, 23, 6, 3, 19, 20, 19, 11, 0, 3, 4, 6, 23, 23, 6],\n",
              " [4, 23, 6, 3, 19, 20, 19, 11, 0, 3, 4, 6, 23, 23, 6, 1, 15, 1, 20, 19],\n",
              " [20, 19, 11, 0, 3, 4, 6, 23, 23, 6, 1, 15, 1, 20, 19, 20, 9, 4, 19, 3],\n",
              " [4, 6, 23, 23, 6, 1, 15, 1, 20, 19, 20, 9, 4, 19, 3, 3, 15, 5, 0, 3],\n",
              " [1, 15, 1, 20, 19, 20, 9, 4, 19, 3, 3, 15, 5, 0, 3, 4, 20, 22, 15, 4],\n",
              " [20, 9, 4, 19, 3, 3, 15, 5, 0, 3, 4, 20, 22, 15, 4, 15, 8, 19, 13, 15],\n",
              " [3, 15, 5, 0, 3, 4, 20, 22, 15, 4, 15, 8, 19, 13, 15, 1, 11, 15, 4, 19],\n",
              " [4, 20, 22, 15, 4, 15, 8, 19, 13, 15, 1, 11, 15, 4, 19, 9, 4, 14, 15, 0],\n",
              " [15, 8, 19, 13, 15, 1, 11, 15, 4, 19, 9, 4, 14, 15, 0, 10, 19, 1, 5, 4],\n",
              " [1, 11, 15, 4, 19, 9, 4, 14, 15, 0, 10, 19, 1, 5, 4, 16, 10, 2, 19, 20],\n",
              " [9, 4, 14, 15, 0, 10, 19, 1, 5, 4, 16, 10, 2, 19, 20, 4, 20, 22, 15, 4],\n",
              " [10, 19, 1, 5, 4, 16, 10, 2, 19, 20, 4, 20, 22, 15, 4, 20, 19, 7, 15, 4],\n",
              " [16, 10, 2, 19, 20, 4, 20, 22, 15, 4, 20, 19, 7, 15, 4, 17, 19, 3, 3, 4],\n",
              " [4, 20, 22, 15, 4, 20, 19, 7, 15, 4, 17, 19, 3, 3, 4, 11, 6, 7, 15, 4],\n",
              " [20, 19, 7, 15, 4, 17, 19, 3, 3, 4, 11, 6, 7, 15, 4, 0, 1, 13, 4, 24],\n",
              " [17, 19, 3, 3, 4, 11, 6, 7, 15, 4, 0, 1, 13, 4, 24, 2, 9, 20, 19, 11],\n",
              " [11, 6, 7, 15, 4, 0, 1, 13, 4, 24, 2, 9, 20, 19, 11, 15, 4, 17, 19, 3],\n",
              " [0, 1, 13, 4, 24, 2, 9, 20, 19, 11, 15, 4, 17, 19, 3, 3, 4, 14, 15, 4],\n",
              " [2, 9, 20, 19, 11, 15, 4, 17, 19, 3, 3, 4, 14, 15, 4, 9, 15, 10, 8, 15],\n",
              " [15, 4, 17, 19, 3, 3, 4, 14, 15, 4, 9, 15, 10, 8, 15, 13, 20, 22, 15, 4],\n",
              " [3, 4, 14, 15, 4, 9, 15, 10, 8, 15, 13, 20, 22, 15, 4, 23, 10, 15, 9, 19],\n",
              " [9, 15, 10, 8, 15, 13, 20, 22, 15, 4, 23, 10, 15, 9, 19, 13, 15, 1, 20, 9],\n",
              " [13, 20, 22, 15, 4, 23, 10, 15, 9, 19, 13, 15, 1, 20, 9, 4, 23, 15, 10, 9],\n",
              " [23, 10, 15, 9, 19, 13, 15, 1, 20, 9, 4, 23, 15, 10, 9, 6, 1, 0, 3, 4],\n",
              " [13, 15, 1, 20, 9, 4, 23, 15, 10, 9, 6, 1, 0, 3, 4, 0, 23, 23, 10, 6],\n",
              " [4, 23, 15, 10, 9, 6, 1, 0, 3, 4, 0, 23, 23, 10, 6, 8, 0, 3, 4, 10],\n",
              " [6, 1, 0, 3, 4, 0, 23, 23, 10, 6, 8, 0, 3, 4, 10, 0, 20, 19, 1, 5],\n",
              " [0, 23, 23, 10, 6, 8, 0, 3, 4, 10, 0, 20, 19, 1, 5, 4, 10, 15, 7, 0],\n",
              " [8, 0, 3, 4, 10, 0, 20, 19, 1, 5, 4, 10, 15, 7, 0, 19, 1, 9, 4, 3],\n",
              " [0, 20, 19, 1, 5, 4, 10, 15, 7, 0, 19, 1, 9, 4, 3, 6, 17, 4, 20, 22],\n",
              " [4, 10, 15, 7, 0, 19, 1, 9, 4, 3, 6, 17, 4, 20, 22, 6, 2, 5, 22, 4],\n",
              " [19, 1, 9, 4, 3, 6, 17, 4, 20, 22, 6, 2, 5, 22, 4, 9, 20, 0, 14, 3],\n",
              " [6, 17, 4, 20, 22, 6, 2, 5, 22, 4, 9, 20, 0, 14, 3, 15, 4, 14, 2, 20],\n",
              " [6, 2, 5, 22, 4, 9, 20, 0, 14, 3, 15, 4, 14, 2, 20, 4, 20, 22, 15, 10],\n",
              " [9, 20, 0, 14, 3, 15, 4, 14, 2, 20, 4, 20, 22, 15, 10, 15, 4, 19, 9, 4],\n",
              " [15, 4, 14, 2, 20, 4, 20, 22, 15, 10, 15, 4, 19, 9, 4, 5, 10, 6, 17, 19],\n",
              " [4, 20, 22, 15, 10, 15, 4, 19, 9, 4, 5, 10, 6, 17, 19, 1, 5, 4, 9, 2],\n",
              " [15, 4, 19, 9, 4, 5, 10, 6, 17, 19, 1, 5, 4, 9, 2, 23, 23, 6, 10, 20],\n",
              " [5, 10, 6, 17, 19, 1, 5, 4, 9, 2, 23, 23, 6, 10, 20, 4, 16, 6, 10, 4],\n",
              " [1, 5, 4, 9, 2, 23, 23, 6, 10, 20, 4, 16, 6, 10, 4, 19, 7, 23, 15, 0],\n",
              " [23, 23, 6, 10, 20, 4, 16, 6, 10, 4, 19, 7, 23, 15, 0, 11, 22, 7, 15, 1],\n",
              " [4, 16, 6, 10, 4, 19, 7, 23, 15, 0, 11, 22, 7, 15, 1, 20, 0, 4, 16, 6],\n",
              " [19, 7, 23, 15, 0, 11, 22, 7, 15, 1, 20, 0, 4, 16, 6, 25, 4, 1, 15, 17],\n",
              " [11, 22, 7, 15, 1, 20, 0, 4, 16, 6, 25, 4, 1, 15, 17, 9, 4, 23, 6, 3],\n",
              " [20, 0, 4, 16, 6, 25, 4, 1, 15, 17, 9, 4, 23, 6, 3, 3, 4, 20, 22, 19],\n",
              " [25, 4, 1, 15, 17, 9, 4, 23, 6, 3, 3, 4, 20, 22, 19, 9, 4, 17, 15, 15],\n",
              " [9, 4, 23, 6, 3, 3, 4, 20, 22, 19, 9, 4, 17, 15, 15, 12, 4, 16, 6, 2],\n",
              " [3, 4, 20, 22, 19, 9, 4, 17, 15, 15, 12, 4, 16, 6, 2, 1, 13, 4, 20, 22],\n",
              " [9, 4, 17, 15, 15, 12, 4, 16, 6, 2, 1, 13, 4, 20, 22, 0, 20, 23, 15, 10],\n",
              " [12, 4, 16, 6, 2, 1, 13, 4, 20, 22, 0, 20, 23, 15, 10, 11, 15, 1, 20, 4],\n",
              " [1, 13, 4, 20, 22, 0, 20, 23, 15, 10, 11, 15, 1, 20, 4, 9, 2, 23, 23, 6],\n",
              " [0, 20, 23, 15, 10, 11, 15, 1, 20, 4, 9, 2, 23, 23, 6, 10, 20, 4, 10, 15],\n",
              " [11, 15, 1, 20, 4, 9, 2, 23, 23, 6, 10, 20, 4, 10, 15, 7, 6, 8, 19, 1],\n",
              " [9, 2, 23, 23, 6, 10, 20, 4, 10, 15, 7, 6, 8, 19, 1, 5, 4, 20, 10, 2],\n",
              " [10, 20, 4, 10, 15, 7, 6, 8, 19, 1, 5, 4, 20, 10, 2, 7, 23, 4, 16, 10],\n",
              " [7, 6, 8, 19, 1, 5, 4, 20, 10, 2, 7, 23, 4, 16, 10, 6, 7, 4, 6, 16],\n",
              " [5, 4, 20, 10, 2, 7, 23, 4, 16, 10, 6, 7, 4, 6, 16, 16, 19, 11, 15, 4],\n",
              " [7, 23, 4, 16, 10, 6, 7, 4, 6, 16, 16, 19, 11, 15, 4, 19, 1, 13, 15, 23],\n",
              " [6, 7, 4, 6, 16, 16, 19, 11, 15, 4, 19, 1, 13, 15, 23, 15, 1, 13, 15, 1],\n",
              " [16, 19, 11, 15, 4, 19, 1, 13, 15, 23, 15, 1, 13, 15, 1, 20, 9, 4, 0, 9],\n",
              " [19, 1, 13, 15, 23, 15, 1, 13, 15, 1, 20, 9, 4, 0, 9, 4, 17, 15, 3, 3],\n",
              " [15, 1, 13, 15, 1, 20, 9, 4, 0, 9, 4, 17, 15, 3, 3, 4, 0, 9, 4, 13],\n",
              " [20, 9, 4, 0, 9, 4, 17, 15, 3, 3, 4, 0, 9, 4, 13, 15, 7, 6, 11, 10],\n",
              " [4, 17, 15, 3, 3, 4, 0, 9, 4, 13, 15, 7, 6, 11, 10, 0, 20, 9, 4, 7],\n",
              " [4, 0, 9, 4, 13, 15, 7, 6, 11, 10, 0, 20, 9, 4, 7, 6, 9, 20, 3, 26],\n",
              " [15, 7, 6, 11, 10, 0, 20, 9, 4, 7, 6, 9, 20, 3, 26, 4, 9, 2, 23, 23],\n",
              " [0, 20, 9, 4, 7, 6, 9, 20, 3, 26, 4, 9, 2, 23, 23, 6, 10, 20, 4, 20],\n",
              " [6, 9, 20, 3, 26, 4, 9, 2, 23, 23, 6, 10, 20, 4, 20, 22, 15, 4, 19, 7],\n",
              " [4, 9, 2, 23, 23, 6, 10, 20, 4, 20, 22, 15, 4, 19, 7, 23, 15, 0, 11, 22],\n",
              " [6, 10, 20, 4, 20, 22, 15, 4, 19, 7, 23, 15, 0, 11, 22, 7, 15, 1, 20, 4],\n",
              " [22, 15, 4, 19, 7, 23, 15, 0, 11, 22, 7, 15, 1, 20, 4, 19, 1, 21, 2, 19],\n",
              " [23, 15, 0, 11, 22, 7, 15, 1, 20, 4, 19, 1, 21, 2, 19, 10, 26, 4, 17, 22],\n",
              " [7, 15, 1, 20, 4, 19, 1, 21, 2, 19, 10, 26, 4, 17, 22, 19, 3, 15, 4, 10],\n",
              " [19, 1, 21, 2, 19, 10, 26, 4, 17, 22, 19, 3, 15, 4, 10, 15, 23, 2, 14, 3],\n",
              " [10, 26, 4, 17, 22, 19, 3, 15, 4, 10, 15, 23, 2, 14, 3, 19, 11, 0, 1, 9],\n",
              " [19, 3, 15, 4, 10, 15, 23, 2, 14, 3, 19, 11, 0, 1, 9, 4, 0, 10, 15, 4],\n",
              " [15, 23, 2, 14, 3, 19, 11, 0, 1, 9, 4, 0, 10, 15, 4, 7, 6, 9, 20, 3],\n",
              " [19, 11, 0, 1, 9, 4, 0, 10, 15, 4, 7, 6, 9, 20, 3, 26, 4, 22, 6, 3],\n",
              " [4, 0, 10, 15, 4, 7, 6, 9, 20, 3, 26, 4, 22, 6, 3, 13, 19, 1, 5, 4],\n",
              " [7, 6, 9, 20, 3, 26, 4, 22, 6, 3, 13, 19, 1, 5, 4, 20, 19, 5, 22, 20],\n",
              " [26, 4, 22, 6, 3, 13, 19, 1, 5, 4, 20, 19, 5, 22, 20, 4, 20, 22, 15, 9],\n",
              " [13, 19, 1, 5, 4, 20, 19, 5, 22, 20, 4, 20, 22, 15, 9, 15, 4, 20, 22, 19],\n",
              " [20, 19, 5, 22, 20, 4, 20, 22, 15, 9, 15, 4, 20, 22, 19, 1, 5, 9, 4, 7],\n",
              " [4, 20, 22, 15, 9, 15, 4, 20, 22, 19, 1, 5, 9, 4, 7, 0, 26, 4, 6, 10],\n",
              " [15, 4, 20, 22, 19, 1, 5, 9, 4, 7, 0, 26, 4, 6, 10, 4, 7, 0, 26, 4],\n",
              " [1, 5, 9, 4, 7, 0, 26, 4, 6, 10, 4, 7, 0, 26, 4, 1, 6, 20, 4, 11],\n",
              " [0, 26, 4, 6, 10, 4, 7, 0, 26, 4, 1, 6, 20, 4, 11, 22, 0, 1, 5, 15],\n",
              " [4, 7, 0, 26, 4, 1, 6, 20, 4, 11, 22, 0, 1, 5, 15, 15, 19, 20, 22, 15],\n",
              " [1, 6, 20, 4, 11, 22, 0, 1, 5, 15, 15, 19, 20, 22, 15, 10, 4, 17, 0, 26],\n",
              " [22, 0, 1, 5, 15, 15, 19, 20, 22, 15, 10, 4, 17, 0, 26, 4, 17, 15, 4, 17],\n",
              " [15, 19, 20, 22, 15, 10, 4, 17, 0, 26, 4, 17, 15, 4, 17, 19, 3, 3, 4, 14],\n",
              " [10, 4, 17, 0, 26, 4, 17, 15, 4, 17, 19, 3, 3, 4, 14, 15, 4, 11, 22, 0],\n",
              " [4, 17, 15, 4, 17, 19, 3, 3, 4, 14, 15, 4, 11, 22, 0, 1, 5, 15, 13, 4],\n",
              " [19, 3, 3, 4, 14, 15, 4, 11, 22, 0, 1, 5, 15, 13, 4, 19, 16, 4, 17, 15],\n",
              " [15, 4, 11, 22, 0, 1, 5, 15, 13, 4, 19, 16, 4, 17, 15, 4, 13, 6, 4, 1],\n",
              " [1, 5, 15, 13, 4, 19, 16, 4, 17, 15, 4, 13, 6, 4, 1, 6, 20, 4, 10, 19],\n",
              " [19, 16, 4, 17, 15, 4, 13, 6, 4, 1, 6, 20, 4, 10, 19, 5, 22, 20, 4, 20],\n",
              " [4, 13, 6, 4, 1, 6, 20, 4, 10, 19, 5, 22, 20, 4, 20, 22, 19, 9, 4, 9],\n",
              " [6, 20, 4, 10, 19, 5, 22, 20, 4, 20, 22, 19, 9, 4, 9, 22, 19, 23, 4, 6],\n",
              " [5, 22, 20, 4, 20, 22, 19, 9, 4, 9, 22, 19, 23, 4, 6, 16, 4, 13, 15, 7],\n",
              " [22, 19, 9, 4, 9, 22, 19, 23, 4, 6, 16, 4, 13, 15, 7, 6, 11, 10, 0, 11],\n",
              " [22, 19, 23, 4, 6, 16, 4, 13, 15, 7, 6, 11, 10, 0, 11, 26, 19, 7, 23, 15],\n",
              " [16, 4, 13, 15, 7, 6, 11, 10, 0, 11, 26, 19, 7, 23, 15, 0, 11, 22, 7, 15],\n",
              " [6, 11, 10, 0, 11, 26, 19, 7, 23, 15, 0, 11, 22, 7, 15, 1, 20, 4, 19, 9],\n",
              " [26, 19, 7, 23, 15, 0, 11, 22, 7, 15, 1, 20, 4, 19, 9, 4, 1, 6, 20, 4],\n",
              " [0, 11, 22, 7, 15, 1, 20, 4, 19, 9, 4, 1, 6, 20, 4, 0, 14, 6, 2, 20],\n",
              " [1, 20, 4, 19, 9, 4, 1, 6, 20, 4, 0, 14, 6, 2, 20, 4, 23, 2, 1, 19],\n",
              " [4, 1, 6, 20, 4, 0, 14, 6, 2, 20, 4, 23, 2, 1, 19, 9, 22, 7, 15, 1],\n",
              " [0, 14, 6, 2, 20, 4, 23, 2, 1, 19, 9, 22, 7, 15, 1, 20, 4, 19, 7, 23],\n",
              " [4, 23, 2, 1, 19, 9, 22, 7, 15, 1, 20, 4, 19, 7, 23, 15, 0, 11, 22, 7],\n",
              " [9, 22, 7, 15, 1, 20, 4, 19, 7, 23, 15, 0, 11, 22, 7, 15, 1, 20, 4, 19],\n",
              " [20, 4, 19, 7, 23, 15, 0, 11, 22, 7, 15, 1, 20, 4, 19, 9, 4, 0, 14, 6],\n",
              " [15, 0, 11, 22, 7, 15, 1, 20, 4, 19, 9, 4, 0, 14, 6, 2, 20, 4, 11, 3],\n",
              " [15, 1, 20, 4, 19, 9, 4, 0, 14, 6, 2, 20, 4, 11, 3, 15, 0, 1, 9, 19],\n",
              " [9, 4, 0, 14, 6, 2, 20, 4, 11, 3, 15, 0, 1, 9, 19, 1, 5, 4, 20, 22],\n",
              " [2, 20, 4, 11, 3, 15, 0, 1, 9, 19, 1, 5, 4, 20, 22, 15, 4, 6, 16, 16],\n",
              " [15, 0, 1, 9, 19, 1, 5, 4, 20, 22, 15, 4, 6, 16, 16, 19, 11, 15, 4, 19],\n",
              " [1, 5, 4, 20, 22, 15, 4, 6, 16, 16, 19, 11, 15, 4, 19, 7, 23, 15, 0, 11],\n",
              " [15, 4, 6, 16, 16, 19, 11, 15, 4, 19, 7, 23, 15, 0, 11, 22, 7, 15, 1, 20],\n",
              " [19, 11, 15, 4, 19, 7, 23, 15, 0, 11, 22, 7, 15, 1, 20, 4, 19, 9, 4, 0],\n",
              " [7, 23, 15, 0, 11, 22, 7, 15, 1, 20, 4, 19, 9, 4, 0, 14, 6, 2, 20, 4],\n",
              " [22, 7, 15, 1, 20, 4, 19, 9, 4, 0, 14, 6, 2, 20, 4, 10, 15, 9, 20, 6],\n",
              " [4, 19, 9, 4, 0, 14, 6, 2, 20, 4, 10, 15, 9, 20, 6, 10, 19, 1, 5, 4],\n",
              " [14, 6, 2, 20, 4, 10, 15, 9, 20, 6, 10, 19, 1, 5, 4, 22, 6, 1, 6, 10],\n",
              " [10, 15, 9, 20, 6, 10, 19, 1, 5, 4, 22, 6, 1, 6, 10, 4, 0, 1, 13, 4],\n",
              " [10, 19, 1, 5, 4, 22, 6, 1, 6, 10, 4, 0, 1, 13, 4, 19, 1, 20, 15, 5],\n",
              " [22, 6, 1, 6, 10, 4, 0, 1, 13, 4, 19, 1, 20, 15, 5, 10, 19, 20, 26, 4],\n",
              " [4, 0, 1, 13, 4, 19, 1, 20, 15, 5, 10, 19, 20, 26, 4, 20, 6, 4, 20, 22],\n",
              " [19, 1, 20, 15, 5, 10, 19, 20, 26, 4, 20, 6, 4, 20, 22, 15, 4, 6, 16, 16],\n",
              " [10, 19, 20, 26, 4, 20, 6, 4, 20, 22, 15, 4, 6, 16, 16, 19, 11, 15, 4, 17],\n",
              " [20, 6, 4, 20, 22, 15, 4, 6, 16, 16, 19, 11, 15, 4, 17, 15, 4, 9, 22, 6],\n",
              " [15, 4, 6, 16, 16, 19, 11, 15, 4, 17, 15, 4, 9, 22, 6, 2, 3, 13, 4, 22],\n",
              " [19, 11, 15, 4, 17, 15, 4, 9, 22, 6, 2, 3, 13, 4, 22, 15, 15, 13, 4, 20],\n",
              " [15, 4, 9, 22, 6, 2, 3, 13, 4, 22, 15, 15, 13, 4, 20, 22, 15, 9, 15, 4],\n",
              " [2, 3, 13, 4, 22, 15, 15, 13, 4, 20, 22, 15, 9, 15, 4, 17, 6, 10, 13, 9],\n",
              " [15, 15, 13, 4, 20, 22, 15, 9, 15, 4, 17, 6, 10, 13, 9, 4, 9, 23, 6, 12],\n",
              " [22, 15, 9, 15, 4, 17, 6, 10, 13, 9, 4, 9, 23, 6, 12, 15, 1, 4, 14, 26],\n",
              " [17, 6, 10, 13, 9, 4, 9, 23, 6, 12, 15, 1, 4, 14, 26, 4, 20, 22, 15, 8],\n",
              " [4, 9, 23, 6, 12, 15, 1, 4, 14, 26, 4, 20, 22, 15, 8, 15, 10, 9, 19, 6],\n",
              " [15, 1, 4, 14, 26, 4, 20, 22, 15, 8, 15, 10, 9, 19, 6, 1, 4, 6, 16, 4],\n",
              " [4, 20, 22, 15, 8, 15, 10, 9, 19, 6, 1, 4, 6, 16, 4, 9, 15, 1, 4, 3],\n",
              " [15, 10, 9, 19, 6, 1, 4, 6, 16, 4, 9, 15, 1, 4, 3, 19, 1, 13, 9, 15],\n",
              " [1, 4, 6, 16, 4, 9, 15, 1, 4, 3, 19, 1, 13, 9, 15, 26, 4, 6, 4, 5],\n",
              " [9, 15, 1, 4, 3, 19, 1, 13, 9, 15, 26, 4, 6, 4, 5, 10, 0, 22, 0, 7],\n",
              " [19, 1, 13, 9, 15, 26, 4, 6, 4, 5, 10, 0, 22, 0, 7, 4, 10, 9, 11, 4],\n",
              " [26, 4, 6, 4, 5, 10, 0, 22, 0, 7, 4, 10, 9, 11, 4, 20, 22, 15, 4, 16],\n",
              " [10, 0, 22, 0, 7, 4, 10, 9, 11, 4, 20, 22, 15, 4, 16, 19, 10, 15, 4, 13],\n",
              " [4, 10, 9, 11, 4, 20, 22, 15, 4, 16, 19, 10, 15, 4, 13, 19, 13, 4, 1, 6],\n",
              " [20, 22, 15, 4, 16, 19, 10, 15, 4, 13, 19, 13, 4, 1, 6, 20, 4, 9, 20, 0],\n",
              " [19, 10, 15, 4, 13, 19, 13, 4, 1, 6, 20, 4, 9, 20, 0, 10, 20, 4, 17, 19],\n",
              " [19, 13, 4, 1, 6, 20, 4, 9, 20, 0, 10, 20, 4, 17, 19, 20, 22, 4, 2, 12],\n",
              " [20, 4, 9, 20, 0, 10, 20, 4, 17, 19, 20, 22, 4, 2, 12, 10, 0, 19, 1, 15],\n",
              " [10, 20, 4, 17, 19, 20, 22, 4, 2, 12, 10, 0, 19, 1, 15, 4, 1, 6, 1, 15],\n",
              " [20, 22, 4, 2, 12, 10, 0, 19, 1, 15, 4, 1, 6, 1, 15, 20, 22, 15, 3, 15],\n",
              " [10, 0, 19, 1, 15, 4, 1, 6, 1, 15, 20, 22, 15, 3, 15, 9, 9, 4, 2, 12],\n",
              " [4, 1, 6, 1, 15, 20, 22, 15, 3, 15, 9, 9, 4, 2, 12, 10, 0, 19, 1, 15],\n",
              " [20, 22, 15, 3, 15, 9, 9, 4, 2, 12, 10, 0, 19, 1, 15, 4, 7, 0, 26, 4],\n",
              " [9, 9, 4, 2, 12, 10, 0, 19, 1, 15, 4, 7, 0, 26, 4, 5, 19, 8, 15, 4],\n",
              " [10, 0, 19, 1, 15, 4, 7, 0, 26, 4, 5, 19, 8, 15, 4, 2, 9, 4, 20, 22],\n",
              " [4, 7, 0, 26, 4, 5, 19, 8, 15, 4, 2, 9, 4, 20, 22, 15, 4, 17, 0, 20],\n",
              " [5, 19, 8, 15, 4, 2, 9, 4, 20, 22, 15, 4, 17, 0, 20, 15, 10, 4, 20, 6],\n",
              " [2, 9, 4, 20, 22, 15, 4, 17, 0, 20, 15, 10, 4, 20, 6, 4, 16, 19, 1, 0],\n",
              " [15, 4, 17, 0, 20, 15, 10, 4, 20, 6, 4, 16, 19, 1, 0, 3, 3, 26, 4, 23],\n",
              " [15, 10, 4, 20, 6, 4, 16, 19, 1, 0, 3, 3, 26, 4, 23, 2, 20, 4, 19, 20],\n",
              " [4, 16, 19, 1, 0, 3, 3, 26, 4, 23, 2, 20, 4, 19, 20, 4, 6, 2, 20, 10],\n",
              " [3, 3, 26, 4, 23, 2, 20, 4, 19, 20, 4, 6, 2, 20, 10, 15, 0, 13, 4, 7],\n",
              " [2, 20, 4, 19, 20, 4, 6, 2, 20, 10, 15, 0, 13, 4, 7, 6, 10, 15, 4, 16],\n",
              " [4, 6, 2, 20, 10, 15, 0, 13, 4, 7, 6, 10, 15, 4, 16, 10, 6, 7, 4, 13],\n",
              " [15, 0, 13, 4, 7, 6, 10, 15, 4, 16, 10, 6, 7, 4, 13, 6, 1, 1, 0, 4],\n",
              " [6, 10, 15, 4, 16, 10, 6, 7, 4, 13, 6, 1, 1, 0, 4, 16, 4, 15, 13, 17],\n",
              " [10, 6, 7, 4, 13, 6, 1, 1, 0, 4, 16, 4, 15, 13, 17, 0, 10, 13, 9, 9],\n",
              " [6, 1, 1, 0, 4, 16, 4, 15, 13, 17, 0, 10, 13, 9, 9, 4, 0, 10, 11, 22],\n",
              " [16, 4, 15, 13, 17, 0, 10, 13, 9, 9, 4, 0, 10, 11, 22, 19, 8, 15, 4, 17],\n",
              " [0, 10, 13, 9, 9, 4, 0, 10, 11, 22, 19, 8, 15, 4, 17, 22, 15, 1, 4, 23],\n",
              " [4, 0, 10, 11, 22, 19, 8, 15, 4, 17, 22, 15, 1, 4, 23, 10, 15, 9, 19, 13],\n",
              " [19, 8, 15, 4, 17, 22, 15, 1, 4, 23, 10, 15, 9, 19, 13, 15, 1, 20, 4, 20],\n",
              " [22, 15, 1, 4, 23, 10, 15, 9, 19, 13, 15, 1, 20, 4, 20, 10, 2, 7, 23, 4],\n",
              " [10, 15, 9, 19, 13, 15, 1, 20, 4, 20, 10, 2, 7, 23, 4, 0, 1, 1, 6, 2],\n",
              " [15, 1, 20, 4, 20, 10, 2, 7, 23, 4, 0, 1, 1, 6, 2, 1, 11, 15, 13, 4],\n",
              " [10, 2, 7, 23, 4, 0, 1, 1, 6, 2, 1, 11, 15, 13, 4, 22, 19, 9, 4, 13],\n",
              " [0, 1, 1, 6, 2, 1, 11, 15, 13, 4, 22, 19, 9, 4, 13, 15, 11, 19, 9, 19],\n",
              " [1, 11, 15, 13, 4, 22, 19, 9, 4, 13, 15, 11, 19, 9, 19, 6, 1, 4, 20, 6],\n",
              " [22, 19, 9, 4, 13, 15, 11, 19, 9, 19, 6, 1, 4, 20, 6, 4, 23, 2, 3, 3],\n",
              " [15, 11, 19, 9, 19, 6, 1, 4, 20, 6, 4, 23, 2, 3, 3, 4, 20, 10, 6, 6],\n",
              " [6, 1, 4, 20, 6, 4, 23, 2, 3, 3, 4, 20, 10, 6, 6, 23, 9, 4, 16, 10],\n",
              " [4, 23, 2, 3, 3, 4, 20, 10, 6, 6, 23, 9, 4, 16, 10, 6, 7, 4, 1, 6],\n",
              " [4, 20, 10, 6, 6, 23, 9, 4, 16, 10, 6, 7, 4, 1, 6, 10, 20, 22, 15, 10],\n",
              " [23, 9, 4, 16, 10, 6, 7, 4, 1, 6, 10, 20, 22, 15, 10, 1, 4, 9, 26, 10],\n",
              " [6, 7, 4, 1, 6, 10, 20, 22, 15, 10, 1, 4, 9, 26, 10, 19, 0, 4, 22, 19],\n",
              " [10, 20, 22, 15, 10, 1, 4, 9, 26, 10, 19, 0, 4, 22, 19, 9, 4, 11, 10, 19],\n",
              " [1, 4, 9, 26, 10, 19, 0, 4, 22, 19, 9, 4, 11, 10, 19, 20, 19, 11, 9, 4],\n",
              " [19, 0, 4, 22, 19, 9, 4, 11, 10, 19, 20, 19, 11, 9, 4, 19, 7, 7, 15, 13],\n",
              " [9, 4, 11, 10, 19, 20, 19, 11, 9, 4, 19, 7, 7, 15, 13, 19, 0, 20, 15, 3],\n",
              " [20, 19, 11, 9, 4, 19, 7, 7, 15, 13, 19, 0, 20, 15, 3, 26, 4, 17, 0, 10],\n",
              " [19, 7, 7, 15, 13, 19, 0, 20, 15, 3, 26, 4, 17, 0, 10, 1, 15, 13, 4, 20],\n",
              " [19, 0, 20, 15, 3, 26, 4, 17, 0, 10, 1, 15, 13, 4, 20, 22, 0, 20, 4, 20],\n",
              " [26, 4, 17, 0, 10, 1, 15, 13, 4, 20, 22, 0, 20, 4, 20, 22, 15, 4, 7, 6],\n",
              " [1, 15, 13, 4, 20, 22, 0, 20, 4, 20, 22, 15, 4, 7, 6, 8, 15, 4, 17, 6],\n",
              " [22, 0, 20, 4, 20, 22, 15, 4, 7, 6, 8, 15, 4, 17, 6, 2, 3, 13, 4, 23],\n",
              " [22, 15, 4, 7, 6, 8, 15, 4, 17, 6, 2, 3, 13, 4, 23, 0, 8, 15, 4, 20],\n",
              " [8, 15, 4, 17, 6, 2, 3, 13, 4, 23, 0, 8, 15, 4, 20, 22, 15, 4, 17, 0],\n",
              " [2, 3, 13, 4, 23, 0, 8, 15, 4, 20, 22, 15, 4, 17, 0, 26, 4, 16, 6, 10],\n",
              " [0, 8, 15, 4, 20, 22, 15, 4, 17, 0, 26, 4, 16, 6, 10, 4, 0, 4, 20, 2],\n",
              " [22, 15, 4, 17, 0, 26, 4, 16, 6, 10, 4, 0, 4, 20, 2, 10, 12, 19, 9, 22],\n",
              " [26, 4, 16, 6, 10, 4, 0, 4, 20, 2, 10, 12, 19, 9, 22, 4, 6, 16, 16, 15],\n",
              " [4, 0, 4, 20, 2, 10, 12, 19, 9, 22, 4, 6, 16, 16, 15, 1, 9, 19, 8, 15],\n",
              " [10, 12, 19, 9, 22, 4, 6, 16, 16, 15, 1, 9, 19, 8, 15, 4, 17, 19, 20, 22],\n",
              " [4, 6, 16, 16, 15, 1, 9, 19, 8, 15, 4, 17, 19, 20, 22, 4, 23, 6, 20, 15],\n",
              " [1, 9, 19, 8, 15, 4, 17, 19, 20, 22, 4, 23, 6, 20, 15, 1, 20, 19, 0, 3],\n",
              " [4, 17, 19, 20, 22, 4, 23, 6, 20, 15, 1, 20, 19, 0, 3, 3, 26, 4, 11, 0],\n",
              " [4, 23, 6, 20, 15, 1, 20, 19, 0, 3, 3, 26, 4, 11, 0, 20, 0, 9, 20, 10],\n",
              " [1, 20, 19, 0, 3, 3, 26, 4, 11, 0, 20, 0, 9, 20, 10, 6, 23, 22, 19, 11],\n",
              " [3, 26, 4, 11, 0, 20, 0, 9, 20, 10, 6, 23, 22, 19, 11, 4, 10, 15, 23, 15],\n",
              " [20, 0, 9, 20, 10, 6, 23, 22, 19, 11, 4, 10, 15, 23, 15, 10, 11, 2, 9, 9],\n",
              " [6, 23, 22, 19, 11, 4, 10, 15, 23, 15, 10, 11, 2, 9, 9, 19, 6, 1, 9, 9],\n",
              " [4, 10, 15, 23, 15, 10, 11, 2, 9, 9, 19, 6, 1, 9, 9, 20, 0, 20, 15, 4],\n",
              " [10, 11, 2, 9, 9, 19, 6, 1, 9, 9, 20, 0, 20, 15, 4, 13, 15, 23, 0, 10],\n",
              " [19, 6, 1, 9, 9, 20, 0, 20, 15, 4, 13, 15, 23, 0, 10, 20, 7, 15, 1, 20],\n",
              " [20, 0, 20, 15, 4, 13, 15, 23, 0, 10, 20, 7, 15, 1, 20, 4, 6, 16, 16, 19],\n",
              " [13, 15, 23, 0, 10, 20, 7, 15, 1, 20, 4, 6, 16, 16, 19, 11, 19, 0, 3, 9],\n",
              " [20, 7, 15, 1, 20, 4, 6, 16, 16, 19, 11, 19, 0, 3, 9, 4, 9, 17, 19, 16],\n",
              " [4, 6, 16, 16, 19, 11, 19, 0, 3, 9, 4, 9, 17, 19, 16, 20, 3, 26, 4, 13],\n",
              " [11, 19, 0, 3, 9, 4, 9, 17, 19, 16, 20, 3, 26, 4, 13, 15, 1, 19, 15, 13],\n",
              " [4, 9, 17, 19, 16, 20, 3, 26, 4, 13, 15, 1, 19, 15, 13, 4, 20, 22, 0, 20],\n",
              " [20, 3, 26, 4, 13, 15, 1, 19, 15, 13, 4, 20, 22, 0, 20, 4, 20, 10, 2, 7],\n",
              " [15, 1, 19, 15, 13, 4, 20, 22, 0, 20, 4, 20, 10, 2, 7, 23, 4, 9, 2, 23],\n",
              " [4, 20, 22, 0, 20, 4, 20, 10, 2, 7, 23, 4, 9, 2, 23, 23, 6, 10, 20, 15],\n",
              " [4, 20, 10, 2, 7, 23, 4, 9, 2, 23, 23, 6, 10, 20, 15, 13, 4, 20, 22, 15],\n",
              " [23, 4, 9, 2, 23, 23, 6, 10, 20, 15, 13, 4, 20, 22, 15, 4, 20, 2, 10, 12],\n",
              " [23, 6, 10, 20, 15, 13, 4, 20, 22, 15, 4, 20, 2, 10, 12, 19, 9, 22, 4, 19],\n",
              " [13, 4, 20, 22, 15, 4, 20, 2, 10, 12, 19, 9, 22, 4, 19, 1, 11, 2, 10, 9],\n",
              " [4, 20, 2, 10, 12, 19, 9, 22, 4, 19, 1, 11, 2, 10, 9, 19, 6, 1, 4, 7],\n",
              " [19, 9, 22, 4, 19, 1, 11, 2, 10, 9, 19, 6, 1, 4, 7, 15, 0, 1, 17, 22],\n",
              " [1, 11, 2, 10, 9, 19, 6, 1, 4, 7, 15, 0, 1, 17, 22, 19, 3, 15, 4, 20],\n",
              " [19, 6, 1, 4, 7, 15, 0, 1, 17, 22, 19, 3, 15, 4, 20, 10, 2, 7, 23, 4],\n",
              " [15, 0, 1, 17, 22, 19, 3, 15, 4, 20, 10, 2, 7, 23, 4, 0, 23, 23, 15, 0],\n",
              " [19, 3, 15, 4, 20, 10, 2, 7, 23, 4, 0, 23, 23, 15, 0, 10, 15, 13, 4, 11],\n",
              " [10, 2, 7, 23, 4, 0, 23, 23, 15, 0, 10, 15, 13, 4, 11, 6, 1, 8, 19, 1],\n",
              " [0, 23, 23, 15, 0, 10, 15, 13, 4, 11, 6, 1, 8, 19, 1, 11, 15, 13, 4, 20],\n",
              " [10, 15, 13, 4, 11, 6, 1, 8, 19, 1, 11, 15, 13, 4, 20, 22, 0, 20, 4, 22],\n",
              " [6, 1, 8, 19, 1, 11, 15, 13, 4, 20, 22, 0, 20, 4, 22, 15, 4, 22, 0, 13],\n",
              " [11, 15, 13, 4, 20, 22, 0, 20, 4, 22, 15, 4, 22, 0, 13, 4, 7, 0, 13, 15],\n",
              " [22, 0, 20, 4, 22, 15, 4, 22, 0, 13, 4, 7, 0, 13, 15, 4, 20, 22, 15, 4],\n",
              " [15, 4, 22, 0, 13, 4, 7, 0, 13, 15, 4, 20, 22, 15, 4, 10, 19, 5, 22, 20],\n",
              " [4, 7, 0, 13, 15, 4, 20, 22, 15, 4, 10, 19, 5, 22, 20, 4, 11, 22, 6, 19],\n",
              " [4, 20, 22, 15, 4, 10, 19, 5, 22, 20, 4, 11, 22, 6, 19, 11, 15, 20, 2, 10],\n",
              " [10, 19, 5, 22, 20, 4, 11, 22, 6, 19, 11, 15, 20, 2, 10, 12, 15, 26, 4, 15],\n",
              " [4, 11, 22, 6, 19, 11, 15, 20, 2, 10, 12, 15, 26, 4, 15, 2, 10, 6, 23, 15],\n",
              " [11, 15, 20, 2, 10, 12, 15, 26, 4, 15, 2, 10, 6, 23, 15, 4, 9, 26, 10, 19],\n",
              " [12, 15, 26, 4, 15, 2, 10, 6, 23, 15, 4, 9, 26, 10, 19, 0, 4, 19, 10, 0],\n",
              " [2, 10, 6, 23, 15, 4, 9, 26, 10, 19, 0, 4, 19, 10, 0, 1, 4, 19, 10, 0],\n",
              " [4, 9, 26, 10, 19, 0, 4, 19, 10, 0, 1, 4, 19, 10, 0, 21, 4, 10, 2, 9],\n",
              " [0, 4, 19, 10, 0, 1, 4, 19, 10, 0, 21, 4, 10, 2, 9, 9, 19, 0, 4, 0],\n",
              " [1, 4, 19, 10, 0, 21, 4, 10, 2, 9, 9, 19, 0, 4, 0, 1, 13, 4, 20, 22],\n",
              " [21, 4, 10, 2, 9, 9, 19, 0, 4, 0, 1, 13, 4, 20, 22, 15, 4, 12, 2, 10],\n",
              " [9, 19, 0, 4, 0, 1, 13, 4, 20, 22, 15, 4, 12, 2, 10, 13, 9, 4, 17, 19],\n",
              " [1, 13, 4, 20, 22, 15, 4, 12, 2, 10, 13, 9, 4, 17, 19, 3, 3, 4, 1, 6],\n",
              " [15, 4, 12, 2, 10, 13, 9, 4, 17, 19, 3, 3, 4, 1, 6, 17, 4, 22, 0, 8],\n",
              " [13, 9, 4, 17, 19, 3, 3, 4, 1, 6, 17, 4, 22, 0, 8, 15, 4, 20, 6, 4],\n",
              " [3, 3, 4, 1, 6, 17, 4, 22, 0, 8, 15, 4, 20, 6, 4, 16, 19, 5, 2, 10],\n",
              " [17, 4, 22, 0, 8, 15, 4, 20, 6, 4, 16, 19, 5, 2, 10, 15, 4, 20, 22, 15],\n",
              " [15, 4, 20, 6, 4, 16, 19, 5, 2, 10, 15, 4, 20, 22, 15, 4, 9, 19, 20, 2],\n",
              " [16, 19, 5, 2, 10, 15, 4, 20, 22, 15, 4, 9, 19, 20, 2, 0, 20, 19, 6, 1],\n",
              " [15, 4, 20, 22, 15, 4, 9, 19, 20, 2, 0, 20, 19, 6, 1, 4, 6, 2, 20, 4],\n",
              " [4, 9, 19, 20, 2, 0, 20, 19, 6, 1, 4, 6, 2, 20, 4, 20, 10, 2, 7, 23],\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "type(dctk)\n",
        "dctk.sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iz-8sI4cQv6V"
      },
      "source": [
        "`dctk.create_char_sequences()` first joins the text strings of the corpus of 136 documents into into a single text string, then splits that string into overlapping 20-character sequences, where the starting positions of the sequences are multiples of 5.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51eJlIJWlWT4"
      },
      "source": [
        "`dctk.create_char_sequences()` <br>\n",
        "* produces a list `dctk.sequences` which contains 168985 20-character sequences from the input data, with each character encoded by the integer position in the character dictionary.<br>\n",
        "* produces a list `dctk.next_char` which contains the next character for each of the 168985 20-character sequences, encoded as its index in the character vocabulary.<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "xJ929OX5h_l9",
        "outputId": "b3625f1f-32b8-4e81-ec48-8466a49abd97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The  27  unique characters are  ['a', 'n', 'u', 'l', ' ', 'g', 'o', 'm', 'v', 's', 'r', 'c', 'k', 'd', 'b', 'e', 'f', 'w', 'z', 'i', 't', 'q', 'h', 'p', 'j', 'x', 'y']\n",
            "<class 'list'>\n",
            "There are  168985 sequences\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[[11, 6, 1, 20, 10, 19, 14, 2, 20, 19, 1, 5, 4, 11, 6, 3, 2, 7, 1, 19],\n",
              " [19, 14, 2, 20, 19, 1, 5, 4, 11, 6, 3, 2, 7, 1, 19, 9, 20, 20, 22, 15]]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "print('The ',len(dctk.unique_chars),' unique characters are ',dctk.unique_chars)\n",
        "print(type(dctk.sequences))\n",
        "print('There are ',len(dctk.sequences),'sequences')\n",
        "display(dctk.sequences[:2])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOZ4jcXfnQJl"
      },
      "source": [
        "For each sequence, `dctk.next_char` contains the integer encoding for the next character we are trying to predict. Here are the values of `next_char` for the first 10 sequences:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8WFHJMTmO88",
        "outputId": "769501a8-a54a-40b5-c052-740045b3b6cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "168985\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[9, 4, 15, 6, 10, 13, 22, 22, 9, 13]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "print(len(dctk.next_char))\n",
        "dctk.next_char[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlmVXzV5nkHQ"
      },
      "source": [
        "The `dctk.create_X_and_Y` method produces X and y, which are the 1-hot encodings for the `sequence` and `next_char`.<br>\n",
        "The dimension of X will be (168985, 20, 27) and the dimension of y will be (168985, 27)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "LlA1J_28hvKi"
      },
      "outputs": [],
      "source": [
        "# create X and y split\n",
        "X, y = dctk.create_X_and_Y()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzYuQI60YWnG"
      },
      "source": [
        "Each character is represented as a one-hot encoded vector of length 27, with <br>\n",
        "positions corresponding to the \"vocabulary\" of all the possible characters. <br>\n",
        "There are 27 possible characters, including the space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ufh4culCPqSm",
        "outputId": "cbb3f332-a463-4ae0-e440-fb05ec80a078"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(168985, 20, 27)\n"
          ]
        }
      ],
      "source": [
        "print(type(X))\n",
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgZVK4satU8_"
      },
      "source": [
        "Here is the one-hot encoding of the first character in the first sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMkNvNWQtT7b",
        "outputId": "725d89f1-6daa-49a5-8697-f99831913fbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[False False False False False False False False False False False  True\n",
            " False False False False False False False False False False False False\n",
            " False False False]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(11)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "print(X[0,0,:])\n",
        "np.argmax(X[0,0,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-FzGr7_x5ujx",
        "outputId": "87ffd357-34bd-4b43-8505-a085eeb6c341"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'c'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "dctk.int_char[np.argmax(X[0,0,:])]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kshRsHRgtwO-"
      },
      "source": [
        "The rows of y are the one-hot encodings of `next_char`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NprE_erXqQR",
        "outputId": "fe786d20-4111-47ab-9313-7c9a87fe8175"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(168985, 27)\n",
            "[False False False False False False False False False  True False False\n",
            " False False False False False False False False False False False False\n",
            " False False False]\n",
            "9\n"
          ]
        }
      ],
      "source": [
        "print(type(y))\n",
        "print(y.shape)\n",
        "print(y[0,:])\n",
        "print(np.argmax(y[0,:]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZhgxBrJ86Cen",
        "outputId": "3de8cda1-48e5-4d7f-e3c2-7f05a2624ed5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'s'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "dctk.int_char[np.argmax(y[0,:])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_IOK_p3U9uCL",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-6a39513d81d87f1b",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "outputId": "d653fff8-71ee-4ad0-8798-4708525ee2ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "168985\n",
            "20\n",
            "[11, 6, 1, 20, 10, 19, 14, 2, 20, 19, 1, 5, 4, 11, 6, 3, 2, 7, 1, 19]\n"
          ]
        }
      ],
      "source": [
        "# dctk.sequences is our encoded doc-term matrix\n",
        "print(len(dctk.sequences))\n",
        "\n",
        "# each doc is maxlen values long\n",
        "print(len(dctk.sequences[0]))\n",
        "\n",
        "# want to know what this encoded document actually says?\n",
        "# you'll need to the char-int look up dictionaries\n",
        "print(dctk.sequences[0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oufq8xNKz3T_"
      },
      "source": [
        "`dctm` also produces character-to-integer and integer-to-character dictionaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laJUQImBSVJI",
        "outputId": "5f6d1d0e-3e25-496c-e189-2ebfc42966fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'a': 0, 'n': 1, 'u': 2, 'l': 3, ' ': 4, 'g': 5, 'o': 6, 'm': 7, 'v': 8, 's': 9, 'r': 10, 'c': 11, 'k': 12, 'd': 13, 'b': 14, 'e': 15, 'f': 16, 'w': 17, 'z': 18, 'i': 19, 't': 20, 'q': 21, 'h': 22, 'p': 23, 'j': 24, 'x': 25, 'y': 26}\n",
            "{0: 'a', 1: 'n', 2: 'u', 3: 'l', 4: ' ', 5: 'g', 6: 'o', 7: 'm', 8: 'v', 9: 's', 10: 'r', 11: 'c', 12: 'k', 13: 'd', 14: 'b', 15: 'e', 16: 'f', 17: 'w', 18: 'z', 19: 'i', 20: 't', 21: 'q', 22: 'h', 23: 'p', 24: 'j', 25: 'x', 26: 'y'}\n"
          ]
        }
      ],
      "source": [
        "# character to index dictionary\n",
        "# keys are chars\n",
        "# vlaues are ints\n",
        "print(dctk.char_int)\n",
        "\n",
        "# index to char dictionary\n",
        "# keys are ints\n",
        "# values are chars\n",
        "print(dctk.int_char)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUOiUSCuVyrS"
      },
      "source": [
        "#### Check that the character encoding works properly\n",
        "Use the integer-to-character dictionary to map the integer character encodings back to the characters they represent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed-GMMsU9uCL",
        "outputId": "a0259a98-fa68-461d-abea-cd7dd4a05a39"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(168985, 20, 27)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "# (num_seqs, seq length, num features)\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Jb_oqtoSKY9",
        "outputId": "85a6f318-3732-42f7-89df-50877e021ccc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "c\n",
            "o\n",
            "n\n",
            "t\n",
            "r\n",
            "i\n",
            "b\n",
            "u\n",
            "t\n",
            "i\n",
            "n\n",
            "g\n",
            " \n",
            "c\n",
            "o\n",
            "l\n",
            "u\n",
            "m\n",
            "n\n",
            "i\n",
            "27\n"
          ]
        }
      ],
      "source": [
        "# now we can check to see that our encoding is correct\n",
        "for ind in dctk.sequences[0]:\n",
        "    print (dctk.int_char[ind])\n",
        "\n",
        "# number of features is the total number of unique chars in our corpus\n",
        "print(dctk.n_features)\n",
        "\n",
        "# (num_seqs, num features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9hrvWPun6xw"
      },
      "source": [
        "Each successive sequence (after the first) starts with the 6th character of the previous sequence. <br>\n",
        "By using overlapping sequences, we get more sequences to train with.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QN7InnwnnAJ",
        "outputId": "b67b311a-749f-46d3-b86f-6546cb1e1f70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i\n",
            "b\n",
            "u\n",
            "t\n",
            "i\n",
            "n\n",
            "g\n",
            " \n",
            "c\n",
            "o\n",
            "l\n",
            "u\n",
            "m\n",
            "n\n",
            "i\n",
            "s\n",
            "t\n",
            "t\n",
            "h\n",
            "e\n"
          ]
        }
      ],
      "source": [
        "for ind in dctk.sequences[1]:\n",
        "    print (dctk.int_char[ind])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkopT0P2dycm"
      },
      "source": [
        "We are building a language model to predict the next character in a sequence, <br>\n",
        "so each target y is the character following the 20th character of that sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4Jxlm53Go4e",
        "outputId": "2602f40c-3d30-4604-fc47-889efdc5fbfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(168985, 27)\n",
            "[False False False False False False False False False  True False False\n",
            " False False False False False False False False False False False False\n",
            " False False False]\n",
            "9\n",
            "s\n"
          ]
        }
      ],
      "source": [
        "print(y.shape)\n",
        "print(y[0])\n",
        "print(np.argmax(y[0]))\n",
        "print (dctk.int_char[np.argmax(y[0])])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bbhYydZpd_v"
      },
      "source": [
        "The code that generates `X` and `y` is in `data_cleaning_toolkit` method `create_X_and_Y()`.<br><br>\n",
        "For the sequence in the $i\\text{th}$ row of `X`, the character the language model is trying to predict should be the character that comes after the 20th character. If there were no overlap between rows, this would be the first character in the next row. But each row starts with the 5th character in the previous row. So the 21st character is actually the 16th character in the next row, i.e. at index 15! <br><br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKDU1JaneiyL",
        "outputId": "8701b647-0ab1-468c-d078-3feeb4162b12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[np.int64(19), np.int64(14), np.int64(2), np.int64(20), np.int64(19), np.int64(1), np.int64(5), np.int64(4), np.int64(11), np.int64(6), np.int64(3), np.int64(2), np.int64(7), np.int64(1), np.int64(19), np.int64(9), np.int64(20), np.int64(20), np.int64(22), np.int64(15)]\n"
          ]
        }
      ],
      "source": [
        "print( [np.argmax(X[1,i,:]) for i in range(20) ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQtxBVBupByq",
        "outputId": "cc7ff694-4351-4278-c067-fe62e2b2ac3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "[np.int64(1), np.int64(5), np.int64(4), np.int64(11), np.int64(6), np.int64(3), np.int64(2), np.int64(7), np.int64(1), np.int64(19), np.int64(9), np.int64(20), np.int64(20), np.int64(22), np.int64(15), np.int64(4), np.int64(22), np.int64(6), np.int64(2), np.int64(9)]\n"
          ]
        }
      ],
      "source": [
        "print(np.argmax(y[1]))\n",
        "print( [np.argmax(X[2,i,:]) for i in range(20) ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEeMZQPJpNi_",
        "outputId": "39d885b7-0821-4984-8cbe-04d7efb524a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15\n",
            "[np.int64(3), np.int64(2), np.int64(7), np.int64(1), np.int64(19), np.int64(9), np.int64(20), np.int64(20), np.int64(22), np.int64(15), np.int64(4), np.int64(22), np.int64(6), np.int64(2), np.int64(9), np.int64(15), np.int64(4), np.int64(19), np.int64(9), np.int64(4)]\n"
          ]
        }
      ],
      "source": [
        "print(np.argmax(y[2]))\n",
        "print( [np.argmax(X[3,i,:]) for i in range(20) ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7vh28iwo8wJ"
      },
      "source": [
        "### Callback function `on_epoch_end`\n",
        "Provides feedback at the end of each epoch to help you gauge how your model is progressing:<br>\n",
        "Takes a sequence of 20 consecutive characters starting at a _randomly chosen_ position <br>\n",
        "in the articles corpus, predicts the next 20 characters using the current version <br>\n",
        "of the trained model, and prints these results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3y8ePgRz_Ov"
      },
      "source": [
        "`sample` is a helper function that generates a character by drawing a sample from a predicted probability distribution.<br>\n",
        "`temperature` is a hyper-parameter that, if different from 1, warps (narrows or broadens) the predicted probability distribution. <br>\n",
        "This can add some variety to the generated characters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "9Xgk-JomzwGX"
      },
      "outputs": [],
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    \"\"\"\n",
        "    Helper function to generate a sample character\n",
        "    Input is a predictions vector from our model, for example a set of 27 character probabilities\n",
        "    Output is the index of the generated character\n",
        "    \"\"\"\n",
        "    # convert predictions to an array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "\n",
        "    # use the temperature hyper-parameter to \"warp\" (sharpen or spread out) the probability distribution\n",
        "    preds = np.log(preds) / temperature\n",
        "\n",
        "    # use the softmax activation function to create a new list of probabilities\n",
        "    #   corresponding to the \"warped\" probability distribution\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "    # Draw a single sample from a multinomial distribution, given these probabilities\n",
        "    #   The sample will be a one-hot encoded character\n",
        "    \"\"\" Notes on the np.random.multinomial() function\n",
        "       The first argument is the number of \"trials\" we want: 1 in this case\n",
        "       The second argument is the list of probabilities for each character\n",
        "       The third argument is number of sets of \"trials\" we want: again, 1 in this case\n",
        "       By analogy with a dice-rolling experiment:\n",
        "          A \"trial\" consists of generating a single \"throw\" of a die with 27 faces;\n",
        "             each face corresponds to a character and its associated probability\n",
        "    \"\"\"\n",
        "\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "\n",
        "    # return the index that corresponds to the max probability\n",
        "    return np.argmax(probas)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPhu860ZEd3g"
      },
      "source": [
        "Create the `on_epoch_end` function to be passed into `LambdaCallback()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "Qn8EUXe29uCL"
      },
      "outputs": [],
      "source": [
        "def on_epoch_end(epoch, _):\n",
        "    \"\"\"\"\n",
        "    Function invoked at end of each epoch.\n",
        "    Prints the text generated by the current version of the model at this point\n",
        "    \"\"\"\n",
        "\n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "\n",
        "\n",
        "    # randomly draw a starting position in the corpus\n",
        "    start_index = random.randint(0, len(text) - dctk.maxlen - 1)\n",
        "\n",
        "    # Initialize the \"seed\" string with maxlen consecutive characters beginning at start_index\n",
        "    seed = text[start_index: start_index + dctk.maxlen]\n",
        "\n",
        "    # number of consecutive characters to generate to follow the seed text\n",
        "    n_characters = 20\n",
        "\n",
        "    print('----- Generating with seed: \"' + seed + '\"')\n",
        "    sys.stdout.write(seed)\n",
        "\n",
        "    # generate n_characters predicted by the model to follow the seed string\n",
        "    for _ in range(n_characters):\n",
        "\n",
        "        # initialize an array to hold the current seed string\n",
        "        #    in numerical form (i.e. one-hot encoded)\n",
        "        # so the seed string is represented by an array of size (1, maxlen, 27)\n",
        "        x_seed = np.zeros((1, dctk.maxlen, dctk.n_features))\n",
        "\n",
        "        # create the one-hot encoded numerical representation of the seed string,\n",
        "        for index, char in enumerate(seed):\n",
        "            x_seed[0, index, dctk.char_int[char]] = 1\n",
        "\n",
        "        # get the predicted probability distribution (for the next character\n",
        "        #    after the seed string) from the current model\n",
        "        preds = model.predict(x_seed, verbose=0)[0]\n",
        "\n",
        "        # generate the character _index_ of the next character from a probability distribution based on the predicted probabilities\n",
        "        char_index = sample(preds)\n",
        "        # convert the character _index_ to the corresponding _character_ using the index-to-character dictionary\n",
        "        char = dctk.int_char[char_index]\n",
        "\n",
        "        # update the seed string by _dropping_ the first character and _adding_ the generated character at the end,\n",
        "        #   thus forming the 20 character sequence for the next prediction\n",
        "        seed = seed[1:] + char\n",
        "\n",
        "        # use the flush() function to prepare to write the next character\n",
        "        sys.stdout.write(char)\n",
        "        sys.stdout.flush()\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9O8868cBUy_2"
      },
      "source": [
        "Create the `print_callback`, usingn the `LambdaCallback` class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "S0BFtoKUIM2x"
      },
      "outputs": [],
      "source": [
        "# create callback object that will print out text generation at the end of each epoch\n",
        "# use for real-time monitoring of model performance\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qIO5ZCcT-nV"
      },
      "source": [
        " Join all the news articles into one long text string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYl_K89k9uCM",
        "outputId": "9335bee2-0d4d-4b2b-f1f9-fca80c189205"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "844942\n"
          ]
        }
      ],
      "source": [
        "# join all the news articles into one long text string\n",
        "# need this for on_epoch_end()\n",
        "text = \" \".join(data)\n",
        "print(len(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53AGJKhk9uCM"
      },
      "source": [
        "---------\n",
        "### Build a Text Generating Model from the News Articles Corpus\n",
        "We see that within 50 epochs, the model has begun to learn to form intelligible words, <br>and it's still slowly training, i.e. the loss function is decreasing at each epoch. <br>\n",
        "By 150 epochs, the generated text usually includes one or more recognizable words per 20 characters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5Ql4CF896Vc"
      },
      "source": [
        "Set up the Adam optimizer to allow changing the learning rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7XeGd0a2MKi",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-0b9d84be1c960668",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "outputId": "2c153032-9cf8-4343-d4c5-29339d83e3a8",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "\u001b[1m1318/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6356\n",
            "----- Generating text after Epoch: 0\n",
            "----- Generating with seed: \" the room he said an\"\n",
            " the room he said andrsecono stheres wo \n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 2.6350\n",
            "Epoch 2/150\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.1789\n",
            "----- Generating text after Epoch: 1\n",
            "----- Generating with seed: \" far and away the wo\"\n",
            " far and away the woudhan ad ivionth wor\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 2.1789\n",
            "Epoch 3/150\n",
            "\u001b[1m1317/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0393\n",
            "----- Generating text after Epoch: 2\n",
            "----- Generating with seed: \"es and democrats say\"\n",
            "es and democrats say a plumingred the ma\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 2.0392\n",
            "Epoch 4/150\n",
            "\u001b[1m1318/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.9504\n",
            "----- Generating text after Epoch: 3\n",
            "----- Generating with seed: \"ends they played out\"\n",
            "ends they played outinather foen in rebu\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 1.9504\n",
            "Epoch 5/150\n",
            "\u001b[1m1315/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8720\n",
            "----- Generating text after Epoch: 4\n",
            "----- Generating with seed: \"he administration th\"\n",
            "he administration that botk wowley alles\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.8719\n",
            "Epoch 6/150\n",
            "\u001b[1m1309/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8115\n",
            "----- Generating text after Epoch: 5\n",
            "----- Generating with seed: \"age the meltdownand \"\n",
            "age the meltdownand in the opresmatery c\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 1.8113\n",
            "Epoch 7/150\n",
            "\u001b[1m1314/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7528\n",
            "----- Generating text after Epoch: 6\n",
            "----- Generating with seed: \" in line with the kr\"\n",
            " in line with the krean his by to our at\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.7528\n",
            "Epoch 8/150\n",
            "\u001b[1m1318/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7082\n",
            "----- Generating text after Epoch: 7\n",
            "----- Generating with seed: \"es the undrafted roo\"\n",
            "es the undrafted roole than all call whi\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.7082\n",
            "Epoch 9/150\n",
            "\u001b[1m1312/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6696\n",
            "----- Generating text after Epoch: 8\n",
            "----- Generating with seed: \"al time to participa\"\n",
            "al time to participary of warred she bur\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 1.6696\n",
            "Epoch 10/150\n",
            "\u001b[1m1318/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6342\n",
            "----- Generating text after Epoch: 9\n",
            "----- Generating with seed: \"the same for car rep\"\n",
            "the same for car reperssate a were pains\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.6342\n",
            "Epoch 11/150\n",
            "\u001b[1m1318/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6067\n",
            "----- Generating text after Epoch: 10\n",
            "----- Generating with seed: \"being enforced while\"\n",
            "being enforced while geatures comments l\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.6067\n",
            "Epoch 12/150\n",
            "\u001b[1m1314/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5814\n",
            "----- Generating text after Epoch: 11\n",
            "----- Generating with seed: \" to avoid the areaad\"\n",
            " to avoid the areaad it on officions gve\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 1.5814\n",
            "Epoch 13/150\n",
            "\u001b[1m1313/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5505\n",
            "----- Generating text after Epoch: 12\n",
            "----- Generating with seed: \"to blast homers rend\"\n",
            "to blast homers rendefable a retion his \n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.5505\n",
            "Epoch 14/150\n",
            "\u001b[1m1317/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5302\n",
            "----- Generating text after Epoch: 13\n",
            "----- Generating with seed: \" from american lawma\"\n",
            " from american lawmada vouddont complete\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 1.5302\n",
            "Epoch 15/150\n",
            "\u001b[1m1311/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5068\n",
            "----- Generating text after Epoch: 14\n",
            "----- Generating with seed: \"terry mclaurinthe ke\"\n",
            "terry mclaurinthe kersion fight jands in\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.5069\n",
            "Epoch 16/150\n",
            "\u001b[1m1315/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4841\n",
            "----- Generating text after Epoch: 15\n",
            "----- Generating with seed: \"people dont think ab\"\n",
            "people dont think about he it we haspond\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.4842\n",
            "Epoch 17/150\n",
            "\u001b[1m1312/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4672\n",
            "----- Generating text after Epoch: 16\n",
            "----- Generating with seed: \"s eastern flank befo\"\n",
            "s eastern flank before geresting will ca\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 1.4672\n",
            "Epoch 18/150\n",
            "\u001b[1m1309/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4469\n",
            "----- Generating text after Epoch: 17\n",
            "----- Generating with seed: \"of the deaths to the\"\n",
            "of the deaths to the moder liding a not \n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.4470\n",
            "Epoch 19/150\n",
            "\u001b[1m1311/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4350\n",
            "----- Generating text after Epoch: 18\n",
            "----- Generating with seed: \"s near the top of to\"\n",
            "s near the top of to the pared of the lo\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 1.4350\n",
            "Epoch 20/150\n",
            "\u001b[1m1311/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4115\n",
            "----- Generating text after Epoch: 19\n",
            "----- Generating with seed: \"if your aunt had jus\"\n",
            "if your aunt had justs remove on the pac\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.4116\n",
            "Epoch 21/150\n",
            "\u001b[1m1317/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3942\n",
            "----- Generating text after Epoch: 20\n",
            "----- Generating with seed: \"e or by other approp\"\n",
            "e or by other approps to daid of us inte\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.3942\n",
            "Epoch 22/150\n",
            "\u001b[1m1317/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3810\n",
            "----- Generating text after Epoch: 21\n",
            "----- Generating with seed: \"onse from one of fru\"\n",
            "onse from one of frums asout to idaition\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 1.3811\n",
            "Epoch 23/150\n",
            "\u001b[1m1311/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3638\n",
            "----- Generating text after Epoch: 22\n",
            "----- Generating with seed: \"blish enter into a d\"\n",
            "blish enter into a demons any as the tan\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.3639\n",
            "Epoch 24/150\n",
            "\u001b[1m1311/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3531\n",
            "----- Generating text after Epoch: 23\n",
            "----- Generating with seed: \"if they do run deep \"\n",
            "if they do run deep it twime a news repo\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 1.3532\n",
            "Epoch 25/150\n",
            "\u001b[1m1315/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3324\n",
            "----- Generating text after Epoch: 24\n",
            "----- Generating with seed: \" description would b\"\n",
            " description would be one cap find eativ\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 1.3325\n",
            "Epoch 26/150\n",
            "\u001b[1m1319/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3244\n",
            "----- Generating text after Epoch: 25\n",
            "----- Generating with seed: \"p these massacres th\"\n",
            "p these massacres the could been those o\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.3245\n",
            "Epoch 27/150\n",
            "\u001b[1m1313/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3120\n",
            "----- Generating text after Epoch: 26\n",
            "----- Generating with seed: \"in sweden and was no\"\n",
            "in sweden and was no muring readent of t\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 1.3121\n",
            "Epoch 28/150\n",
            "\u001b[1m1316/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3026\n",
            "----- Generating text after Epoch: 27\n",
            "----- Generating with seed: \"ed residents seeking\"\n",
            "ed residents seeking russian cliltical m\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.3027\n",
            "Epoch 29/150\n",
            "\u001b[1m1314/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2825\n",
            "----- Generating text after Epoch: 28\n",
            "----- Generating with seed: \"ure that provides a \"\n",
            "ure that provides a many enselleced with\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 1.2826\n",
            "Epoch 30/150\n",
            "\u001b[1m1312/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2835\n",
            "----- Generating text after Epoch: 29\n",
            "----- Generating with seed: \"ons back leg to forc\"\n",
            "ons back leg to forces both atceppair an\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 1.2836\n",
            "Epoch 31/150\n",
            "\u001b[1m1320/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2649\n",
            "----- Generating text after Epoch: 30\n",
            "----- Generating with seed: \"iden speaking on sun\"\n",
            "iden speaking on sungerties an anda pres\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.2649\n",
            "Epoch 32/150\n",
            "\u001b[1m1315/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2558\n",
            "----- Generating text after Epoch: 31\n",
            "----- Generating with seed: \"ternational communit\"\n",
            "ternational community were doing aras al\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 1.2559\n",
            "Epoch 33/150\n",
            "\u001b[1m1319/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2488\n",
            "----- Generating text after Epoch: 32\n",
            "----- Generating with seed: \"y the supreme court \"\n",
            "y the supreme court is performand outboo\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.2488\n",
            "Epoch 34/150\n",
            "\u001b[1m1314/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2319\n",
            "----- Generating text after Epoch: 33\n",
            "----- Generating with seed: \"rdoor sedan accordin\"\n",
            "rdoor sedan accordint to project to teln\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 1.2320\n",
            "Epoch 35/150\n",
            "\u001b[1m1309/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2211\n",
            "----- Generating text after Epoch: 34\n",
            "----- Generating with seed: \"ment against removin\"\n",
            "ment against removinuee that will sky of\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 1.2213\n",
            "Epoch 36/150\n",
            "\u001b[1m1318/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2130\n",
            "----- Generating text after Epoch: 35\n",
            "----- Generating with seed: \"such as online marke\"\n",
            "such as online market enited to a sugers\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.2130\n",
            "Epoch 37/150\n",
            "\u001b[1m1312/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2083\n",
            "----- Generating text after Epoch: 36\n",
            "----- Generating with seed: \"e works claimed to h\"\n",
            "e works claimed to has from fundyen the \n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 1.2084\n",
            "Epoch 38/150\n",
            "\u001b[1m1312/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2005\n",
            "----- Generating text after Epoch: 37\n",
            "----- Generating with seed: \"nto what appears to \"\n",
            "nto what appears to the enformation any \n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.2006\n",
            "Epoch 39/150\n",
            "\u001b[1m1320/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1912\n",
            "----- Generating text after Epoch: 38\n",
            "----- Generating with seed: \" showed him eager to\"\n",
            " showed him eager to the american fronth\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.1912\n",
            "Epoch 40/150\n",
            "\u001b[1m1311/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1811\n",
            "----- Generating text after Epoch: 39\n",
            "----- Generating with seed: \"t fortnite would fin\"\n",
            "t fortnite would final images of has pow\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 1.1812\n",
            "Epoch 41/150\n",
            "\u001b[1m1316/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1664\n",
            "----- Generating text after Epoch: 40\n",
            "----- Generating with seed: \"eerroasted mushrooms\"\n",
            "eerroasted mushrooms averainsation oc st\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.1666\n",
            "Epoch 42/150\n",
            "\u001b[1m1310/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1668\n",
            "----- Generating text after Epoch: 41\n",
            "----- Generating with seed: \"oma faces the same c\"\n",
            "oma faces the same commented blayip from\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 1.1670\n",
            "Epoch 43/150\n",
            "\u001b[1m1314/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1610\n",
            "----- Generating text after Epoch: 42\n",
            "----- Generating with seed: \"ery day with whippin\"\n",
            "ery day with whippinfeddly tites stopps \n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.1611\n",
            "Epoch 44/150\n",
            "\u001b[1m1316/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1540\n",
            "----- Generating text after Epoch: 43\n",
            "----- Generating with seed: \"redentials with any \"\n",
            "redentials with any pollticts opporturs \n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.1541\n",
            "Epoch 45/150\n",
            "\u001b[1m1320/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1396\n",
            "----- Generating text after Epoch: 44\n",
            "----- Generating with seed: \"ming native history \"\n",
            "ming native history the pattion of the t\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 1.1397\n",
            "Epoch 46/150\n",
            "\u001b[1m1316/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1373\n",
            "----- Generating text after Epoch: 45\n",
            "----- Generating with seed: \"bed as the epicenter\"\n",
            "bed as the epicenters freenusted finatio\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.1374\n",
            "Epoch 47/150\n",
            "\u001b[1m1312/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1328\n",
            "----- Generating text after Epoch: 46\n",
            "----- Generating with seed: \"esources and environ\"\n",
            "esources and environgic comes hel seemin\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 1.1329\n",
            "Epoch 48/150\n",
            "\u001b[1m1317/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1277\n",
            "----- Generating text after Epoch: 47\n",
            "----- Generating with seed: \" that has allowed to\"\n",
            " that has allowed to a taid parent thing\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.1278\n",
            "Epoch 49/150\n",
            "\u001b[1m1319/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1222\n",
            "----- Generating text after Epoch: 48\n",
            "----- Generating with seed: \"zure of the city of \"\n",
            "zure of the city of projespre is glowed \n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.1222\n",
            "Epoch 50/150\n",
            "\u001b[1m1316/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1143\n",
            "----- Generating text after Epoch: 49\n",
            "----- Generating with seed: \"dwayne haskins to st\"\n",
            "dwayne haskins to stree medition possess\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 1.1144\n",
            "Epoch 51/150\n",
            "\u001b[1m1313/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1166\n",
            "----- Generating text after Epoch: 50\n",
            "----- Generating with seed: \" foreign policy init\"\n",
            " foreign policy init or pebsough thank h\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.1167\n",
            "Epoch 52/150\n",
            "\u001b[1m1320/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1079\n",
            "----- Generating text after Epoch: 51\n",
            "----- Generating with seed: \" governmentturkishba\"\n",
            " governmentturkishbanks invasigate in th\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.1080\n",
            "Epoch 53/150\n",
            "\u001b[1m1311/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0959\n",
            "----- Generating text after Epoch: 52\n",
            "----- Generating with seed: \"life sentencesthen t\"\n",
            "life sentencesthen the collect and clear\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 1.0962\n",
            "Epoch 54/150\n",
            "\u001b[1m1318/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0977\n",
            "----- Generating text after Epoch: 53\n",
            "----- Generating with seed: \"bandoning kurdish fi\"\n",
            "bandoning kurdish fight of the pursie co\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.0978\n",
            "Epoch 55/150\n",
            "\u001b[1m1313/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0928\n",
            "----- Generating text after Epoch: 54\n",
            "----- Generating with seed: \"roberts kan and thom\"\n",
            "roberts kan and thomessaltion and turkey\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 1.0930\n",
            "Epoch 56/150\n",
            "\u001b[1m1311/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0875\n",
            "----- Generating text after Epoch: 55\n",
            "----- Generating with seed: \"enderson coming out \"\n",
            "enderson coming out any among out of the\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.0877\n",
            "Epoch 57/150\n",
            "\u001b[1m1311/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0871\n",
            "----- Generating text after Epoch: 56\n",
            "----- Generating with seed: \"ir best to fit in an\"\n",
            "ir best to fit in an lush quire their co\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.0873\n",
            "Epoch 58/150\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0887\n",
            "----- Generating text after Epoch: 57\n",
            "----- Generating with seed: \" message of a chart \"\n",
            " message of a chart must but pitch genle\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 1.0887\n",
            "Epoch 59/150\n",
            "\u001b[1m1312/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0755\n",
            "----- Generating text after Epoch: 58\n",
            "----- Generating with seed: \"el agent in dc durin\"\n",
            "el agent in dc during dont and pebcepped\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.0757\n",
            "Epoch 60/150\n",
            "\u001b[1m1318/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0778\n",
            "----- Generating text after Epoch: 59\n",
            "----- Generating with seed: \" you guys would be w\"\n",
            " you guys would be wall policiea politic\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.0779\n",
            "Epoch 61/150\n",
            "\u001b[1m1313/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0641\n",
            "----- Generating text after Epoch: 60\n",
            "----- Generating with seed: \"itarily and to remon\"\n",
            "itarily and to remons plondupts usityle \n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 1.0643\n",
            "Epoch 62/150\n",
            "\u001b[1m1317/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0676\n",
            "----- Generating text after Epoch: 61\n",
            "----- Generating with seed: \"equests to discuss h\"\n",
            "equests to discuss harod for whose pows \n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.0677\n",
            "Epoch 63/150\n",
            "\u001b[1m1313/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0620\n",
            "----- Generating text after Epoch: 62\n",
            "----- Generating with seed: \" they did in june ow\"\n",
            " they did in june ow she along fed counc\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 1.0621\n",
            "Epoch 64/150\n",
            "\u001b[1m1313/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0661\n",
            "----- Generating text after Epoch: 63\n",
            "----- Generating with seed: \"hted turkeys invasio\"\n",
            "hted turkeys invasion are schedulist con\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.0662\n",
            "Epoch 65/150\n",
            "\u001b[1m1313/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0574\n",
            "----- Generating text after Epoch: 64\n",
            "----- Generating with seed: \"lso a college qb and\"\n",
            "lso a college qb and adjucts the polies \n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.0576\n",
            "Epoch 66/150\n",
            "\u001b[1m1315/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0600\n",
            "----- Generating text after Epoch: 65\n",
            "----- Generating with seed: \"p from the governmen\"\n",
            "p from the governmenblean addissare stil\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 1.0601\n",
            "Epoch 67/150\n",
            "\u001b[1m1311/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0513\n",
            "----- Generating text after Epoch: 66\n",
            "----- Generating with seed: \"ble see overviewstep\"\n",
            "ble see overviewstep mackition jow you w\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.0515\n",
            "Epoch 68/150\n",
            "\u001b[1m1319/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0504\n",
            "----- Generating text after Epoch: 67\n",
            "----- Generating with seed: \"nfessing what he had\"\n",
            "nfessing what he had she has ave topume \n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 1.0505\n",
            "Epoch 69/150\n",
            "\u001b[1m1315/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0465\n",
            "----- Generating text after Epoch: 68\n",
            "----- Generating with seed: \"senator and secretar\"\n",
            "senator and secretary agound a wearhy th\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.0467\n",
            "Epoch 70/150\n",
            "\u001b[1m1316/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0466\n",
            "----- Generating text after Epoch: 69\n",
            "----- Generating with seed: \"ion no one wants a c\"\n",
            "ion no one wants a coreer and that publi\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.0467\n",
            "Epoch 71/150\n",
            "\u001b[1m1317/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0433\n",
            "----- Generating text after Epoch: 70\n",
            "----- Generating with seed: \"ts any other person \"\n",
            "ts any other person and when the trump m\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 1.0434\n",
            "Epoch 72/150\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0444\n",
            "----- Generating text after Epoch: 71\n",
            "----- Generating with seed: \"ht a relationship be\"\n",
            "ht a relationship benowe on wentington i\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 1.0444\n",
            "Epoch 73/150\n",
            "\u001b[1m1318/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0381\n",
            "----- Generating text after Epoch: 72\n",
            "----- Generating with seed: \" its so beautiful to\"\n",
            " its so beautiful to tancaaged to be tea\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 1.0382\n",
            "Epoch 74/150\n",
            "\u001b[1m1318/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0411\n",
            "----- Generating text after Epoch: 73\n",
            "----- Generating with seed: \"the context of colle\"\n",
            "the context of collegonaty purpoinalizel\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.0412\n",
            "Epoch 75/150\n",
            "\u001b[1m1316/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0419\n",
            "----- Generating text after Epoch: 74\n",
            "----- Generating with seed: \"few thousand intervi\"\n",
            "few thousand intervieand beto what wis a\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 1.0420\n",
            "Epoch 76/150\n",
            "\u001b[1m1310/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0316\n",
            "----- Generating text after Epoch: 75\n",
            "----- Generating with seed: \" americas racial fai\"\n",
            " americas racial failuperians its trumps\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.0319\n",
            "Epoch 77/150\n",
            "\u001b[1m1318/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0385\n",
            "----- Generating text after Epoch: 76\n",
            "----- Generating with seed: \" signaled the admini\"\n",
            " signaled the administration with the so\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.0386\n",
            "Epoch 78/150\n",
            "\u001b[1m1310/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0283\n",
            "----- Generating text after Epoch: 77\n",
            "----- Generating with seed: \"gton post disclaims \"\n",
            "gton post disclaims to get abonot recent\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 1.0285\n",
            "Epoch 79/150\n",
            "\u001b[1m1312/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0257\n",
            "----- Generating text after Epoch: 78\n",
            "----- Generating with seed: \"bal powerthe latest \"\n",
            "bal powerthe latest electtory including \n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.0259\n",
            "Epoch 80/150\n",
            "\u001b[1m1316/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0302\n",
            "----- Generating text after Epoch: 79\n",
            "----- Generating with seed: \"tigation but trump c\"\n",
            "tigation but trump corment at the police\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.0303\n",
            "Epoch 81/150\n",
            "\u001b[1m1311/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0289\n",
            "----- Generating text after Epoch: 80\n",
            "----- Generating with seed: \" able to read the ga\"\n",
            " able to read the game the american was \n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 1.0291\n",
            "Epoch 82/150\n",
            "\u001b[1m1311/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0232\n",
            "----- Generating text after Epoch: 81\n",
            "----- Generating with seed: \" us a new payment me\"\n",
            " us a new payment methodowmman cotura al\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.0234\n",
            "Epoch 83/150\n",
            "\u001b[1m1311/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0227\n",
            "----- Generating text after Epoch: 82\n",
            "----- Generating with seed: \"ted conductyou may n\"\n",
            "ted conductyou may nit mant funfities th\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 1.0229\n",
            "Epoch 84/150\n",
            "\u001b[1m1313/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0161\n",
            "----- Generating text after Epoch: 83\n",
            "----- Generating with seed: \"ure a bipartisan she\"\n",
            "ure a bipartisan shew on the him his fee\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.0163\n",
            "Epoch 85/150\n",
            "\u001b[1m1320/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0169\n",
            "----- Generating text after Epoch: 84\n",
            "----- Generating with seed: \"oss the ring kneeing\"\n",
            "oss the ring kneeing she same terrisal f\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.0170\n",
            "Epoch 86/150\n",
            "\u001b[1m1313/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0225\n",
            "----- Generating text after Epoch: 85\n",
            "----- Generating with seed: \"united states v nixo\"\n",
            "united states v nixorday the redivessext\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 1.0226\n",
            "Epoch 87/150\n",
            "\u001b[1m1318/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0115\n",
            "----- Generating text after Epoch: 86\n",
            "----- Generating with seed: \"ns of the gamebedroc\"\n",
            "ns of the gamebedroc with the case lowns\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.0115\n",
            "Epoch 88/150\n",
            "\u001b[1m1314/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0134\n",
            "----- Generating text after Epoch: 87\n",
            "----- Generating with seed: \" goal a nofly zone o\"\n",
            " goal a nofly zone or mocks perfest to u\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 1.0135\n",
            "Epoch 89/150\n",
            "\u001b[1m1315/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0119\n",
            "----- Generating text after Epoch: 88\n",
            "----- Generating with seed: \"ld likely require fr\"\n",
            "ld likely require fringed on the screen \n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.0121\n",
            "Epoch 90/150\n",
            "\u001b[1m1316/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0126\n",
            "----- Generating text after Epoch: 89\n",
            "----- Generating with seed: \"a key role in three \"\n",
            "a key role in three brodcorncicas to pun\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.0127\n",
            "Epoch 91/150\n",
            "\u001b[1m1317/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0101\n",
            "----- Generating text after Epoch: 90\n",
            "----- Generating with seed: \"cation officials sai\"\n",
            "cation officials said in the lifing jone\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 1.0102\n",
            "Epoch 92/150\n",
            "\u001b[1m1319/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0108\n",
            "----- Generating text after Epoch: 91\n",
            "----- Generating with seed: \"n the way that the n\"\n",
            "n the way that the now the coidumenich l\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.0109\n",
            "Epoch 93/150\n",
            "\u001b[1m1317/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0102\n",
            "----- Generating text after Epoch: 92\n",
            "----- Generating with seed: \"ors apart the intell\"\n",
            "ors apart the intelligenes of the otiean\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.0103\n",
            "Epoch 94/150\n",
            "\u001b[1m1313/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0090\n",
            "----- Generating text after Epoch: 93\n",
            "----- Generating with seed: \"an the online social\"\n",
            "an the online social mansa formation and\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 1.0091\n",
            "Epoch 95/150\n",
            "\u001b[1m1316/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0108\n",
            "----- Generating text after Epoch: 94\n",
            "----- Generating with seed: \"kplace so the decisi\"\n",
            "kplace so the decision of the begrath th\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.0109\n",
            "Epoch 96/150\n",
            "\u001b[1m1314/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0074\n",
            "----- Generating text after Epoch: 95\n",
            "----- Generating with seed: \"ay make use of the c\"\n",
            "ay make use of the children and swhetald\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 1.0076\n",
            "Epoch 97/150\n",
            "\u001b[1m1320/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0033\n",
            "----- Generating text after Epoch: 96\n",
            "----- Generating with seed: \"d to be little in th\"\n",
            "d to be little in the playing for a sigh\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.0033\n",
            "Epoch 98/150\n",
            "\u001b[1m1319/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9996\n",
            "----- Generating text after Epoch: 97\n",
            "----- Generating with seed: \" improved over time \"\n",
            " improved over time probermiss news aban\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.9997\n",
            "Epoch 99/150\n",
            "\u001b[1m1315/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9990\n",
            "----- Generating text after Epoch: 98\n",
            "----- Generating with seed: \" paid hunter biden t\"\n",
            " paid hunter biden the world what house \n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.9991\n",
            "Epoch 100/150\n",
            "\u001b[1m1310/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9985\n",
            "----- Generating text after Epoch: 99\n",
            "----- Generating with seed: \"be too little too la\"\n",
            "be too little too lattabtolomow commone \n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.9987\n",
            "Epoch 101/150\n",
            "\u001b[1m1316/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0015\n",
            "----- Generating text after Epoch: 100\n",
            "----- Generating with seed: \"s fellow litigators \"\n",
            "s fellow litigators in the carcout anfic\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 1.0016\n",
            "Epoch 102/150\n",
            "\u001b[1m1317/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0043\n",
            "----- Generating text after Epoch: 101\n",
            "----- Generating with seed: \"ually become muddied\"\n",
            "ually become muddied the constilute if y\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 1.0044\n",
            "Epoch 103/150\n",
            "\u001b[1m1315/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9956\n",
            "----- Generating text after Epoch: 102\n",
            "----- Generating with seed: \" can sense the chang\"\n",
            " can sense the change the people and the\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - loss: 0.9957\n",
            "Epoch 104/150\n",
            "\u001b[1m1315/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9975\n",
            "----- Generating text after Epoch: 103\n",
            "----- Generating with seed: \"chin said we have a \"\n",
            "chin said we have a but the mostional fo\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.9976\n",
            "Epoch 105/150\n",
            "\u001b[1m1311/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9940\n",
            "----- Generating text after Epoch: 104\n",
            "----- Generating with seed: \"elding cnn person tw\"\n",
            "elding cnn person two was repobsier he i\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.9942\n",
            "Epoch 106/150\n",
            "\u001b[1m1314/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9962\n",
            "----- Generating text after Epoch: 105\n",
            "----- Generating with seed: \" between anne frank \"\n",
            " between anne frank on find in his helpo\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.9963\n",
            "Epoch 107/150\n",
            "\u001b[1m1320/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9937\n",
            "----- Generating text after Epoch: 106\n",
            "----- Generating with seed: \"ago this month a man\"\n",
            "ago this month a man a belong conduce ou\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.9937\n",
            "Epoch 108/150\n",
            "\u001b[1m1315/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9911\n",
            "----- Generating text after Epoch: 107\n",
            "----- Generating with seed: \"een a particular tar\"\n",
            "een a particular tarks in s kelessancres\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.9913\n",
            "Epoch 109/150\n",
            "\u001b[1m1318/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9931\n",
            "----- Generating text after Epoch: 108\n",
            "----- Generating with seed: \"tability and uncerta\"\n",
            "tability and uncertaintading top will se\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.9931\n",
            "Epoch 110/150\n",
            "\u001b[1m1318/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9882\n",
            "----- Generating text after Epoch: 109\n",
            "----- Generating with seed: \"you find yourself wi\"\n",
            "you find yourself with and privices by r\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.9883\n",
            "Epoch 111/150\n",
            "\u001b[1m1312/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9930\n",
            "----- Generating text after Epoch: 110\n",
            "----- Generating with seed: \"missions by the wash\"\n",
            "missions by the washington post firs ove\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.9932\n",
            "Epoch 112/150\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9867\n",
            "----- Generating text after Epoch: 111\n",
            "----- Generating with seed: \" that nofly zones we\"\n",
            " that nofly zones web baken hod anokneti\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.9868\n",
            "Epoch 113/150\n",
            "\u001b[1m1313/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9918\n",
            "----- Generating text after Epoch: 112\n",
            "----- Generating with seed: \" or person we may ca\"\n",
            " or person we may calleteen allors was n\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.9920\n",
            "Epoch 114/150\n",
            "\u001b[1m1320/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9861\n",
            "----- Generating text after Epoch: 113\n",
            "----- Generating with seed: \"t wrestling scene to\"\n",
            "t wrestling scene to usural offices and \n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.9861\n",
            "Epoch 115/150\n",
            "\u001b[1m1315/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9868\n",
            "----- Generating text after Epoch: 114\n",
            "----- Generating with seed: \"feel as if youre ste\"\n",
            "feel as if youre stel as larger us was i\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.9869\n",
            "Epoch 116/150\n",
            "\u001b[1m1318/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9847\n",
            "----- Generating text after Epoch: 115\n",
            "----- Generating with seed: \"jones said but the b\"\n",
            "jones said but the bott make beammenblew\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.9848\n",
            "Epoch 117/150\n",
            "\u001b[1m1310/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9834\n",
            "----- Generating text after Epoch: 116\n",
            "----- Generating with seed: \" they dont want to t\"\n",
            " they dont want to the ameracion while a\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.9837\n",
            "Epoch 118/150\n",
            "\u001b[1m1320/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9903\n",
            "----- Generating text after Epoch: 117\n",
            "----- Generating with seed: \"httpstcoxwtqzkcbeto \"\n",
            "httpstcoxwtqzkcbeto phic stky mort be it\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.9903\n",
            "Epoch 119/150\n",
            "\u001b[1m1310/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9879\n",
            "----- Generating text after Epoch: 118\n",
            "----- Generating with seed: \"that happening and h\"\n",
            "that happening and his ferent this books\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.9881\n",
            "Epoch 120/150\n",
            "\u001b[1m1314/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9855\n",
            "----- Generating text after Epoch: 119\n",
            "----- Generating with seed: \"irefighteradso i fou\"\n",
            "irefighteradso i foun good farruller des\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.9857\n",
            "Epoch 121/150\n",
            "\u001b[1m1319/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9806\n",
            "----- Generating text after Epoch: 120\n",
            "----- Generating with seed: \"bidadfor the eagles \"\n",
            "bidadfor the eagles would in why dre dec\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.9806\n",
            "Epoch 122/150\n",
            "\u001b[1m1316/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9838\n",
            "----- Generating text after Epoch: 121\n",
            "----- Generating with seed: \"alabamas republican \"\n",
            "alabamas republican moves not be decodon\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.9839\n",
            "Epoch 123/150\n",
            "\u001b[1m1320/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9867\n",
            "----- Generating text after Epoch: 122\n",
            "----- Generating with seed: \"rate indigenous peop\"\n",
            "rate indigenous peopeepel bent in by was\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.9867\n",
            "Epoch 124/150\n",
            "\u001b[1m1315/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9824\n",
            "----- Generating text after Epoch: 123\n",
            "----- Generating with seed: \"idnt poke the soft f\"\n",
            "idnt poke the soft for drazin amenictrat\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.9825\n",
            "Epoch 125/150\n",
            "\u001b[1m1318/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9857\n",
            "----- Generating text after Epoch: 124\n",
            "----- Generating with seed: \"he oath of office a \"\n",
            "he oath of office a restrust mildionsipe\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.9857\n",
            "Epoch 126/150\n",
            "\u001b[1m1316/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9798\n",
            "----- Generating text after Epoch: 125\n",
            "----- Generating with seed: \" gift subscriptions \"\n",
            " gift subscriptions are keep with appara\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.9799\n",
            "Epoch 127/150\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9776\n",
            "----- Generating text after Epoch: 126\n",
            "----- Generating with seed: \"can modernist compos\"\n",
            "can modernist compos information you cou\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.9777\n",
            "Epoch 128/150\n",
            "\u001b[1m1313/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9868\n",
            "----- Generating text after Epoch: 127\n",
            "----- Generating with seed: \"was closely related \"\n",
            "was closely related them are mombisideri\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.9870\n",
            "Epoch 129/150\n",
            "\u001b[1m1320/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9749\n",
            "----- Generating text after Epoch: 128\n",
            "----- Generating with seed: \" screen at you to in\"\n",
            " screen at you to invides that cowbyct c\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.9750\n",
            "Epoch 130/150\n",
            "\u001b[1m1315/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9765\n",
            "----- Generating text after Epoch: 129\n",
            "----- Generating with seed: \"anera serves more th\"\n",
            "anera serves more that theirs jondsonday\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.9766\n",
            "Epoch 131/150\n",
            "\u001b[1m1318/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9768\n",
            "----- Generating text after Epoch: 130\n",
            "----- Generating with seed: \" facing more direct \"\n",
            " facing more direct and lovated an emcam\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.9768\n",
            "Epoch 132/150\n",
            "\u001b[1m1319/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9787\n",
            "----- Generating text after Epoch: 131\n",
            "----- Generating with seed: \"he president is comf\"\n",
            "he president is comfers onf any police b\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.9787\n",
            "Epoch 133/150\n",
            "\u001b[1m1318/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9812\n",
            "----- Generating text after Epoch: 132\n",
            "----- Generating with seed: \"seddoor depositionhi\"\n",
            "seddoor depositionhing stop to suggers t\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.9813\n",
            "Epoch 134/150\n",
            "\u001b[1m1314/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9808\n",
            "----- Generating text after Epoch: 133\n",
            "----- Generating with seed: \"rican modernist comp\"\n",
            "rican modernist compames trimanments ins\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.9809\n",
            "Epoch 135/150\n",
            "\u001b[1m1313/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9748\n",
            "----- Generating text after Epoch: 134\n",
            "----- Generating with seed: \"d takatch has retain\"\n",
            "d takatch has retains from viorthells se\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.9750\n",
            "Epoch 136/150\n",
            "\u001b[1m1313/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9795\n",
            "----- Generating text after Epoch: 135\n",
            "----- Generating with seed: \"ept right he added b\"\n",
            "ept right he added by the charge your ev\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.9797\n",
            "Epoch 137/150\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9724\n",
            "----- Generating text after Epoch: 136\n",
            "----- Generating with seed: \"ze the salary of the\"\n",
            "ze the salary of the samerous the kurds \n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.9725\n",
            "Epoch 138/150\n",
            "\u001b[1m1310/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9751\n",
            "----- Generating text after Epoch: 137\n",
            "----- Generating with seed: \"ays trump has gone f\"\n",
            "ays trump has gone for the kuid is schoo\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.9753\n",
            "Epoch 139/150\n",
            "\u001b[1m1319/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9715\n",
            "----- Generating text after Epoch: 138\n",
            "----- Generating with seed: \"y as it did would th\"\n",
            "y as it did would that that he people sa\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - loss: 0.9716\n",
            "Epoch 140/150\n",
            "\u001b[1m1313/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9754\n",
            "----- Generating text after Epoch: 139\n",
            "----- Generating with seed: \" of your next schedu\"\n",
            " of your next schedulesia shiulding a va\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.9756\n",
            "Epoch 141/150\n",
            "\u001b[1m1313/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9691\n",
            "----- Generating text after Epoch: 140\n",
            "----- Generating with seed: \" university who wrot\"\n",
            " university who wrotiesscelleg truchters\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.9693\n",
            "Epoch 142/150\n",
            "\u001b[1m1314/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9695\n",
            "----- Generating text after Epoch: 141\n",
            "----- Generating with seed: \"hich was so good tha\"\n",
            "hich was so good that was are sunfirmame\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.9697\n",
            "Epoch 143/150\n",
            "\u001b[1m1311/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9741\n",
            "----- Generating text after Epoch: 142\n",
            "----- Generating with seed: \"ters will probably g\"\n",
            "ters will probably grade also we litec l\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.9743\n",
            "Epoch 144/150\n",
            "\u001b[1m1311/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9687\n",
            "----- Generating text after Epoch: 143\n",
            "----- Generating with seed: \"he services you give\"\n",
            "he services you give the blax concernize\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.9690\n",
            "Epoch 145/150\n",
            "\u001b[1m1319/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9743\n",
            "----- Generating text after Epoch: 144\n",
            "----- Generating with seed: \"bbeck and their coll\"\n",
            "bbeck and their colleagues art as the co\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.9744\n",
            "Epoch 146/150\n",
            "\u001b[1m1312/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9630\n",
            "----- Generating text after Epoch: 145\n",
            "----- Generating with seed: \"would halt the offen\"\n",
            "would halt the offens with ambical our s\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.9633\n",
            "Epoch 147/150\n",
            "\u001b[1m1313/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9712\n",
            "----- Generating text after Epoch: 146\n",
            "----- Generating with seed: \"would eat a proper d\"\n",
            "would eat a proper daily almince to a pr\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.9714\n",
            "Epoch 148/150\n",
            "\u001b[1m1319/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9724\n",
            "----- Generating text after Epoch: 147\n",
            "----- Generating with seed: \"the resulting snapsh\"\n",
            "the resulting snapsher and close the two\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.9724\n",
            "Epoch 149/150\n",
            "\u001b[1m1317/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9690\n",
            "----- Generating text after Epoch: 148\n",
            "----- Generating with seed: \"leds song all i do i\"\n",
            "leds song all i do in case upto liquimed\n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.9691\n",
            "Epoch 150/150\n",
            "\u001b[1m1312/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9686\n",
            "----- Generating text after Epoch: 149\n",
            "----- Generating with seed: \" you know what he ad\"\n",
            " you know what he adazely mores a sixed \n",
            "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.9688\n",
            "CPU times: user 19min 42s, sys: 1min 26s, total: 21min 8s\n",
            "Wall time: 19min 5s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c12f3120fb0>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "## Takes about 4.5 minutes to train the entire corpus for 50 epochs on a colab GPU (1 LSTM layer, 128 neurons)\n",
        "\n",
        "# build a 1 layer LSTM language model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "opt = Adam(learning_rate=0.001)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# hidden layer 1\n",
        "model.add(LSTM(128,\n",
        "               input_shape=(dctk.maxlen, dctk.n_features), # input_shape is (20,27)\n",
        "               return_sequences=False)) # whenever using 2 or more LSTM layers, set return_sequences= True for all but the last LSTM layer\n",
        "\n",
        "# this is our output layer\n",
        "# recall that n_features = number of characters in the dictionary = 27\n",
        "model.add(Dense(dctk.n_features,\n",
        "                activation='softmax'))\n",
        "\n",
        "# notice that we are using categorical_crossentropy this time around - why?\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt)\n",
        "\n",
        "# fit the model\n",
        "# X and y are pretty large, consider sub-sampling\n",
        "model.fit(X, y,\n",
        "          batch_size=128,\n",
        "          epochs=150,\n",
        "          callbacks=[print_callback])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBt5ugHKIM21"
      },
      "source": [
        "-------------\n",
        "## Challenge\n",
        "\n",
        "You will be expected to use a Keras LSTM to generate text on today's assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ger33u0CIM22"
      },
      "source": [
        "# Review\n",
        "\n",
        "- <a href=\"#p1\">Part 1: </a>Describe Neural Networks used for modeling sequences\n",
        "    * Sequence Problems:\n",
        "        - Text Classification\n",
        "        - Text Generation\n",
        "        - Machine Translation\n",
        "        - Time Series Forecasting (like Stock Prices, Weather, etc.)\n",
        "    * LSTMs are generally preferred over RNNs for most problems\n",
        "    * LSTMs generally use 1 or 2 hidden layers.\n",
        "    * Keras has LSTMs/RNN layer types implemented nicely\n",
        "- <a href=\"#p2\">Part 2: </a>Apply LSTMs to a text classification problem and to a text generation problem using TensorFlow/Keras\n",
        "    * The shape of the input data for an LSTM is important\n",
        "    * LSTMs can take a while to train\n",
        "    * You can use LSTMs to write movie scripts. :P"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "celltoolbar": "Create Assignment",
    "colab": {
      "machine_shape": "hm",
      "name": "DS_431_RNN_and_LSTM_Lecture.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "py37  (Python3)",
      "language": "python",
      "name": "py37"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}